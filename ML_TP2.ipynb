{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML-TP2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4FG/+mtEIAWygntK52gcH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agustinLapi/MachineLearning/blob/main/ML_TP2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx7UxitHMXXl"
      },
      "source": [
        "#Ejercicio 1 - K vecinos m√°s cercanos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "Rqsgr4SVBedl",
        "outputId": "293136a4-9011-440c-cfe1-faaff030a87c"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "\n",
        "# Assign colum names to the dataset\n",
        "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
        "\n",
        "# Read dataset to pandas dataframe\n",
        "dataset = pd.read_csv(url, names=names)\n",
        "\n",
        "dataset.head()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal-length</th>\n",
              "      <th>sepal-width</th>\n",
              "      <th>petal-length</th>\n",
              "      <th>petal-width</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal-length  sepal-width  petal-length  petal-width        Class\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ca72OhrVTWx"
      },
      "source": [
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, 4].values\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWytABruVXDO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JxN1l_vVaY_"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmYR_OQwVfoz",
        "outputId": "b272f951-c095-4de0-c927-94dacb55d76d"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=4)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIouqdQYVhyZ"
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_smIhvaVl2k",
        "outputId": "6541812f-7ed9-4c64-d826-806d4807f94b"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 8  0  0]\n",
            " [ 0 13  1]\n",
            " [ 0  2  6]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00         8\n",
            "Iris-versicolor       0.87      0.93      0.90        14\n",
            " Iris-virginica       0.86      0.75      0.80         8\n",
            "\n",
            "       accuracy                           0.90        30\n",
            "      macro avg       0.91      0.89      0.90        30\n",
            "   weighted avg       0.90      0.90      0.90        30\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSCaN8vFVp3v"
      },
      "source": [
        "error = []\n",
        "\n",
        "# Calculating error for K values between 1 and 40\n",
        "for i in range(1, 40):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_i = knn.predict(X_test)\n",
        "    error.append(np.mean(pred_i != y_test))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "61fOAADeWKCu",
        "outputId": "bd7db083-282b-42d5-b954-bd71f6841c52"
      },
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',\n",
        "         markerfacecolor='blue', markersize=10)\n",
        "plt.title('Error Rate K Value')\n",
        "plt.xlabel('K Value')\n",
        "plt.ylabel('Mean Error')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Mean Error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI6j-FnNQemt"
      },
      "source": [
        "##Repito lo anterior para un dataset propio, generado a partir de distribuciones normales cada uno con su respectiva media y variancia\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCD45nR7WMRj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "meanA, A_sd = 5, 1.5\n",
        "meanB, B_sd = 8, 1.8\n",
        "n = 50\n",
        "\n",
        "A_df = pd.DataFrame(np.random.normal(meanA, A_sd, size=n),columns=['Tama√±os'])\n",
        "B_df = pd.DataFrame(np.random.normal(meanB, B_sd, size=n),columns=['Tama√±os'])\n",
        "y = pd.DataFrame(np.random.randint(1,5, size=2*n), columns=['Y'])\n",
        "A_df['Clase'] = 'A'\n",
        "B_df['Clase'] = 'B'\n",
        "\n",
        "C_df =  pd.concat([A_df, B_df], axis=0)\n",
        "C_df.reset_index(drop=True, inplace=True)\n",
        "data_df = pd.concat([C_df, y] , axis=1)\n",
        "data_df\n",
        "Clases = data_df[\"Clase\"]\n",
        "data_df = data_df[[\"Tama√±os\", \"Y\"]]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp_LgHELelVt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_df, Clases, test_size=0.40)\n",
        "#Divido a una razon de 60-40 para entrenar y testear"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUK-gGeletgY"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuGynX9kg6Cu",
        "outputId": "bde048e0-1c43-4efe-defc-49291947fa54"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_56UJv5Lg9hm"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "#realizo la predicci√≥n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd5WUd-nhDVw",
        "outputId": "c6d3b2bd-fdcd-41e7-d92b-8b0bfb0209ea"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[13  8]\n",
            " [ 2 17]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.87      0.62      0.72        21\n",
            "           B       0.68      0.89      0.77        19\n",
            "\n",
            "    accuracy                           0.75        40\n",
            "   macro avg       0.77      0.76      0.75        40\n",
            "weighted avg       0.78      0.75      0.75        40\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "3yJ_8hwwS44c",
        "outputId": "2c942fe1-b90b-481d-ecf4-265872732ff0"
      },
      "source": [
        "from sklearn import metrics \n",
        "disp = metrics.plot_confusion_matrix(classifier, X_test, y_test, cmap='inferno')\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[13  8]\n",
            " [ 2 17]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyjkKQTEhH5W"
      },
      "source": [
        "error = []\n",
        "\n",
        "# Calculating error for K values between 1 and 40\n",
        "for i in range(1, 40):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_i = knn.predict(X_test)\n",
        "    error.append(np.mean(pred_i != y_test))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "1TxMGMKDhMlt",
        "outputId": "98dce427-f0c4-48af-e4bd-96ede56a2b7c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',\n",
        "         markerfacecolor='blue', markersize=10)\n",
        "plt.title('Error Rate K Value')\n",
        "plt.xlabel('K Value')\n",
        "plt.ylabel('Mean Error')\n",
        "\n",
        "#Plotting error rate for k values between 1 and 40"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Mean Error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt0AAAGDCAYAAAD3W6zoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxU1fnH8c+TEAIBImoIFRAUxBVxIUrcqq0rXdBWa5W61AoWcKtVq621Vaut1VoLLihiXavWtUUFba3VnxVDQUVRFJOgaFBWRfYQyPn9cWbKECbJLPfOxvf9et3XZO5yzrktzn3mzDnPMeccIiIiIiISnqJsN0BEREREpNAp6BYRERERCZmCbhERERGRkCnoFhEREREJmYJuEREREZGQKegWEREREQmZgm4REckbZvaSmY3MdjtERJKloFtEJE1m9pGZrTWzVTHbrRluw0tmti5S91Ize9LMdkjw2iPMrCGNuje73sw6Rup/1czKW5x7uZn9X5wyKsxsvZkNSrUdIiK5TEG3iEgwvu2c6xqznRfvJDPrEGdfcTIVtXH+ec65rsAuQFfgD8mUGwQzKwWeBLoDxzjnVrQ45UHgYDPbucX+U4DZzrl3MtBMEZGMU9AtIhIiM/thpMf3ZjNbBlxlZvea2QQzm2Jmq4Gvmdkekd7q5Wb2rpkNjylji/PbqtM5txz4G7BvTBlnmdl7ZrbSzOaZ2Y8j+7sAU4FeMb30vcysKNIrXW9my8zsUTPbrp17LQOeBjoA33TOrY7TtgbgReD0FofOAO43s23N7BkzW2JmX0T+7tNKfVeZ2YMx73cyMxf9YmNm25jZ3Wb2mZktMLNrk/2CIyISFAXdIiLhGwrMA3oC10X2jYj83Q2Yjg9W/wFUAucDfzGz3WLKiD3/P21VZmbbA98F6mJ2Lwa+BZQDZwE3m9n+kcB4GPBpTC/9p5E2nAAcDvQCvgBua6PaUnzwvg443jm3to1z7yMm6I7c577AQ/jn0j1AP6AvsBZIdajOvcAGfM//fsAxgMaDi0hWKOgWEQnG3yK91NFtVMyxT51ztzjnNsQEo393zr3qnGvGB5xdgeudc+udcy8CzwCnxpTxv/Odc+taacN4M/sSWApU4ANnAJxzzzrn6p33Mj7AP6yN+xkNXOGca3DONQJXASfFGx4T0Q04CLgvcn5bngJ6mtnBkfdnAFOdc0ucc8ucc08459Y451biv2gc3k55WzCznsA3gJ8451Y75xYDN+OHsYiIZJyCbhGRYJzgnOses90Vc+yTOOfH7usFfBIJwKPmA73bKaOlC5xz2wCDgW2B/w3LMLNhZlZjZp+b2XJ8QFrRRln9gKeiXyKA94CN+N76eJbiA9r7zOzYthrpnFsDPAacYWYG/AC4P9LOMjO708zmm9kK4P+A7ikMC+kHlACfxdzDnfhfEkREMk5Bt4hI+Fw7+z4FdjSz2M/kvsCCdsqIX5lzs4FrgdvMKwWewE+s7Omc6w5MAayNsj8BhrX4ItHJObcgzrnRep8ERgGPm1mb487xQ0xOBo7G95I/Hdl/MbAbMNQ5Vw58NbLftigBVgNlMe+/0qL9jUBFTPvLnXN7tdMuEZFQKOgWEcm+6cAa4GdmVmJmRwDfBh5Jo8z78L3Sw4GO+DHXS4ANZjYMP745ahGwvZltE7PvDuA6M+sHYGY9zOz49ip1zj0MnAf83cwOaePUV4DlwETgEefc+sj+bvhx3MsjEzd/3UYZs4CvmlnfSNt/HtOOz/BDaG4ys/LIxNABZpb0UBURkSAo6BYRCcbTtnme7qcSvTAScH4bP6FxKXA7cIZz7v1UGxMpcxxwZWRs9AXAo/gJkSOAyTHnvg88DMyLDMXoFbl2MvAPM1sJ1OAnhCZS9334HutnzezAVs5x+CEl/SKvUX8COuP/d6gBnmujnn8CfwXeBl7Hj4OPdQb+C8ecyH0/DiSUu1xEJGjmP/dERERERCQs6ukWEREREQmZgm4RERERkZAp6BYRERERCZmCbhERERGRkCnoFhEREREJWWvL+RaUiooKt9NOO2W7GSIiIiJSwF5//fWlzrke8Y5tFUH3TjvtxMyZM7PdDBEREREpYGY2v7VjGl4iIiIiIhIyBd0iIiIiIiFT0C0iIiIiEjIF3SIiIiIiIVPQLSIiIiISMgXdIiIiIiIhU9AtIiIiIhIyBd25pr6exrEXsba8J81Fxawt70nj2Iugvj7bLRMRERGRFCnoziVTp7J6cDXjJ3Vm0MppdHSNDFo5jfGTOrN6cDVMnZrtFoqIiIhICkINus3sODOba2Z1ZnZ5nOOjzWy2mc0ys/+Y2Z4xx34euW6umR2baJl5q76e1SedwVFrJvOzpt8yjwFspAPzGMDPmn7LUWsms/qkM9TjLSIiIpKHQgu6zawYuA0YBuwJnBobVEc85Jzb2zm3L3AD8MfItXsCpwB7AccBt5tZcYJl5qXGm27l9qZR1HBQ3OM1HMSEppE03nxbhlsmIiIiIukKs6f7QKDOOTfPObceeAQ4PvYE59yKmLddABf5+3jgEedco3PuQ6AuUl67Zear5gcf4o6ms9s8Z0LTSDY+8FCGWiQiIiIiQekQYtm9gU9i3jcAQ1ueZGbnAj8FOgJfj7m2psW1vSN/t1tmpNxzgHMA+vbtm3zrM6x01VLm06/Ncz6mL51WLc1Qi0REREQkKFmfSOmcu805NwC4DPhlgOVOdM5VOeeqevToEVSxoWnsWkE/5rd5Tl8+Zl3Xigy1SERERESCEmbQvQDYMeZ9n8i+1jwCnNDOtcmWmTeKThvB6JK72zxnTMkkik8fkaEWiYiIiEhQwgy6ZwADzWxnM+uInxg5OfYEMxsY8/abQG3k78nAKWZWamY7AwOB/yZSZr4qvfg8xpbcRTWvxT1ezWuMKZlE6UXnZrhlIiIiIpKu0IJu59wG4DzgeeA94FHn3Ltmdo2ZDY+cdp6ZvWtms/Djus+MXPsu8CgwB3gOONc5t7G1MsO6h4waMIAuj9/PC2XDubHDZfSnng400Z96biz5OS+UDafL4/fDgAHZbqmIiIiIJMmcc+2fleeqqqrczJkzs92MxNTX03jzbWx84CE6rVjMutJtKB55lu/hVsAtIiIikrPM7HXnXFW8Y1mfSCktDBhA6bW/ouzLhRR1KaNs7FmU3vpHBdwiIiIieUxBd65ZuxYqK+H66/3r4sXZbpGIiIiIpElBd655801oaoLdd4eePRV0i4iIiBSAMBfHkVTURNYEGjoUvvUt2Lgxu+0RERERkbQp6M4106dD376www5wxRXZbo2IiIiIBEDDS3LN9Om+lzuquRm2ggwzIiIiIoVMQXcuaW6GK6+EUaP8+4kToWNH+OKL7LZLRERERNKi4SW5pKgIzj570/tu3fyY7sWLYbvtstcuEREREUmLerpzyRtvwPvvb3pfWelflcFEREREJK+ppzuXXHopfPklRFfP7NnTvyroFhEREclr6unOFRs3wowZm0+iVE+3iIiISEFQ0J0r3nsPVq7cPOjefnsYMwb22CN77RIRERGRtGl4Sa6YPt2/xgbdxcVw++3ZaY+IiIiIBEY93bmipga23RYGDtx8/4YNfpy3iIiIiOQtBd254rrrYMoUnzYw1jHH+OXgRURERCRvaXhJrqis3DRxsuX+N9/MfHtEREREJDDq6c4Fs2fDDTfA559veayyEhYtynybRERERCQwCrpzwZQpcNll4NyWxyor/ZjuxsbMt0tEREREAqGgOxfU1MAuu/gUgS1Fh5wsWZLZNomIiIhIYBR0Z5tzPl1gdXX849XVfpJl586ZbZeIiIiIBEYTKbOtoQE++2zz/NyxBg/2m4iIiIjkLfV0Z9v770NJSetBd3MzfPwxLFuW2XaJiIiISGAUdGfb0UfDihWw//7xj69eDf36wZ//nNl2iYiIiEhgNLwkF3Tq1Pqxrl398cWLM9ceEREREQmUerqzqakJjjwSJk9u/Rwzn8FEQbeIiIhI3lLQnU2zZ8OLL8LatW2fp6BbREREJK8p6M6m6dP9a2uTKKMUdIuIiIjkNQXd2VRTAz17+omSbTnvPPj5zzPTJhEREclP9fU0jr2IteU9aS4qZm15TxrHXgT19VtH/Tku1KDbzI4zs7lmVmdml8c5/lMzm2Nmb5vZv8ysX2T/18xsVsy2zsxOiBy718w+jDm2b5j3EKrp030vt1nb5w0bBiedlJk2iYiISP6ZOpXVg6sZP6kzg1ZOo6NrZNDKaYyf1JnVg6th6tTCrj8PmHMunILNioEPgKOBBmAGcKpzbk7MOV8Dpjvn1pjZGOAI59z3W5SzHVAH9Imcdy/wjHPu8UTbUlVV5WbOnJn2PQVqwwb4znfg2GN9T3ZbvvjC5/Pef38oLc1M+0RERCQ/1NezenA1R62ZTA0HbXG4mtd4oWw4Xd6ugQEDCq/+HGJmrzvnquIdC7On+0Cgzjk3zzm3HngEOD72BOfcv51zayJva4A+cco5CZgac15h6NABnn66/YAb4Nln4eCDYf788NslIiIieaXxplu5vWlU3IAXoIaDmNA0ksabbyvI+vNFmEF3b+CTmPcNkX2tORuI99vDKcDDLfZdFxmScrOZ5WfX74YNiZ9bWelfNZlSREREWmh+8CHuaDq7zXMmNI1k4wMPFWT9+SInJlKa2WlAFXBji/07AHsDz8fs/jmwO3AAsB1wWStlnmNmM81s5pIlS0Jpd1pOOAGOP77980BBt4iIiLSqdNVS5tN2UoaP6UunVUsLsv58EWbQvQDYMeZ9n8i+zZjZUcAVwHDnXGOLwycDTznnmqI7nHOfOa8RuAc/jGULzrmJzrkq51xVjx490ryVgDnnM5ck2i4F3SIiItKKxq4V9KPtIah9+Zh1XSsKsv58EWbQPQMYaGY7m1lH/DCRzZZeNLP9gDvxAXe8iPJUWgwtifR+Y2YGnAC8E0Lbw1VfD8uWtZ+fOyoanCvoFhERkRaKThvB6JK72zxnTMkkik8fUZD154vQgm7n3AbgPPzQkPeAR51z75rZNWY2PHLajUBX4LFI+r//BeVmthO+p/zlFkX/xcxmA7OBCuDasO4hNIkuihNVUgJ//SucfHJ4bRIREZG8VHrxeYwtuYtqXot7vJrXGFMyidKLzi3I+vNFaCkDc0nOpQw8/3y45x748ksoLs52a0RERCTfTZ3K6pPOYELjWUzY+GM+pi99+ZgxJZMYUzKJLo/f79f9CLv+NWcygTGZrz9HZCtloLTmyCPhl79MLuB+6y146aXQmiQiIiJ5bNgwurxdw/nHfMDs4n1ppBOz2ZvzR671+bHDDniHDaPLc09yPuOZ3emATfWfnaH684B6uvPF974H774Lc+a0f66IiIhs3aZMgYcfhnHjYLvtMlNnUxO8/jr07QtlZdCpk9+2Im31dHfIdGO2ekuW+GElAwa0v/x7rMpKePHF8NolIiIiheMb3/BbJpWUQHV1ZuvMIxpekml/+QsMHAgLFyZ3XWUlfP65/xYpIiIiEs8hh8Do0f5v53zskCm33775UNjrr4err85c/TlOQXemTZ8OO+4IO+yQ3HU9e/rXpVt3YnkRERFpw9y5UBQJ737wAzj00MzUu2EDXHop/O1vm/a9/rpPHCGAgu7Mq6lJ7aeX6AI5ixYF2x4REREpDOvW+XVAevf27/fYA95/3w9rDds778CaNZunQ66uhvnzFbtEKOjOpMWL4aOPEs/PHeuww+Dll2GXXQJvloiIiBSABZGFv/v08a9Dh/ohJjNmhF93TY1/je1YjMY70fVJtnIKujMp2UVxYvXoAV/9KnTtGmybREREpDA0NPjXaE/3gQf612hAHKbp032sstNOm/btv79Pj5yJ+vOAgu5MOvhgeOIJGDIk+Ws3boSHHoI33gi+XSIiIpL/uneHM8/0CRui73ffPTM9zR984DsVYzOzlZX5tUmKFG6C8nTnD+egtBQuvhh+97tst0ZERETywSOP+F/Jv/WtcOtxDlauhPLycOvJcVqRMhc0N8P48VBXl9r1Zn4ypSYjiIiISDzr1vngN9Ypp4QfcIOPU9oKuLeCTt72KOjOlPfegwsvhGnTUi+jstJPxhQRERFpacSILYewbtwI//2vH/4RlokT4Uc/8h2MLS1e7Ie43HtvePXnCQXdmZLOJMooBd0iIiLSmgUL/GTGWM7BEUf4hWvCMnmyj3Pijd2uqPC/0msypYLujJk+3U9oiE5uSIWCbhEREWlNQ8OmzCVRHTr43u+wgl7nfIzTWqdiUZHPoqKgW0F3xtTU+H+Q6czg/c1v4MUXg2uTiIiIFIamJvjss005umNVV8Obb0JjY/D1fvihXy27rV/yq6v94jmrVgVffx5R0J0Ja9f6FaHSGVoC0K8f9O8fTJtERESkcCxc6Hud4wXdQ4fC+vXw1lvB1xtvUZx49Tc3Q75nkkuTgu5M6NwZPv8cfvKT9Mqpr4c//AGWLAmmXSIiIlIYSkvhiivid/BF94UxxMM52G8/2Guv1s8ZOhR++EPYZpvg688jytOdT6ZOhW98w2dAOeigbLdGRERE8oFz8J//+OBYK1uHSnm6s+3qq2HcuPTLqaz0r5pMKSIiIrGWLfO/qsfrTDWDww4LPuBubk48/7Zz/hf7raCztzUKusPmHNx5J8yYkX5ZCrpFREQknuuv3zJzSay6OrjySh+cB2XGDJ+i8NVX2z/3jjtgl118hpWtlILusDU0+NnE6U6iBAXdIiIiEl80XaBZ/OMLFsC1125aNyQINTU+iN9pp/bPrYqMuAiy/jyjoDts0X9cbc3qTVRpqZ+EoKBbREREYi1YED9zSdSQIT5tcZCTKadP93W21cMetc8+Po7ZioPuDtluQMGbPt3/I9tnn2DKmzMHttsumLJERESkMDQ0wMEHt368a1cYNCjYoLetRXFa6tjRT+TcihfJUU932JyDr33N/2MLQq9e0KlTMGWJiIhI/nOu/Z5u8L+6T5/uJ0Cma8kSmDcvueGz1dXw+ut+IZ+tkILusP3hDz7VX1CefNJPlhAREREB2LgRxo+HE05o+7yhQ/25CxYEU+ell8LRRyd+zZlnwoMPbrUZTJSnO9+MHu0Db43rFhERkWQ0NkKHDlBcnO2WFCzl6c6WiRNh8GD44ovgyqyshKVL/TdMERERkcWL/RLv7Q3bKC0NLuCeMwfWrUv+upkz4bnngmlDnlHQHbT6ehrHXsTa8p40/3gMa9+po/GKq31C+CBUVvqfZYLMsxmk2PsvKmZteU8ax14U3P2LiIjI5p58Evbd14+zbs/48fCDH6RXX3OzXxn7oouSv/aaa1K7rgCEGnSb2XFmNtfM6szs8jjHf2pmc8zsbTP7l5n1izm20cxmRbbJMft3NrPpkTL/amYBzVAMwNSprB5czfhJnRm0chodaWSQm834SWWsHlwdzNjuXM7V3fL+XSODVk5j/KTOwd2/iIiIbK6hwfdg9+zZ/rmLF8Nf/wpr1qRe39y5sGJFamuQVFfD++8HOwogT4QWdJtZMXAbMAzYEzjVzPZscdqbQJVzbjDwOHBDzLG1zrl9I9vwmP2/B252zu0CfAGcHdY9JKW+ntUnncFRaybzs6bfMo8BbKQD8xjAz5p+y1FrJrP6pDPS7/GN/geVaz3dmbp/ERER2dyCBbDDDokNHYlOpnzjjdTri6b9SyXojl4TxErdeSbMnu4DgTrn3Dzn3HrgEeD42BOcc/92zkW/atUAbea6MTMDvo4P0AHuA9qZqpsZjTfdyu1No6jhoLjHaziICU0jabz5tvQqOuQQWL8eDj88vXIClrH7FxERkc01NLSfLjAqGvSmk697+nS/WN9uuyV/7QEH+FUzt8JFcsIMunsDn8S8b4jsa83ZQOz4g05mNtPMaswsGlhvDyx3zm1IsMyMaX7wIe5oarvTfULTSDY+8FB6FXXoACUl6ZURgozdv4iIiGwuugR8Iior/bLt6SxSM306HHigX+EyWeXlsMceW2XQnRMrUprZaUAVENt92885t8DM+gMvmtls4MskyjwHOAegb9++QTY3rtJVS5lPvzbP+Zi+dFq1NP3KLrzQj4k69dT0ywpIRu9fRERENhk/Hrp0Sfz873wnvSxot9yS+rUAf/tb4l8SCkiYQfcCYMeY930i+zZjZkcBVwCHO+cao/udcwsir/PM7CVgP+AJoLuZdYj0dsctM3LdRGAi+DzdQdxQWxq7VtBv5XzmMaDVc/ryMeu6VlCWbmWPPuonQORQ0J3R+xcREZFNklmgBuCPf0yvvkMPTe/6gQPTuz5PhTm8ZAYwMJJtpCNwCjA59gQz2w+4ExjunFscs39bMyuN/F0BHALMcX4ln38DJ0VOPRP4e4j3kLCi00YwuuTuNs8ZUzKJ4tNHpF9ZZWXOZS/J6P2LiIiIt2wZPPMMfP558temshz7K6/A00+nt6rkqlXwi1/Av/6Vehl5KLSgO9ITfR7wPPAe8Khz7l0zu8bMotlIbgS6Ao+1SA24BzDTzN7CB9nXO+fmRI5dBvzUzOrwY7zbjvQypPTi8xhbchfVvBb3eDWvMaZkEqUXnZt+ZT175lzQndH7FxEREe/11+Hb34Z33038mo0boX9/uPLK5Ov705/gJz/xkyFT1amTHxLz95zoN82YUMd0O+emAFNa7PtVzN9HtXLdNGDvVo7Nw2dGyS0DBtDl8ft54aThTGgayYSmkXxMX/ryMWNKJjGmZBJdHr8fBrQ+/CJhlZW5l3ov9v7Xn82EDaPCu38RERHxFkRG2SaavQR8asGKitQmU06fnn4GtQ4doKpqq5tMqRUpgzRsGF3eruH8cxqZXX4IjUWdmV1+COef00iXt2tg2LBg6unVK71vmGGJ3v+wOmazN40W0v2LiIiI19DgX3v1Su666mq/JHsyEyobGnyQn0p+7paGDoU330xtKfk8paA7aAMGUHrrHyn7ciFFGzdQ9uVCSm/9Y7A9vDfcAHV1wZUXpAEDKD32a5SxlqLZb1E27V/B37+IiIh4DQ3QoweUliZ33dChsHp1csNSoj3TQQTd1dV+TPmsWemXlScUdEvwamt96qI774SD4i+WIyIiIgFIZmGcWKkskvPGG9CxI+y7b/L1xau/e3f49NP0y8oTCrrz0dtvwwknJPftNJOuvx7eegt23BFWroQVK7LdIhERkcJ0880wcWLy1w0YAJdcAoMGJX7Nb34Dc+cm36seT69ePvPKd7+bfll5QkF3Plq3zs/4/fDDbLckvk6d/H/M0W/eC+KmUhcREZF07bqrn5SYLDO48cbkfpEuKvKrWQYllRUt89jWdbeForLSv+ZY2kAANmyAiy/2P1dFg+7oJA8REREJTmMj3HEHfPBBatdv2OAnM65Z0/65778Po0YFmz3t+edh771zM54JgYLufNSjh3/NxX+k8+f7la7mzNm0xKuCbhERkeA1NMCYMTBtWmrXv/gi7L8/vBZ/jY3NvPwyTJqUWj2tKSuDd97ZalIHKujOR126+C0Xg+7aWv+6yy6+p/vuu+Gww7LbJhERkUIU7dRKZSIlwIGRZU8SCXpranxu7/79U6srniFDfM7wrSToDnVxHAnRfvv5b4i5Jhp0DxzoZzj/6EfZbY+IiEihis6Ziv6ynKzu3WG33RILeqdP9xlHglwnpKwMBg9W0C057pVXst2C+GproWtXv1Q9+GEmX36p1IEiIiJBS7enG3y+7KlTwbnWA+ovv/RjukeMSL2e1gwdCg89BM3NBT+xsrDvTjJv8WLfyx39D/eyy/x4MxEREQnWggXQrZvfUjV0qH92z5/f+jkNDX5YSXV16vW05thj4Vvf8imGC5w557LdhtBVVVW5mTNnZrsZwRo/HqZMgeeey3ZLttTYuCmH5+jR8MQTsGRJdtskIiJSaL78EhYu9ENEUrVggV/347DDoHPnts9tqzdcADCz151zcXM4anhJvlq0CF54ITd/jolNmt+nDyxd6nOLd+qUvTaJiIgUmm228Vs6evdOfEx4WAG3c/4LRPfu4ZSfI3IsWpOEVVbCxo3wxRfZbskmH30E3/ueXyY2Kvof8la0zKuIiEhG/O538O9/p1/OjBk+21g8zvnJjuPHp19Pa045BY44Irzyc4SC7nyViwvkvPsuPP44rF27aZ8WyBEREQnehg3wy1/6XNvp+utf4dxzYf36LY99+CHMnu0zkoVlt918HatXh1dHDlDQna+i2UFyKeiOTRcYVVXlV5waPDg7bRIRESlECxf6IabpZC6Jqq7287HeemvLY9F0fkOHpl9PW/U3N0Ohzb9rQUF3vurTx6fh65BDw/Lr6qC8fNOKmQDbbgvHHFPw47REREQyKpqjO4igOxpQx8uXXVPjJ1juvXf69bQmmUV68piC7ny1665+2ddDDsl2Szaprd08XWDUlCm5m1dcREQkH0WHbaa6ME6sPn1ghx3iB73Tp/tfrcPs5KuogAEDCj7ozqFuUsl7nTvD/vtvuf+SS2DPPbUcvIiISFCiCQqC6Ok2873ds2Zteezww6Ffv/TraM9VVxX8r+LK053PjjzS/yTzu99luyVtO/pon/S+pibbLRERESkMzsHy5T5QDSKV35IlvqySkvTL2oq1ladbw0vy2eLFMHdutlvRvj59lL1EREQkSGZ+3lRQubN79Ngy4F66NH5GkzBs3OhTF9bVZaa+LFDQnc8qK3Mne8k//+kndtbXb3msTx/47DOf3khERETSd911MGlScOU5BxddtHmZF1zgh4dmwoYNcOihcOedmakvCxR057NcCrpnz/bDR+KNx+rTx6cCWrQo8+0SEREpRHffHczCOFFmPuf3449v2jd9euZS/paWwn77FfRkSgXd+SyXgu7aWv8z1/bbb3nsxBNhzpxNC/qIiIhI6pzzKQODmEQZa+hQH/Q2N/sx3vPm+RzamVJd7XN1F+gv4wq681lVlZ+k2Nyc7Zb4MVixi+LEqqiAPfbQ5AwREZEgRMdaB5EuMFZ1tZ+cWVsL//2v3xfmojgtDR3qV7WePTtzdWaQgu58dvrp8NhjUJQD/zfW1sIuu8Q/1tQEt9wCr76a2TaJiIgUomhygjB6usH3dtfU+PhiyJSLXpAAACAASURBVJBg62hLtFe9QIeYKE+3pM85/x/loYfGP96hA1x6qZ+QkUuL+YiIiOSjL76ALl2CD7r32AN23x3WrYPvfAd23BG6dg22jrbstJMfV14VN+Ne3suBLlJJ2axZfujG889ntx1m8MQTMGZM68d7985M2sD6ehrHXsTa8p40FxWztrwnjWMvip9VRUREJB99/et+/YsDDgi23A8/pPFrx7H2kitprjqAtZdcmdln6Lx5ND42mbW9d0ntGZ7jMUCoQbeZHWdmc82szswuj3P8p2Y2x8zeNrN/mVm/yP59zew1M3s3cuz7Mdfca2YfmtmsyLZvmPeQ07p1g2XLYOHC7LYjkQWW+vTxkz7CNHUqqwdXM35SZwatnEZH18igldMYP6kzqwdXw9Sp4dYvIiKSKWbB5eiG7D9Do/Xf1Sm1+rPd/kQ450LZgGKgHugPdATeAvZscc7XgLLI32OAv0b+3hUYGPm7F/AZ0D3y/l7gpGTaMmTIEFeQVqxwDpy74YbstuMPf3CuVy/nVq1q/ZxTT3Wuf//w2lBX51aVVbhqpjn/LWDzrZppblVZhXN1deG1QUREJBN+/3vnLroouPKy/QxNt/5stz8GMNO1Eo+G2dN9IFDnnJvnnFsPPAIc3yLg/7dzbk3kbQ3QJ7L/A+dcbeTvT4HFQI8Q25qfunaFzp2znzbwgw+gsdGPL2tNdFXKRHrFU9B4063c3jSKGg6Ke7yGg5jQNJLGm28LpX4REZGM+ec/Ydq0wIrL9jM0sfrPpvHaG/2v+7FbY2Pk+pE5HwOEGXT3Bj6Jed8Q2deas4Et+v7N7EB8T3nsgJzrIsNObjaz0iAam5fMciNXd21t6+kCo37xC5/iKMifwmI0P/gQdzSd3eY5E5pGsvGBh0KpX0REJGMaGgKdRJntZ2hi9Y9i4733ww47bL69+GLk+pHtXJ/9GCAnspeY2WlAFXB4i/07AA8AZzrnosmofw4sxAfiE4HLgGvilHkOcA5A3759Q2t71p12mp9dnE21tfC1r7V9TryVKgNUumop8+nX5jkf05dOq5aG2g4REZHQLVgAxxwTWHHZfoYmXL+th9snbH5gr72y3v5EhRl0LwBio8E+kX2bMbOjgCuAw51zjTH7y4FngSucczXR/c65zyJ/NprZPcAl8Sp3zk3EB+VUVVWFM6YhF1x7bXbrX7PGf+NuLUd31KJF8Mc/wve/D/vvH3gzGrtW0G/lfOYxoNVz+vIx67pWUBZ47SIiIhmyYoXPXBJgT3e2n6EJ19+tgrLRo1O/PssxQJjDS2YAA81sZzPrCJwCTI49wcz2A+4EhjvnFsfs7wg8BdzvnHu8xTU7RF4NOAF4J8R7yA+Nje2fE5Z16+C88+CrX237vA0b4IYbNq1wFbCi00YwuuTuNs8ZUzKJ4tNHhFK/iIhIRixfDrvtBv37B1Zktp+h6daf7fYnrLUZlkFswDeAD/Djsa+I7LsGH2QDvAAsAmZFtsmR/acBTTH7ZwH7Ro69CMzGB9sPAl3ba0fBZi9xzrkrr3SupMS55uZst6RtTU3OFRU598tfhlN+Ds1cFhERySvZfoYqe0kgAf0U59yuzrkBzrnrIvt+5ZybHPn7KOdcT+fcvpFteGT/g865kpj9+zrnZkWOfd05t7dzbpBz7jTn3Kow7yHnde/ul1n/8svs1P/ll77+9nTo4Cc8hLVAzoABdHn8fl4oG86NHS6nP/V0oIn+1HNjyc95oWw4XR6/Hwa0/tOTiIjIVin2GVry88w/Q9OtP9vtT5BWpMx3lZX+NVsZTC65BPq1PXnhf3r3DneBnGHD6PJ2DecPn89s9qaRTszufCDnn9NIl7drYNiw8OoWERHJhAkTfPKCjRuDLTf6DD2nkdnlh9BY1JnZ5Ydk7hmabv3Zbn8CzIWUNzmXVFVVuZkzZ2a7GeH4xz/g2GPhlVfg0EMzX/8RR/ie7ldfbf/cE0+ETz4JbVz3/9x3H/zwhzB3Luy6a7h1iYiIZNLo0fDEE7BkSbZbInGY2evOuap4x9TTne+y3dOdSI7uqEceCT/gBjj6aHj8cT+c5ZVXwl9+XkREJFMCztEtmaOgO9/17euHeAQ4izlhq1fDp58mHnSXlITbnqhevXyv+vLlPqvK009npl4REZGwLVigoDtPKejOd9ttBzfeCPvum/m66+r8a6JB95tvwogR8NFHoTUJ8L3cb73lx5B36uR740VERApBQ4N/vkneUdBdCFauhGXLMl9vRQVcfz0ceGBi569cCQ8/vClYD4NzcNZZcPfdUFTkF+1R0C0iIoVg40bYbz+/Sd5pc0VKMysGfu+ci7vqo+SIAw+EQYPgsccyW2/v3nDZZcmdD+GlDQQ/tn3Vqk297wMHwnvvhVefiIhIphQX+wQKkpfa7Ol2zm0EspASQ5JSWZmdiZTvv5/cJMVMBN3RXu3osvQDB8K8ecGnVhIRERFJQiLDS940s8lmdrqZfTe6hd4ySVy2gu5zzoFTTkn8/E6d/JCUTATd0Z7ukSPhxRfDq09ERCRTHn/cdyrNn5/tlkgK2hxeEtEJWAZ8PWafA54MpUWSvJ49sxNY1tYmn2x+r738z2Nhqa31q1/utJN/P3Bg4hM9RUREctmHH0J9vU+iIHmn3aDbOXdWJhoiaaishM8/94vUZCot38qVsHBh8gHtSy+F0pz/uewy+P73feANsGGDH+s+cCBUxc1VLyIikh8aGqC8HLp1y3ZLJAXtDi8xsz5m9pSZLY5sT5iZEkTmkmOPhZtvzuy45WTTBWbKNtvAPvtsel9c7IeY/OUv2WuTiIhIEJQuMK8lMqb7HmAy0CuyPR3ZJ7li6FD4yU/8mOlMaTl2OlFPPgmHHQbr1gXfJufg17/efNVLM6UNFBGRwqCFcfJaIkF3D+fcPc65DZHtXqBHyO2SZKxf7zOJfPFF5uo85BDfe7zrrsld9+WX8J//+JUsg/bZZ3DNNTBjxub7Bw5U0C0iIvnvsMP8r9uSlxIJupeZ2WlmVhzZTsNPrJRcMX8+7LEHPPts5urs3duvLtm5c3LXRb+hJ5NqMFGt9b5H0wZu2BB8nSIiIply441w8cXZboWkKJGg+0fAycBC4DPgJECTK3NJZaV/zWTawGefhdmzk78uGnSHkTawraB7wwalWBIRkfzV3OyHUUreajPojqxI+Vvn3HDnXA/nXKVz7gTn3McZap8korwcOnbMbND9ox/BuHHJXxedABJGT3ddnf/foW/fzfd/97s+4N555+DrFBERyYQZM/yvy1p7Im+1mTLQObfRzPqZWUfn3PpMNUqSZJbZBXJWrPB1pZK5pLzcT/zs2jX4ds2fD/37b5kHvHt3v4mIiOSrBQugsVE5uvNYIovjzANeNbPJwOroTufcH0NrlSSvshIWLcpMXalmLomqqQmuLbEeeshP1Izn1lv9apjJrKApIiKSK6LDMpW9JG8lEnTXR7YiQNnYc9VVV0FZWWbqSjfoDotZ6z3af/6zX7lTQbeIiOSjhgYoLYXtt892SyRFbQbdkTHduzrnfpCh9kiqvv3tzNUVXRhnwIDUrv/tb+GZZ2DatODatGiRX43y/PNhyJAtjw8cCG+8EVx9IiIimbRggZ8XZZbtlkiK2pxI6ZzbCPQzs44Zao+k6tNP4YUXMjOzeexYeO211HvW1671C9gEuYLme+/Bffe1nqt84ED48ENoagquThERkUw56igYNSrbrZA0aEx3ofjLX+BnP/OTHLuFPApou+2gujr163v39gH3okXQq1cwbWpvyMsuu/g6P/oo94bFiIiItOcsZWvOd4nk6a4HnmHTmO7oJrkkk7m6//CHLVd9TEYYubpra/1Ytx13jH984ECf1eSTT4KrU0REJBOcgyVLlKc7z7Xb0+2cu7rlPjNLpIdcMik26E51rHUili+HSy+FG26AAw5IrYxoru6GBjjwwGDaVVvr0wUWtfI9cuhQWLPG5/EWERHJJ8uW+ef8uHFwwQXZbo2kqNWebjP7T8zfD7Q4/N/QWiSp6dnTv4bd0x1E5pK+fWHYMNhmm2DaBH7oyF57tX68QwcF3CIikp+ivwxHO60kL7XVY90l5u9BLY5p6myuydTwkiCC7u23hylTgmlP1OTJ7f/sdtNNfqLltdcGW7eIiEiYlKO7ILQ1ptu18ne895JtPXvC3/4Gxx0Xbj11dT5dURBDWIIem9ZeGqWZM+Hhh4OtU0QkVn09jWMvYm15T5qLillb3pPGsRdBfX22W5YZ2b7/Qq1/wQL/qqA7r7UVdHc3s++Y2YmRv78b2U4EEhoXYGbHmdlcM6szs8vjHP+pmc0xs7fN7F9m1i/m2JlmVhvZzozZP8TMZkfKHG+mhJUAlJTA8ce3PpEwKPX1vo5OndIr53vfg2OOCaZN06bBkUfC3LltnzdwoM9esn59MPWKiMSaOpXVg6sZP6kzg1ZOo6NrZNDKaYyf1JnVg6th6tRstzBc2b7/Qq6/ocHPWYoOJZX85JyLuwH3tLW1dl3M9cX4zCf9gY7AW8CeLc75GlAW+XsM8NfI39vhUxVuB2wb+XvbyLH/AtX4IS5TgWHttWXIkCFuq/Dyy8699FK4dWzY4NzChemXc+qpzg0YkH45zjk3YYJz4Nz8+W2fd999/rz33w+mXhGRqLo6t6qswlUzzfmf8TbfqpnmVpVVOFdXl+2WhiPb91/o9b/0knO//32wbZZQADNdK/Foqz3dzrmz2toSiOcPBOqcc/Occ+uBR4DjW9Txb+fcmsjbGiD6u8mxwD+dc587574A/gkcZ2Y7AOXOuZrIjd0PnJBAW7YOv/gFXL1FsplgFRcH8027d2//zT2IISa1tb7nvb2f3aLj0KPj0kVEAtJ4063c3jSKGg6Ke7yGg5jQNJLGm2/LcMsyI9v3X/D1H364X4tD8loiebpT1RuITYrcENnXmrPxPddtXds78neiZW5dKivDnUi5fDn8+Md+bHS6+vSBxkafBildtbV+jHlr6QKjBg70i/GsWdP2eSIiSWp+8CHuaDq7zXMmNI1k4wMPZahFmZXt+y/4+ufMaX3FZckbYQbdCTOz04Aq4MYAyzzHzGaa2cwlS5YEVWxuCzvonjsXJk70S86nK9orHZ0cko66usSyqVRU+PpOPjn9OkVEYpSuWsp8+rV5zsf0pdOqpRlqUWZl+/4Lvv7qarjqqtSulZwRZtC9AIid1dcnsm8zZnYUcAUw3DnX2M61C9g0BKXVMgGccxOdc1XOuaoePXqkfBN5pbISli71OavDEES6wKi99oJRo6CsLP2yBgyAg+L/pCcikgmNXSvox/w2z+nLx6zrWpGhFmVWtu+/oOtfsQJWrlTmkgKQUNBtZgeb2QgzOyO6JXDZDGCgme1sZh2BU4DJLcrdD7gTH3DHdtE+DxxjZtua2bbAMcDzzrnPgBVmVh3JWnIG8PdE7mGrUFnpx0gHMWQjntpaP4Sjf//0y9p9d99rHkQA//TTiY91+9Of4Nhj069TRCRG0WkjGF1yd5vnjCmZRPHpIzLUoszK9v0XdP1KF1gw2g26I6tR/gE4FDggslW1d51zbgNwHj6Afg941Dn3rpldY2bDI6fdCHQFHjOzWWY2OXLt58Bv8IH7DOCayD6AscAkoA6fHaXAczAl4cQTYcYM6N49nPJra/1qkqWlwZS3cSOsXh1MWYlavhz++U9Yty6z9YpIQSu9+DzGltxFNa/FPV7Na4wpmUTpRedmuGWZke37L+j6o0G3VqPMf62lNYlu+IDZ2jsvl7etJmVg2IYPd+6444Irr18/5846K70yJk50btddnVu2LLHzH3zQ529699306hURaWnKFLeqrMLdWHK560+d68B61586d6Nd4tPFTZmS7RaGa8oUt6rTdu7G4kuzc/8PP+xWUeZutEuyU/+jj8avnzTrv+ce/9yqrw+0uRIO2kgZ2NYy8FHvAF8BPgsx9pcgrFoFjzzixzfvtVfw5f/979DcHFx5PXtuWto2VXPm+DK23Tax82PTBu65Z3p1i4jEGjaMLm/XcP5ZP2bsG5PotPYL1hV3obi5idKX/w+q2v2ROL8NG0aXd/7L+TffxtgHDqHTqqWs69CN4vVrKJ3yD5/2LkxHHkmXkSM4f81Sxj4Tqb+kG8WNqyl96pngFmRrzSef0IU1nH/SZ4x9PlJ/520pPvEESn9Vk/pKzoceCnfdpZ7uApDImO4KYI6ZPW9mk6Nb2A2TFDQ2+smJL7wQXh3tpeVLRp8+6Wcvqa2FXXZpfwn4KOXqFpEw9e5N6X9epOyScynauIGyN16ldONa+Ne/st2ycK1dC2PGQFMTpbf+kbIvF/r7r59NafFGeOaZ8NvQowfcdRelf7lnU/0fz6X0puth6NDw6992Wzj1VEoffXBT/auWUHrfXakH3OCfcSNHBje0U7ImkQjqKvwCNL8FborZJNdsu61fvCaMtIGzZsE3v+l7loPSp0/6Pd2JpguM2nZb39ux3Xbp1SsiEs+HH/oJ7dHPpUGD4Mgj4bbbYMOG7LYtTA8/DHfcAQsXbr6/Tx+44orwg96XX4bnn99ywbXKSvjpT2GbbcKtH+Css+ChOHm4337bPz9TfTb/97/w3nvptU1yQrtBt3Pu5XhbJhonSSoq8t/0wwi6334bpkzxQX1QevfelAopFRs2wLx5vhcgGc8/Dz/6UWp1ioi0JforWuzn0gUX+EW53n8/O20Km3MwbhwMHhx/CMnVV8NJJ4Xbhssug/PPj7/KsXNw773+i0FYnnsO1q+Pf6xjR//8nDgxtbJHj9ZqlAUikewl1WY2w8xWmdl6M9toZisy0ThJQc+e4QTd0XSBO+8cXJlHHAHXXJP6UvBr1sBpp8FhhyV/bRDLz4uItBRvPYNvfhM++cT3eheil1/2HTMXXND6UL/PP/c94WF89k6f7rfzz48/BNIM/vxn+MUvwlnH4u23Ydgw/2tGPLvv7lPV3n5764F5WxoaNJ67QCQyvORW4FSgFugMjARa+ZclWRfWqpS1tbDTTv4be1AOPBCuvBLKy1O7vrzcf5B+85vJXTdxoh9esnZtavWKiLSmrs5/vsQOYSsuhs6d/UT0L7/MXtvCMm4cbL89jGgjB/Wzz/ox3//8Z/D1jx8P3brBD3/Y+jkXXggffeTXdQjaLbf4/3/PPLP1cy64AD77DB5/PLmy162DJUuUo7tAJDQrzjlXBxQ75zY65+4Bjgu3WZKyu+/2WUaCVlsbzEI2sZzzS8qnupjP2rWp9Zp06+bzddfXp1aviEhrbrnF93y21NwMQ4b44KuQOOeH0lx8sQ88W3Pyyf6X2HHjgq3/00/h0Uf9kMFu3Vo/7/jj/ToT48cHW//SpfDgg3D66W3PFTruONh11+Tr//RT/6qe7oKQSNC9JrKi5Cwzu8HMLkrwOsmGHXf0vd1B22EH3zMdpMZG/0Fyxx2pXX/55b5dyQbe0S8PdXWp1Ssi0poOHeIHSEVFcMghPq3rokWZb1dYzODGG+HnP2/7vNJSPzZ5yhT44IPg6q+rg169/NCStnToAOeeC//+d/wvRamaNMn3RrdXf1ER/OpXfhG7ZIa4aDXKgpJI8Hx65LzzgNXAjsCJYTZK0vDGG3DVVcEPnXjmGT/+OkidOkFFReoZTGprfdCdaLrAKKUNFJEwrF0LY8dCTU384+ef78f03nlnZtsVllWrfIraRDs+Ro+GkhK49dbg2vDVr/qMMYmk5Bs5Eg4+2E/gD8r//Z/PTpPIeP0f/AAuvTS5hASDBvlJmkOGpN5GyRmJZC+ZDxiwg3PuaufcTyPDTSQXvfWWnymeLz0pvXunnqs71SEv22zjs7wo6BaRINXXw4QJPgiMZ7fd/IS7CRNSm1CXax54AI4+GmbOTOz8r3wFTj3VD5kIYkLlRx9BU1Pi60dstx28+qpfbCYozz4Ljz2W+PmNjf5/t+iwkfZsu62fhKk0twUhkewl3wZmAc9F3u+rxXFyWHRoSZCTKR9+2KeCapl/NQip5upuavIPtlTHmY8aFfxwGRHZusXLXNLSBRf4z9KnnspMm8LS3OzHJ1dVJbfS5t13+8mEyf5C2ZJz8N3vwje+kfy1y5f73NfpWrPG30eiKyKD72Q680z/xSsR//kPTJ2aWvsk5yS6OM6BwHIA59wsIMC8cRKoMILud97xi+Jsv31wZUb17p1a0P3RR35cXLI5uqOuu87/1CgiEpR4ObpbOuYYP1zvxDwfpfnCCz7v+IUXJhdAd+jgXxsa0kvf9+qr8Oab8L3vJX/t6af7gL2pKfX6X3/d99y/9FJy1/XvD9/+th9itG5d++f/6U9+cR8pCIkE3U3OuZY5jpTkOFdFg+4gh5fU1vr83CUlwZUZddppfhJOsj81duniJ6UcdFDqda9YUdgrxIlIZtXW+nkq3bu3fk5RkU9zGg0+89W4cT4bSSpB77RpPgVtOj2448b5HubTTkv+2nPO8T3O6fzaMG6cf27tt1/y115wgU8D+Mgj7Z/b0KBJlAUkkaD7XTMbARSb2UAzuwWYFnK7JFU9evjXIHu6w0gXGHXYYf6ntmR/auzVy49d33331Op98kk/tjvIZe1FZOu2YoUft52Im27K3/SBK1f6+UNjxvisJMk64ADfS5xq+sCPP/YB86hRUFaW/PXf/KafeJlq/QsX+oD5hz9MbXn5r38d9tprU+DeFgXdBSWRoPt8YC+gEXgYWAH8JMxGSRrKynze0MsuC6Y858INuteu9WPrli5N7rr58/0KZ6naaSf/qsmUIhKUv/7Vr86YiE8/9eN6U51Ink3dusG8eXDJJaldX1Li0/e98AK8+27y10d7iM89N7X6i4rgvPN8j3uik0Bj3XmnH5rSXprA1pj5L1wbNrT97NuwwQf4CroLRiLZS9Y4565wzh3gnKuK/J3AQCTJmu23T3w2d3vWrvWLCqSy1HoiPvwQhg5NfpWyH//Yz5pPVXTMpYJuEQlSoungzjvPj2m+/fZw2xO0det8MNixox/ml6pRo3za2FtuSf7aSy/1Y6r79k29/rPO8l8eXnghueuamvyXpWHD/GI3qTr7bJ8vPPrrdDyLFvl/I1oYp2C0OqisvQwlzrnhwTdHAjFxos+fGsTki7Iy+Mtf0i+nNdFv8Mn29tTW+p8oU1Ve7se/K+gWkSDMnetXZbz2Wth33/bP33lnGD7c95r+8pdtr+aYS+64ww+NefNNP349VRUVPm/1ww/DzTcnfv/O+Z7iffZJvW7ww0Lq6pJfTK6kxI9FT7djK/rlLDq3KF5KwMpKn8ggjAXvJCva+ldzENAHeAX4A3BTi01y1bPPwn33BVNWU1Mw+VRbU14OXbsml8Fk/XqfvSTdIS8DB2pVShEJxjvv+M/e5ubEr7nwQli2zAee+WDjRt8z3a9fegF31K9/7YeXJBNwH3ZYar3j8USD2USyiMTab7/0g37wnWM77QS//3384yUlfux3W73hklfaCrq/AvwCGASMA44GljrnXnbOJThoTbKisjK4iZRXXulXfUzmQZKsZHN1f/ihb0+6Qfe55yptoIgEI5Ec3S0dcYQPvBNZzTAXTJnix3IHNQF0xx2TG6/84os+VWC3bsHUD77Xftdd/aI17ampgTPOCG7Niq5d/WqWd93lc3639OqrfvXOdFIbSk5pNeh2zm10zj3nnDsTqAbqgJfM7LyMtU5SU1np0xEFESjX1fn0V0GNEY8n2aA7lYdbPKee6vO1ioikq67Op9BLJiA083mY82WhrnHj/Of1d74TXJmLFvn5OU88kVj9PXrAKacEV//ee8Mnn8Cjj7Z/7p/+BJMn+2A5KBdeCF98AQ8+uOWxv//dD1nK9/SS8j9tRlJmVmpm3wUeBM4FxgN5vozWVqBnT/8z4BdfpF9WmJlLon79a9/bkKh99vHj1vfaK716m5p8ysDly9MrR0Qknc/K2lqYNCnY9gTtvffgX/+CsWODXbOhosJ/YWkvfV99vV9UaPRoPwEzKEcf7VPPtpe+r6HBr6Q5cmSwQfchh/jhKuPHb1n/ggV+EmW6q3dKzmg16Daz+4HXgP2BqyPZS37jnMvD/EZbmcpKnzt12bL0ynHOfximuupjog491H/wJGrHHf3M9/Ly9Op9910fuCebOUVEpKXtt0+9x/qee3xGpo8+CrRJgdptNz+8ZNSoYMstLvaZXF55xU/ObM2tt/pzR48Otv5o+r7XX4fXXmv9vAkT/DPxvIB/7Dfzvd3vvgszZmx+TDm6C05bPd2nAQOBC4FpZrYisq00sxWZaZ6k5OSTfaq/dNIZgc8ju2ZN+D3dCxf6nxZXJPjP6pVX4IMP0q9XaQNFJChPPpncL3axxozxwddttwXbpiAVFfk0eUFMoGzp7LN9pqzx41s/5/TT/QTKXr2Cr/+MM3w2k9bqX7vWZ5kZPnzTGg9BOuUU/4Wj5Ze2BQsUdBeYtsZ0FznnukW28pitm3MuzS5GCVVRUTA/RxUX+0V2Dj44/bLaMmMGnHQSvP9+YuefcQZcdVX69Xbt6ieJKugWkWzacUc48UQ/xGT16my3Zku33+6fBRs3hlN+9+5+ZeKHHmo9CcD++wffyx3VpYtPjdtaFpHGRt++iy8Op/7S0i3TTDrne7qVo7ughDg7TrJmzRq/PO3TT6dXzle+Atdfn1jO2XREv8knMpmysdEvARxU77vSBopIup5+2n9OpjM85IIL/PySBx4IrFmB2LDBPwdmzEh84Z9UXHghXHfdlukDm5t9wD9nTnh1g18avl+/+Me6d/e/Yhx6aHj1O+d7/KOrSZv5LyC/+EV4dUrGKeguRKWlcP/9W44PS9bChT6PaNii3+QTWSBn3rxg0gVG7bKLerpFJD3vvANvveXHdafq4IN9UBdUuteg/O1vPrtHUGkCW7Pbbn5Z+ZbZX557Dm64wf/vG7aZMzcNz4yaNcvP+wlznhVWIAAAIABJREFUvQrwQfa6dX7seHSoZXk5bLttuPVKRinoLkTFxX7cXbof3mPHZiaVVUWFX1I4kZ7uoNIFRo0e7XOkhv2BKiKFq7bW/zKYTv5oM3j5ZfjVr4JrVxDGj/erZ3772+HXtXGj7zD6xz82r79XLz8EMWyrVsFjj/lhLlFXX+3Tyya7gE4qLrwQVq70i9vNmgWXX+5TKkrBUNBdaOrraRx7EWuXraH5zomsLe9J49iLfLqlZK4v70nzU39jbW1DctenoqjIf6gm0tMddNB9wAH+YaKUTCKSqqBSqxYV+c/gH5zlP4OLitP7DA/i+ldm0LhDv8xkVjGDX/+axtNHbqr/+Zdp7NPfDysM2+GHw2670fizKzfV/7fnaOw70CcWCNuBB8I++9D4y9+w9qCv0/z7G1i7y97hP4MlY0INus3sODOba2Z1ZnZ5nONfNbM3zGyDmZ0Us/9rZjYrZltnZidEjt1rZh/GHAt5wHEemTqV1YOrGT+pM4Oa36Ij6xm0chrjJ3Vm9eBqmDo18etXTvPXb3gz8evT8dhjfjxfe37wA3j+edhuu2DqXb/el6chJiKSqqCC7qlTWb1nFeMf2t5/BrvG9D7Dg7iedxg/ozr8ZwDA88+z+tPljF988ub1v3FoZup/7jlWf7iI8Z+P2Lz+2Udkpv6pU1n9/seMX3EGg9bN8M/gVa9l5hksmeGcC2UDioF6oD/QEXgL2LPFOTsBg4H7gZNaKWc74HOgLPL+3tbObW0bMmSIK3h1dW5VWYWrZprzYyU236qZ5laVVThXVxfO9flq9Wp/g7/5TbZbIiL5qKnJue9/37l7702vnGx/hmf7GaD6t85ncAECZrpW4tEwe7oPBOqcc/Occ+uBR4DjWwT8Hznn3gbaWq/8JGCqc25NeE3Nf4033crtTaOo4aC4x2s4iAlNI2m8OX4e2HSvT9tbb7W/Ihj4lSjbWkAhWWVlfiKnerpFJBUdOsAjj/iUcmnI9md4tp8Bqj/Lz2DJjNai8XQ3fLA8Keb96cCtrZx7L633dL8IfKvFuXOBt4GbgdL22rI19HSv6Vbp+lMX9xtydOtPnVtNZ+ceecRf9H//51ynTs516uTW0Dmx68t7hnMDN9/sK1m6tI2bXOPPueqqYOs+4gjnDjoo2DJFZOuwYUMgxST1GR753HadOjm3cKG/vuM2yV9fVrap/pLyrD4DEr5/1R9K/RIc2ujp7pDRCD9JZrYDsDfwfMzunwML8UNWJgKXAdfEufYc4ByAvn37ht7WbCtdtZT5tJJjNOJj+tKJxk0rVfbu/b80UKU3/CGx61ctDaS9W4jN1d1a2q158/xr0CtkDhwITz0VbJkisnX43e/8r3QNDT5da4qS+gy/4JJNO8vK/PVNK5O/PmYCeemGVVl9BiR8/6o/lPolM8IMuhcAO8a87xPZl4yTgaecc03RHc65zyJ/NprZPcAl8S50zk3EB+VUVVUVfD64xq4V9Fs5n3kMaPWcvnzMuvIelO23n9/Rv///VuBqnHBvYtd3raAs0JZHRIPuBQtgn33inxN05pKoXXaBpUv9whTduwdbtogUttpaH2ynEXBDkp/hcVZOzNj1IT0DVH9265fMCHNM9wxgoJntbGYdgVOAyUmWcSrwcOyOSO83ZmbACcA7AbQ17xWdNoLRJXe3ec6YkkkUnz4ilOvTFl0gp61c3WEF3T/4Abzxhl8WXkQkGQFlLsn2Z3i2nwGqP8vPYMmM1sadBLEB3wA+wGcxuSKy7xpgeOTvA4AGYDWwDHg35tqd8D3jRS3KfBGYjQ+2HwS6tteOrWFMd97PXF+/3rmiIueuvLL1c845x7mKinDqFxFJRY8ezo0alX452f4Mz/YzQPUre0mBoI0x3aEG3bmybRVBt3POTZniVpVVuBtLLnf9qXMdWO/6U+duLLnc/8c6ZUq416errs6n8GvNmjXOzZsXTt1//rNzL7wQTtkiUpiWL/eP0RtuCKa8bH+GZ/sZoPqzW78EQkH31hJ0O+dcXZ1bd+5FbnV5T7exqNitLu/p1p17UeLfjtO9Pl/tuKNzp52W7VaISD5ZutS5Sy5x7rXXgisz25/h2X4GqP6t8xlcQNoKus0fL2xVVVVu5syZ2W6GtOeZZ2DOHPjZz7Y8tmYNXHkljBgBQ4YEX/eRR8Lq1VBTE3zZIiIislUws9edc1XxjoW6DLxIUv7xj9aXgq+vhz/+Eerqwql74EAtkCMiyVmyxHcIiIgkQEG35I4+fWDFCli5cstj0YB4l13CqXvgQPj8c7+JiCTipz+FPfbIditEJE8o6JbcEU0buCBOOvew0gVGRcsNqyddRApPbW14HQEiUnAUdEvuiF2VsqW6OqishPLycOo+6ij/U/EBB4RTvogUnrq68DoCRKTg5PQy8LKViQbdixZteWzx4nAfbmVl/1tOWUSkXV98AcuWKegWkYQp6JbcsfPOPoNIvOD373+HxsZw67/lFiguhrFjw61HRPJf2PNMRKTgaHiJ5I6iorZ7m0tLw61/8mS4995w6xCRwtC7N/zpT1AVNzOYiMgWFHRLbrn5Zrjhhs33zZ0LJ58M77wTbt3RtIFbQe56EUlT795w4YWbJoCLiLRDQbfklhdegEce2Xzf7Nnw2GPQ1BRu3QMHwvLlfpymiEhbZs2CDz/MditEJI8o6Jbc0qfPltlLMjV2MjohSovkiEh7zjnHbyIiCVLQLbmld2+fui920mRtLXzlK9CtW7h1DxwInTv7TCkiIq1xzn8uKXOJiCRB2Uskt0TTBn76qc9mApl7uO26K6xa5Sd0ioi0ZtkyPxRNQbeIJEHRheSWPn1gu+18DtyoLl1gv/3Cr9tMAbeItC/sFXJFpCCpp1tyy9FHbzmR8bnnMlf/uHHw7rswcWLm6hSR/KKgW0RSoG49yS1m2a3//9u78/Cqqnv/4+8vIQECxIEgKjKIOBaRIpqgXh5rq6W2V22lFSgWWwQFHErtgFqvre3t/bXUgQjiABZntDihBQccqi2DxoqIOJBQESkFkauSEAIk6/fH2rmEcJKc5JydfYbP63nOk3P23muv71lnQ75ZZ+21ysrg4Yc1baCINO7MM+HRR/cMgRMRiYOSbkk9P/whlJT45089BUOHwvr1bVN3//7wxRf+Zk4RkVgOOQS+8x3Iy4s6EhFJI0q6JfUsXQqvvuqfr1wJy5b5cd5tQdMGikhz5s+HN9+MOgoRSTNKuiX11J+re80aOPRQfzNlW1DSLSJNcQ7GjYM5c6KORETSjJJuST2HHQYbNvjnbT0Xbt++cPTR0Y8tF5HU9MknfgiabqIUkRbS7CWSenr29PN019T4pPvcc9uu7txceO+9tqtPRNKLZi4RkVZST7eknqOOggED/NSBp5wCp54adUQiIp6SbhFpJSXdknrGjoUVK+Cgg+CJJ+Cii9q2/lmz4PjjNW2giOxrzRrIyfFD0UREWkBJt6SuqJLemhpYtQo2bYqmfhFJXb/4Bbzxhh+KJiLSAkq6JfVs2+aHlRxzDPTuDbt2tW39/fv7n5rBREQaKiiAE06IOgoRSUNKuiX1dO7se5I++MD3drd1j5KmDRSRWJyDX/0KXnst6khEJA0p6ZbUUl5O9WVXUbWrPbUYVRs/o3rSFCgvb7v6p5VQRSdqx42nqqBHy+ovL6d60hSqCnpQ2y4n/conKur6UyWGdBb1NRh1+aZs2gS//jUsX574uUQk64SadJvZcDN738zKzGxqjP3DzOwfZrbbzEY02FdjZiuCx4J62w83s+XBOR82M63DmykWLaJyYDElszsxwK0kj50MqFlByexOVA4shkWL2qb+uzszgLfJo5oB25bEX3/9+LctIc+lWflERV1/qsSQzqK+BqMu3xzNXCIiiXDOhfIAcoByoB+QB7wFHNfgmL7AQOBeYESDfRWNnPcRYGTw/HZgYnOxnHjiiU5SXFmZq8gvdMUscf473L0fxSxxFfmFzpWVpWb96V4+UVHXnyoxpLOor8Goy8djzhx/Ml1DItIIoNQ1ko+G2dN9MlDmnFvrnNsJzAP2WuXEOfehc24lUBvPCc3MgDOA+cGme4DzkheyRKX6xhnctms8yxgac/8yhjJr18VU3zwzJetP9/KJirr+VIkhnUV9DUZdPi5r1kD79tCnT+vPISLZq7FsPNEHMAKYXe/1hcCMRo6dy7493buBUmAZcF6wrRCfyNcd0wtY1Vws6ulOfdu7HuT6URazh6ru0Y8yV1nQI9r6u3T3BWbOdO7gg//vsd3yWxb/f/1XYuUvuSSx8lG1X0j1p0oM6axF7XfssXtdf+7gg9323IL4yzco6w4+2G3vsH+c/wYPil2+4wHhf/6jRzt31FHJa3QRyTg00dOdysvA93HObTCzfsCLZvY28Hm8hc1sAjABoHfv3iGFKMnSoWIL62i69+gjetOxYku09Vdu9S/694dzztlT/s7Z8ZXfFsQ/YEDryte9/xNP9HlEa8snWdSfX6rEkM5a1H7DR0Nl5d7lW3INjhy3b/13xVm+8lMYnUD5RD7/+++Hz+P+NSQisrfGsvFEH8BQ4Nl6r68Grm7k2Lk06OmOtR8wYAvQPlYdjT3U0536ou6lTLT+dC+fqKjrT5UY0lnU12DU5UVEkoGIxnS/DhwZzDaSB4wEFjRTBgAzO8DMOgTPC4FTgdXBm3kJn4ADjAWeTHrk0ubajRnNpblzmjxmYu5sci4cnZL1p3v5REVdf6rEkM6ivgajLt+szZth7Fi/hoCISGs0lo0n4wGcDXyAn8Xk2mDbDcA5wfOTgI+BSuBT4J1g+ynA2/gZT94GxtU7Zz/gNaAM+DPQobk41NOdBqKeeSLqmROiLp+oqOtPlRjSWdTXYNTlm/Pyy/5Ezz3XuvIikhVooqc71KQ7VR5KutPEwoWuIr/QTcud6vpR5tqz0/WjzE3Lnep/WS5cmNr1p3v5RC1c6Co6HOCmcVWD+n/hKjp1C7/+uhiibIN0d8stroJOblq7n6XnNRzm53/XXf5X5tq1rT+HiGQ8Jd1KutNHWZnbMXmKqyzo4Wra5bjKgh5ux+Qpbdc7mWj9qVr+jTfiK5+owYPdjv26711/t0OcO/nktql/wgTnbrxxTxtgrrLD/m17DaWzMWOc69zZ7bh4cupdw60t37nQ7eh3jHPvvBNf+cb8/OfO5eU5t3t3YucRkYzWVNJtfn9mGzJkiCstLY06DJFoPPYYjBoFK1fC0UeHV09pKZx0EkyfDldcsWf7H/8IP/sZvPkmDBoUXv2rVsHxx8P//A9MDRbAHTwYDjwQFi8Or95MsXGjn3964kT/GWaKxYvhzDPhT3+Ciy5q/XnOPx9Wr4Z3301aaCKSeczsDefckFj7Ql0GXkRSwKmn+p+33hpuPdOnQ9eu+yY248ZBfn749d96K3TsCOPH79lWXAyvvQY1NeHWnQluvx1274bLL486kuT66lfhS1/y12cinUw1NX6qTxGRVlLSLZLpevSAkSNh7tzw5hjeuBEefhh++EMoKNh73wEH+FkfHngAPvkknPq3boX77oMxY6Bbtz3bi4pg2zZ4771w6s0kX/4y/PSnfg76TGLmv3lZsQL+9rfWn+eJJ+DPf05eXCKSdZR0i2SDK67wi5ncfXc4599vv32HldR3+eVQXQ1PPx1O/XfdBVVV+9Z/+unw29/C/vuHU28mOe88+MMfoo4iHGPG+D/+MmnYjIikHSXdItngxBP9MJPbbkvsK/bG5Of7scBHHBF7/7HHwgcf+J7wMAwcCFOm+DHd9fXpA9deCz17hlNvJnAO5szx3xZkqvx8uO46OO201pVftswPU9E3JiKSgFReBl5EkmnGDN/ja5bc8z79NKxf78dSt2/iv5Qjj/Q/a2uhXZL/3v/GN/wjlq1b/U2Ww4Ylt85MsWQJXHwx7NoFl14adTThmTKl9WVXroQXX4ROnZIXj4hkHfV0i2SLQYOgb9/kntM5+NWv/E2MOTnNH3/ddXDGGcmN4e67YdOmxvffcgt85StQUZHcejPF9On+j7ELL4w6kvDt2AH33gvbt7es3Jo10KED9OoVTlwikhWUdItkk/JyOPts3/ObDEuW+GWxr7givh707t3hr3/1M4okw5tv+tlRHnig8WOKinzvupbv3tf69X5KyfHjoXPnqKMJX2mpv6n3/vtbVm7NGj90Ktnf0IhIVtH/ICLZZP/94eWXoaQkOecrKWlZL+lFF/lpBZNZf+fO8KMfNX5MUZH/uWxZcurMJHVj/CdPjjqStnHqqX6WlpKSlt3bUFa2Z3iUiEgrKekWySbduvmZHO67Dz79NLFzrV8Pjz7qxwPH20taUOAT5Ece8dMMJmLzZnjwQZ/INzU7SWGh76Vcvjyx+jLRunXw7W/7G06zgRlceSW88w688EL85Y44ws/5LiKSACXdItnmiiv82NbZsxM7z9atPhFpaS/pZZf5RVhuvz2x+u+4A3bujG8xl6Ii39OdBSvwtsiDD8JDD0UdRdu64AI/zKkl37Y8+eSeVU5FRFpJSbdIthkwwE9/NnOmT35b64QT/GIjLb05s39/nzCPHdv6usH3tJ99dnxL2199NSxalFh9mcQ52LDBP8/NjTaWttaxo5+lZcMG/8eniEgbMZcFPT9DhgxxpaWlUYchkjoWL4bXX4cf/7h106CtWOHnvu7ePfmxtcTu3U1PUyixvfginHUWPPdc8meTSQc7d/o/NuK5+XfOHPj972Hp0r1XOxURicHM3nDODYm1Tz3dItnoa1/zvb+tSbid8zdO/ud/JhbD0qV+7uTW/OG/fr3/2ZKEe948ePzxlteViaZP9ys0nnJK1JFEIy/PJ9yff9789IGrV/vr7YAD2iY2EclYSrpFstWuXX48b0unD3z5ZV/mkksSq3/lSj+H9t//3rJyy5b5G/+eeqpl5aZPh5tualmZTLR2rW+7Sy7xQy2y1fr1/tuaOXOaPm7NGj8kStMFikiC9L+ISLbavt3PzzxtWsvKTZ/uZwQZNSqx+seM8bOOTJ/e8vq7doXTT29ZuaIiP1f3rl0tK5dpZszwCxlNnBh1JNHq1cvf33DrrX4e98asWaPpAkUkKZR0i2Sr/fbz0+3Nm9f0io71rV0LCxYkp5e0c2ef9D/+OHz0UXxlNmyA+fP9gjhdu7asvqIiqKpK3sJA6WjnTr8i44gRvpc32115pU+qn3km9v6aGn/NK+kWkSRQ0i2SzS6/3Cdid9wR3/GLF/tx1MnqJZ082Y/pvu22+I6fNcsnQpdd1vK66uZZzuZFcvLy4K234He/izqS1DBiBBx6aOPftmzf7r+RGTasbeMSkYykpFskmx19NAwf7pPZnTubP37ChD1jYZOhTx8/fdshhzR/bE0N3HOPv4GzX7+W19W3r59t5f33W142k/TsCYcfHnUUqSE31/8B+dxz8OGH++7v2tWP+f7mN9s8NBHJPJoyUCTbPfMM/OQnfthI//6NH1ddDR06tF1csWzeDNu2+RUCW+Ozz5pevTKTPfMM/PGP/g8XDS3Z49NP/bClgQP33VdV5a953UQpInHSlIEi0rivf90vi91Uwl1bC1/+Mlx7bTgx7N4NTz/d/PSBBx3U+oQbsjfhBj+EYvXq6OdWTzXdusVOuAGuuQYOPlgrmYpIUijpFsl2Zv5RUQH/+lfsY557Dt59F447LpwY5s3zw0ZefDH2/ldegf/4D39TWyLWr4fvfc+vpJlN3nvP93RPnOjHdcvedu70Y7cbLg2/Zo0f+hTPIjoiIs1Q0i0ifrz08cfDVVfF3j99uu/x++53w6l/xAjfA9sw6alf/+rVPoZEFBT42U9eeimx86SbGTN8sj1hQtSRpKa8PP8H2c03+38LdTRdoIgkkZJuEfHzNn/nOz4h3bBh733vvx9+L2nHjn4awqee2rc3e906eOIJnzDm5ydWz377wbHHwvLliZ0nnXz2Gcyd6+dV79Ej6mhS15VX+pspFyzwr3fv1nSBIpJUSrpFxJs82ffyNZy+r66XNNEVKJszcaJP/mfM2Hv7zJn+6/1Jk5JTT1GRnzYwW8bptm8Pv/61v1lWGnfOOdC7957pA9et84m3km4RSRIl3SLi9evnE4877vCzNtS55hq/XHzYvaSHHuqHr/ztb3sS4spKuOsu3wvfq1dy6ikq8jNWJDo+PF106eKHDTV2s6B47dv7+d//+lc/l3l+Plx/PQwdGnVkIpIhlHSLyB4jRlD96Taquh1Gbbscqgp6UP2bP8AJJ7RN/bNmwQMPUD35J1QV9KC2awFVO6Da5UJ5eXLqGDoUBg+GrVuTc75kKy+netIU//7rPoNJU+J//w3LdzqQ6kuvTF77ZbJx42D8eKpvmknV0YOoveE3VBWd3rL2FxFpRKhJt5kNN7P3zazMzKbG2D/MzP5hZrvNbES97YPMbKmZvWNmK83sgnr75prZP81sRfAYFOZ7EMkaixZReckUStpPYUDVa+S5agZsW0LJXR2oHFgMixaFH8OSJVQOOoWS2R0ZsG2Jj2FHKSVP9kleDAMHwhtvwEknJX6uZFu0iMqBxZTM7rTn/W9bQsnsTvG9/1jld7xOyd35bfcZprPly6l84HFKHipsXfuLiDTFORfKA8gByoF+QB7wFnBcg2P6AgOBe4ER9bYfBRwZPD8U2AjsH7yeW//YeB4nnniiE5EmlJW5ivxCV8wS58d27P0oZomryC90rqwsc2KoqUnOeZIl0fefCp9hOlP7iUgSAKWukXw0zJ7uk4Ey59xa59xOYB5wboOE/0Pn3EqgtsH2D5xza4Ln/wI2A1rRQSQk1TfO4LZd41lG7PGryxjKrF0XU33zzMyI4fbb/RSF1dWJnytJEn3/qfAZpjO1n4iELbRl4IPhIsOdcxcHry8Eipxzl8U4di7wtHNufox9JwP3AF9yztUGxw4FqoEXgKnOuSZ/c2oZeJGmVRX0YMC2Jayl8dUe+1HO2wWnkv/5v9M/hsceg/PP97OYFBUldq4kadH7f+VZGDly7/IfrGdA7VuRfobpLBX+DYhI+kvbZeDN7BDgPuCHzrm63vCrgWOAk4ADgV80UnaCmZWaWeknn3zSJvGKpKsOFVtYR58mj/mI3nSs2JIZMdQl2ik0X3eL3n9+vh+bXu/RoXZ75J9hOkuFfwMiktnCTLo3APXn+Dos2BYXMysA/gJc65xbVrfdObcxGDZTDfwJP4xlH865O51zQ5xzQ7p318gUkaZUdymkD+uaPKY3H7GjS2FmxNCzJxx2mO/pThEtev9HHgkPP7zXo7pr98g/w3SWCv8GRCSzhZl0vw4caWaHm1keMBJYEE/B4PjHgXsbDjkJer8xMwPOA1YlNWqRLNRuzGguzZ3T5DETc2eTc+HozImhqCileroTff+p8BmmM7WfiISusTssk/EAzgY+wM9icm2w7QbgnOD5ScDHQCXwKfBOsH0MsAtYUe8xKNj3IvA2Ptm+H+jSXByavUSkGakwc0NbxzB/vnPXX586s5ho9pJoqf1EJAloYvaSUJPuVHko6RaJw8KFriK/0E3Lner6Uebas9P1o8xNy53qk42FC7MjhijddJOroJOb1u5nrXv/2d5+iVL7iUiCmkq6Q5u9JJVo9hKROJWXU33zTGrue5COFVvY0aWQnAtH02HKZDii8Vkd0jaGL77wS8Iffnhyz9tao0fDU09RPWosNQ/Pb937T4XPMJ2p/UQkAU3NXqKkW0Sy1+DB0K0bPP981JHAhg3Qty9cfjncdFPU0YiISCuk7ZSBIiKhKiqC116D2trmjw3bsmWQmwuX7bOUgYiIZAAl3SKSvYqK/BCT99+POhK/WM+//w39+kUdiYiIhEBJt4hkr1RZJOeLL/zPgoJo4xARkdAo6RaR7HX00bDfftEukuMcDBsGF18cXQwiIhK69lEHICISmXbt4J57oH//6GJ49VV46y2YPDm6GEREJHRKukUku517brT1T58OBx4I3/9+tHGIiEioNLxERLJbZSXMmwdr1rR93evWwRNPwPjxkJ/f9vWLiEibUdItItlt+3YYNconv23tjjvATENLRESygIaXiEh2697dT9MXxQwmV18Np50GvXq1fd0iItKm1NMtIlJcHM0MJl27wtlnt329IiLS5pR0i4gUFfll2DdsaJv6nIMRI+DJJ9umPhERiZySbhGRukVySkvbpr7Fi+HRR+Hzz9umPhERiZzGdIuIDB7sZxJpq7HVJSVw0EFwwQVtU5+IiEROPd0iIrm50Lu3n0kkbGVl8Je/wKWXQocO4dcnIiIpQUm3iAjAK6/A2LGwe3e49dx6K7Rv75NuERHJGkq6RUTA30R5772walW49QwbBtddB4ccEm49IiKSUpR0i4jAnpspw56v+/zzfdItIiJZRUm3iAjA4YdDYWF4SXdtLcyYAZ9+Gs75RUQkpSnpFhEBfxNlmIvkLFoEl18Ozz8fzvlFRCSlKekWEalzyil+JpOdO5N/7unT4dBD/fASERHJOkq6RUTqTJ0Kb70FeXnJPe/q1b6He9Ikn9SLiEjWUdItIlInrHm6b73Vz8k9YUI45xcRkZSnpFtEpL5LL4UxY5J3Pudg82Z/zu7dk3deERFJK1oGXkSkvupqePZZnywno+fbDB59FGpqEj+XiIikLfV0i4jUV1wMW7bAP/+Z+LlqamD9ev88Jyfx84mISNpS0i0iUt+hh1JNHlUDhlDbLoeqgh5UT5oC5eXxlS8vp3rSFKoKelCbm0dV76OoPn9U/OVFRCQjKekWEamzaBGVI39ECZczoOp18lw1A7YtoWR2JyoHFvu5tpsrP7CYktmdGLBtiS/PKkqe6htfeRERyVjmnAvv5GbDgelADjDbOff/GuwfBtwCDARGOufm19s3Fvhl8PK3zrl7gu0nAnOBTsBC4ErXzJsYMmSIKy0tTcp7EpEMVV5O5cBivrZ9AcvKxqxMAAAJvUlEQVQYus/uYpayOP8cOq9cBkcckfzyIiKS9szsDefckFj7QuvpNrMcYCbwDeA4YJSZHdfgsI+Ai4AHG5Q9ELgeKAJOBq43swOC3bOA8cCRwWN4SG9BRLJI9Y0zuG3X+JgJM8AyhjJr18VU3zwzlPIiIpLZwhxecjJQ5pxb65zbCcwDzq1/gHPuQ+fcSqC2QdmvA88757Y65/4XeB4YbmaHAAXOuWVB7/a9wHkhvgcRyRK19z/I7bvGNXnMrF0XU3PvA/7FnXfC0KH/96i98674yt/3YJPHiIhIZgpzysCewPp6rz/G91y3tmzP4PFxjO37MLMJwASA3r17x1mtiGSrDhVbWEefJo/5iN50rPjUv+jYEQoK9pSv2R5n+S0JxyoiIuknY2+kdM7d6Zwb4pwb0l0LUohIM6q7FNKHdU0e05uP2NG10L/4wQ/8fN7Bo7pr9/jKdylMVsgiIpJGwky6NwC96r0+LNiWSNkNwfPWnFNEpFHtxozm0tw5TR4zMXc2OReODqW8iIhktjCT7teBI83scDPLA0YCC+Is+yxwlpkdENxAeRbwrHNuI/CFmRWbmQE/AJ4MI3gRyS4drrqMSbl3UczSmPuLWcrE3Nl0mDI5lPIiIpLZQku6nXO7gcvwCfS7wCPOuXfM7AYzOwfAzE4ys4+B7wJ3mNk7QdmtwG/wifvrwA3BNoBJwGygDCgHNPGtiCTuiCPoPP9eFuefw7Tcq+lHOe3ZRT/KmZZ7tZ/ub/69jU/3l2h5ERHJaKHO050qNE+3iMStvJzqm2dSc9+DdKzYwo4uheRcONr3UMeTMCdaXkRE0lZT83Qr6RYRERERSYJIFscRERERERFPSbeIiIiISMiUdIuIiIiIhExJt4iIiIhIyJR0i4iIiIiETEm3iIiIiEjIlHSLiIiIiIRMSbeIiIiISMiyYnEcM/sEWNeKooXAliSHk03UfolR+yVObZgYtV9i1H6JUfslRu2XmNa2Xx/nXPdYO7Ii6W4tMyttbFUhaZ7aLzFqv8SpDROj9kuM2i8xar/EqP0SE0b7aXiJiIiIiEjIlHSLiIiIiIRMSXfT7ow6gDSn9kuM2i9xasPEqP0So/ZLjNovMWq/xCS9/TSmW0REREQkZOrpFhEREREJmZLuRpjZcDN738zKzGxq1PGkGzP70MzeNrMVZlYadTypzszuNrPNZraq3rYDzex5M1sT/DwgyhhTWSPt9ysz2xBcgyvM7OwoY0xlZtbLzF4ys9Vm9o6ZXRls1zUYhybaT9dgHMyso5m9ZmZvBe3362D74Wa2PPg9/LCZ5UUdaypqov3mmtk/611/g6KONZWZWY6ZvWlmTwevk379KemOwcxygJnAN4DjgFFmdly0UaWlrzjnBmnKorjMBYY32DYVeME5dyTwQvBaYpvLvu0HcHNwDQ5yzi1s45jSyW7gKufccUAxMDn4P0/XYHwaaz/QNRiPauAM59wJwCBguJkVA7/Ht19/4H+BcRHGmMoaaz+An9W7/lZEF2JauBJ4t97rpF9/SrpjOxkoc86tdc7tBOYB50Yck2Qw59wrwNYGm88F7gme3wOc16ZBpZFG2k/i5Jzb6Jz7R/B8G/4XT090DcalifaTODivIniZGzwccAYwP9iu668RTbSfxMnMDgO+CcwOXhshXH9KumPrCayv9/pj9B9oSzngOTN7w8wmRB1MmurhnNsYPP830CPKYNLUZWa2Mhh+oqERcTCzvsCXgeXoGmyxBu0HugbjEny1vwLYDDwPlAOfOed2B4fo93ATGrafc67u+vvv4Pq72cw6RBhiqrsF+DlQG7zuRgjXn5JuCctpzrnB+CE6k81sWNQBpTPnpxlSz0XLzAKOwH/duhG4MdpwUp+ZdQEeBX7snPui/j5dg82L0X66BuPknKtxzg0CDsN/23xMxCGllYbtZ2YDgKvx7XgScCDwiwhDTFlm9i1gs3PujbDrUtId2wagV73XhwXbJE7OuQ3Bz83A4/j/RKVlNpnZIQDBz80Rx5NWnHObgl9EtcBd6Bpskpnl4hPGB5xzjwWbdQ3GKVb76RpsOefcZ8BLwFBgfzNrH+zS7+E41Gu/4cGwJ+ecqwb+hK6/xpwKnGNmH+KHE58BTCeE609Jd2yvA0cGd67mASOBBRHHlDbMrLOZda17DpwFrGq6lMSwABgbPB8LPBlhLGmnLlkMfBtdg40Kxi/OAd51zt1Ub5euwTg01n66BuNjZt3NbP/geSfgTPy4+JeAEcFhuv4a0Uj7vVfvD2bDj0fW9ReDc+5q59xhzrm++HzvRefc9wnh+tPiOI0Ipna6BcgB7nbO/XfEIaUNM+uH790GaA88qPZrmpk9BJwOFAKbgOuBJ4BHgN7AOuB7zjndLBhDI+13Ov5rfQd8CFxSb3yy1GNmpwGvAm+zZ0zjNfhxyboGm9FE+41C12CzzGwg/ka1HHxn4CPOuRuC3yXz8EMj3gTGBL22Uk8T7fci0B0wYAVwab0bLiUGMzsd+Klz7lthXH9KukVEREREQqbhJSIiIiIiIVPSLSIiIiISMiXdIiIiIiIhU9ItIiIiIhIyJd0iIiIiIiFT0i0ikmHMrKLe87PN7AMz61NvW18z+9jM2jUot8LMiho5Z18z0zy/IiKtpKRbRCRDmdlXgRLgG865dXXbnXMfAh8B/1Hv2GOArs655W0dp4hINlDSLSKSgcxsGH7p8W8558pjHPIQfvW1OiOBeUGP9qtm9o/gcUqMc19kZjPqvX46WFQCMzvLzJYGZf9sZl2S+sZERNKUkm4RkczTAb+i6XnOufcaOeYR4Dwzax+8vgCfiG8GznTODQ62lcRbqZkVAr8EvhaULwV+0rq3ICKSWdo3f4iIiKSZXcASYBxwZawDnHObgjHaXzWzTcBu59wqM9sPmGFmg4Aa4KgW1FsMHAf83cwA8oClrX8bIiKZQ0m3iEjmqQW+B7xgZtc4537XyHF1Q0w2Bc8BpgSvT8B/G7ojRrnd7P1NacfgpwHPO+dGJRa+iEjm0fASEZEM5JzbDnwT+L6ZjWvksMeAs/HDSOYF2/YDNjrnaoELgZwY5T4EBplZOzPrBZwcbF8GnGpm/QHMrLOZtaSnXEQkY6mnW0QkQznntprZcOAVM/vEObegwf7PzGwpcLBzbm2w+TbgUTP7AfAMUBnj1H8H/gmsBt4F/hGc7xMzuwh4yMw6BMf+EvggyW9NRCTtmHMu6hhERERERDKahpeIiIiIiIRMSbeIiIiISMiUdIuIiIiIhExJt4iIiIhIyJR0i4iIiIiETEm3iIiIiEjIlHSLiIiIiIRMSbeIiIiISMj+P374F26Fm5qgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu0yTyNBhPxu"
      },
      "source": [
        "#Agrego dos dimensiones al dataset para evaluar c√≥mo cambia\n",
        "meanD, D_sd = 120, 5.7\n",
        "meanE, E_sd = 135, 8.3\n",
        "\n",
        "D_df = pd.DataFrame(np.random.normal(meanD, D_sd, size=n),columns=['Longitud'])\n",
        "E_df = pd.DataFrame(np.random.normal(meanE, E_sd, size=n),columns=['Longitud'])\n",
        "\n",
        "w = pd.DataFrame(np.random.randint(3,7, size=2*n), columns=['w'])\n",
        "\n",
        "\n",
        "My_df =  pd.concat([D_df, E_df], axis=0)\n",
        "My_df.reset_index(drop=True, inplace=True)\n",
        "data_df.reset_index(drop=True, inplace=True)\n",
        "data2_df = pd.concat([data_df, My_df, w] , axis=1)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBUNTOOqPBiG"
      },
      "source": [
        "data2_df.head\n",
        "\n",
        "#Hago split entre train y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(data2_df, Clases, test_size=0.40)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#Clasificador vecinos con 11\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=11)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "#realizo la predicci√≥n\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCmctljPPjpf",
        "outputId": "4a0867d5-35a3-424b-88b3-47c1f1209e2c"
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[20  5]\n",
            " [ 2 13]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.91      0.80      0.85        25\n",
            "           B       0.72      0.87      0.79        15\n",
            "\n",
            "    accuracy                           0.82        40\n",
            "   macro avg       0.82      0.83      0.82        40\n",
            "weighted avg       0.84      0.82      0.83        40\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "ds260qGnRtdW",
        "outputId": "c1050683-33ed-45b9-9e7f-ddf0d0339794"
      },
      "source": [
        "from sklearn import metrics \n",
        "disp = metrics.plot_confusion_matrix(classifier, X_test, y_test, cmap='inferno')\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[20  5]\n",
            " [ 2 13]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvWRz4NmPsiU"
      },
      "source": [
        "error = []\n",
        "\n",
        "# Calculating error for K values between 1 and 40\n",
        "for i in range(1, 40):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_i = knn.predict(X_test)\n",
        "    error.append(np.mean(pred_i != y_test))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "3fsqxvvzPt74",
        "outputId": "45e26e91-fd9f-46fe-b5a8-9fe798880516"
      },
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',\n",
        "         markerfacecolor='blue', markersize=10)\n",
        "plt.title('Error Rate K Value')\n",
        "plt.xlabel('K Value')\n",
        "plt.ylabel('Mean Error')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Mean Error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIPyoj0zMxNm"
      },
      "source": [
        "#Ahora incremento el N de 50 a 5000 y rehago todo\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "meanA, A_sd = 5, 1.5\n",
        "meanB, B_sd = 8, 1.8\n",
        "n = 5000\n",
        "#Repito lo anterior para un dataset propio, generado a partir de distribuciones normales cada uno con su respectiva media y variancia\n",
        "\n",
        "A_df = pd.DataFrame(np.random.normal(meanA, A_sd, size=n),columns=['Tama√±os'])\n",
        "B_df = pd.DataFrame(np.random.normal(meanB, B_sd, size=n),columns=['Tama√±os'])\n",
        "y = pd.DataFrame(np.random.randint(1,5, size=2*n), columns=['Y'])\n",
        "A_df['Clase'] = 'A'\n",
        "B_df['Clase'] = 'B'\n",
        "\n",
        "C_df =  pd.concat([A_df, B_df], axis=0)\n",
        "C_df.reset_index(drop=True, inplace=True)\n",
        "data_df = pd.concat([C_df, y] , axis=1)\n",
        "data_df\n",
        "Clases = data_df[\"Clase\"]\n",
        "data_df = data_df[[\"Tama√±os\", \"Y\"]]\n",
        "\n",
        "D_df = pd.DataFrame(np.random.normal(meanD, D_sd, size=n),columns=['Longitud'])\n",
        "E_df = pd.DataFrame(np.random.normal(meanE, E_sd, size=n),columns=['Longitud'])\n",
        "\n",
        "w = pd.DataFrame(np.random.randint(3,7, size=2*n), columns=['w'])\n",
        "\n",
        "\n",
        "My_df =  pd.concat([D_df, E_df], axis=0)\n",
        "My_df.reset_index(drop=True, inplace=True)\n",
        "data_df.reset_index(drop=True, inplace=True)\n",
        "data2_df = pd.concat([data_df, My_df, w] , axis=1)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PEgTd9jNKPc"
      },
      "source": [
        "#Hago split entre train y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(data2_df, Clases, test_size=0.40)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#Clasificador vecinos con 20\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=20)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "#realizo la predicci√≥n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuPEdGjdNNrr",
        "outputId": "76a96947-a5f5-4691-a6da-010f4eee678e"
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1877  115]\n",
            " [ 206 1802]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.90      0.94      0.92      1992\n",
            "           B       0.94      0.90      0.92      2008\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "vDJmR7-VNQ_n",
        "outputId": "18f80234-e775-4b32-9180-fe07c406c2a1"
      },
      "source": [
        "from sklearn import metrics \n",
        "disp = metrics.plot_confusion_matrix(classifier, X_test, y_test, cmap='inferno')\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[1877  115]\n",
            " [ 206 1802]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLdsEwkUNaS2"
      },
      "source": [
        "error = []\n",
        "\n",
        "# Calculating error for K values between 1 and 40\n",
        "for i in range(1, 40):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_i = knn.predict(X_test)\n",
        "    error.append(np.mean(pred_i != y_test))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "XQO9p_WMNfaJ",
        "outputId": "3676c41f-8d47-4c5b-d15c-80622139a75a"
      },
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',\n",
        "         markerfacecolor='blue', markersize=10)\n",
        "plt.title('Error Rate K Value')\n",
        "plt.xlabel('K Value')\n",
        "plt.ylabel('Mean Error')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Mean Error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg-14bXsP8A3"
      },
      "source": [
        "#Conclusi√≥n ::\n",
        "###En mi caso, debido a los datos generados que quizas no tienen una correlaci√≥n real entre ellos, dado que son datos generados aleatoriamente. Al aumentar las dimensiones del dataset (de 2 a 4) el error minimo al predecir por el algoritmo de vecinos sube muy poco (de 0.1 a 0.12), \n",
        "###Luego tom√© ese mismo dataset (multivariable) y aument√© su N a 5000, logrando reducir el error por debajo de 0.08, de todas formas, es decir la predicci√≥n por K vecinos m√°s cercanos no muestra una mejora significativa (4%) al aumentar el tama√±o de los datos de forma considerable (dos √≥rdenes de magnitud)\n",
        "######                ->¬øCu√°nto es una mejora significativa?<-\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "WcWXwSTkWnqu",
        "outputId": "aab2d5a7-c05d-4eb7-cc77-1c7e20d0a912"
      },
      "source": [
        "data2_df.head()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tama√±os</th>\n",
              "      <th>Y</th>\n",
              "      <th>Longitud</th>\n",
              "      <th>w</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.080941</td>\n",
              "      <td>3</td>\n",
              "      <td>111.559128</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.790833</td>\n",
              "      <td>3</td>\n",
              "      <td>116.072364</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.798309</td>\n",
              "      <td>3</td>\n",
              "      <td>117.142957</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.217334</td>\n",
              "      <td>1</td>\n",
              "      <td>123.268286</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.186950</td>\n",
              "      <td>3</td>\n",
              "      <td>120.582157</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Tama√±os  Y    Longitud  w\n",
              "0  2.080941  3  111.559128  3\n",
              "1  6.790833  3  116.072364  5\n",
              "2  4.798309  3  117.142957  3\n",
              "3  2.217334  1  123.268286  5\n",
              "4  5.186950  3  120.582157  4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5RL8X2_MIHg"
      },
      "source": [
        "#Ejercicio 2 - Grid Search (Opcional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlJZq6L1d48r"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import Adam\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "cols= [\"Tama√±os\", \"Y\", \"Longitud\", \"w\"]\n",
        "X = data2_df[cols]\n",
        "Y = Clases\n",
        "\n",
        "scaler = StandardScaler().fit(X)\n",
        "\n",
        "# Transform and display the training data\n",
        "X_standardized = scaler.transform(X)\n",
        "\n",
        "data = pd.DataFrame(X_standardized)\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfVgiLfBUsma"
      },
      "source": [
        "def create_model(learn_rate, dropout_rate):\n",
        "    # Create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(4, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    adam = Adam(lr=learn_rate)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=1)\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH9xlZ--Utzr",
        "outputId": "85e73d91-9150-4a14-d952-dcf63fe8ced1"
      },
      "source": [
        "# Define the parameters that you wish to use in your Grid Search along\n",
        "# with the list of values that you wish to try out\n",
        "learn_rate = [0.001, 0.02, 0.2]\n",
        "dropout_rate = [0.0, 0.2, 0.4]\n",
        "batch_size = [10, 20, 30]\n",
        "epochs = [1, 5, 10]\n",
        "\n",
        "seed = 42\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "param_grid = dict(learn_rate=learn_rate, dropout_rate=dropout_rate, batch_size=batch_size, epochs=epochs )\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid,\n",
        "                    cv=KFold(random_state=seed), verbose=10)\n",
        "\n",
        "grid_results = grid.fit(X_standardized, Y)\n",
        "\n",
        "# Summarize the results in a readable format\n",
        "print(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\n",
        "\n",
        "means = grid_results.cv_results_['mean_test_score']\n",
        "stds = grid_results.cv_results_['std_test_score']\n",
        "params = grid_results.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.4597 - accuracy: 0.7902\n",
            "200/200 [==============================] - 0s 931us/step - loss: 0.2698 - accuracy: 0.9060\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.906, total=   2.2s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5910 - accuracy: 0.8380\n",
            "200/200 [==============================] - 0s 963us/step - loss: 0.1960 - accuracy: 0.9215\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.922, total=   1.9s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4569 - accuracy: 0.8627\n",
            "200/200 [==============================] - 0s 956us/step - loss: 0.2016 - accuracy: 0.9215\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.922, total=   1.9s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    6.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 2s 1ms/step - loss: 0.4819 - accuracy: 0.8572\n",
            "200/200 [==============================] - 0s 977us/step - loss: 0.2900 - accuracy: 0.8660\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.866, total=   2.1s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5261 - accuracy: 0.6656\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.8630\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.863, total=   1.9s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2884 - accuracy: 0.8644\n",
            "200/200 [==============================] - 0s 984us/step - loss: 0.2061 - accuracy: 0.9280\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=0.928, total=   1.9s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   11.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 2s 1ms/step - loss: 0.2529 - accuracy: 0.8971\n",
            "200/200 [==============================] - 0s 961us/step - loss: 0.3148 - accuracy: 0.8825\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=0.882, total=   2.0s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   13.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3077 - accuracy: 0.8671\n",
            "200/200 [==============================] - 0s 994us/step - loss: 0.1991 - accuracy: 0.9210\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=0.921, total=   1.9s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   15.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2997 - accuracy: 0.8463\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8835\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=0.883, total=   1.9s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   17.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mSe han truncado las √∫ltimas 5000 l√≠neas del flujo de salida.\u001b[0m\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1952 - accuracy: 0.9182\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1891 - accuracy: 0.9223\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1865 - accuracy: 0.9206\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1916 - accuracy: 0.9246\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1929 - accuracy: 0.9260\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1902 - accuracy: 0.9256\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1849 - accuracy: 0.9254\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2517 - accuracy: 0.8940\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=0.894, total=  11.6s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2668 - accuracy: 0.8872\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1966 - accuracy: 0.9219\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1953 - accuracy: 0.9213\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1907 - accuracy: 0.9236\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1952 - accuracy: 0.9209\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2097 - accuracy: 0.9166\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1960 - accuracy: 0.9209\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1953 - accuracy: 0.9186\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1962 - accuracy: 0.9216\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1898 - accuracy: 0.9242\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.9195\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=0.919, total=  11.5s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2974 - accuracy: 0.8761\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2048 - accuracy: 0.9247\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1943 - accuracy: 0.9292\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1914 - accuracy: 0.9291\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1831 - accuracy: 0.9272\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1856 - accuracy: 0.9271\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1913 - accuracy: 0.9268\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1898 - accuracy: 0.9284\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1902 - accuracy: 0.9266\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1782 - accuracy: 0.9302\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2202 - accuracy: 0.9060\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=0.906, total=  11.4s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2316 - accuracy: 0.9061\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1925 - accuracy: 0.9276\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1875 - accuracy: 0.9278\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1850 - accuracy: 0.9292\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1837 - accuracy: 0.9283\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1821 - accuracy: 0.9324\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1868 - accuracy: 0.9244\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1927 - accuracy: 0.9248\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1766 - accuracy: 0.9279\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1863 - accuracy: 0.9260\n",
            "200/200 [==============================] - 0s 970us/step - loss: 0.3397 - accuracy: 0.8825\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=0.882, total=  11.6s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3112 - accuracy: 0.8788\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2495 - accuracy: 0.8996\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2603 - accuracy: 0.9004\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2566 - accuracy: 0.8946\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2612 - accuracy: 0.8946\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2483 - accuracy: 0.8988\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2393 - accuracy: 0.9128\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2339 - accuracy: 0.9089\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2433 - accuracy: 0.8952\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2373 - accuracy: 0.9068\n",
            "200/200 [==============================] - 0s 994us/step - loss: 0.1765 - accuracy: 0.9715\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=0.971, total=  11.6s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2835 - accuracy: 0.8862\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2670 - accuracy: 0.9014\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2793 - accuracy: 0.8972\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2409 - accuracy: 0.8965\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2460 - accuracy: 0.9061\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2531 - accuracy: 0.8952\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2592 - accuracy: 0.9127\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2423 - accuracy: 0.9123\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2566 - accuracy: 0.9062\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2756 - accuracy: 0.8997\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.8795\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=0.879, total=  11.2s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2760 - accuracy: 0.8889\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3108 - accuracy: 0.8911\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2808 - accuracy: 0.8972\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2593 - accuracy: 0.9017\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2625 - accuracy: 0.9107\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2772 - accuracy: 0.9018\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2569 - accuracy: 0.9070\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2685 - accuracy: 0.9112\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2988 - accuracy: 0.8885\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2727 - accuracy: 0.8884\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2600 - accuracy: 0.8820\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=0.882, total=  10.8s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3035 - accuracy: 0.8891\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2594 - accuracy: 0.9011\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2549 - accuracy: 0.9066\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2455 - accuracy: 0.9117\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2471 - accuracy: 0.9224\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2631 - accuracy: 0.9132\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2625 - accuracy: 0.9131\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2662 - accuracy: 0.9069\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2758 - accuracy: 0.9056\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2504 - accuracy: 0.9192\n",
            "200/200 [==============================] - 0s 983us/step - loss: 0.2825 - accuracy: 0.8665\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=0.867, total=  11.9s\n",
            "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.2784 - accuracy: 0.8924\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2452 - accuracy: 0.9118\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2915 - accuracy: 0.8984\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2577 - accuracy: 0.9063\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2353 - accuracy: 0.9107\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2635 - accuracy: 0.8992\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2410 - accuracy: 0.9101\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2334 - accuracy: 0.9135\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2419 - accuracy: 0.9086\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2522 - accuracy: 0.9056\n",
            "200/200 [==============================] - 0s 983us/step - loss: 0.2405 - accuracy: 0.9150\n",
            "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=0.915, total=  11.9s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.4858 - accuracy: 0.8113\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2757 - accuracy: 0.9030\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.903, total=   2.0s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5627 - accuracy: 0.7667\n",
            "200/200 [==============================] - 0s 969us/step - loss: 0.2721 - accuracy: 0.8955\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.896, total=   1.9s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4885 - accuracy: 0.7915\n",
            "200/200 [==============================] - 0s 985us/step - loss: 0.2040 - accuracy: 0.9210\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.921, total=   1.9s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5068 - accuracy: 0.7270\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.8640\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.864, total=   2.0s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4735 - accuracy: 0.7708\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8925\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.892, total=   1.9s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3010 - accuracy: 0.8820\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2156 - accuracy: 0.9050\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=0.905, total=   1.9s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2961 - accuracy: 0.9000\n",
            "200/200 [==============================] - 0s 945us/step - loss: 0.2347 - accuracy: 0.8830\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=0.883, total=   1.9s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.3391 - accuracy: 0.8627\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2250 - accuracy: 0.9170\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=0.917, total=   2.3s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.3009 - accuracy: 0.8889\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2629 - accuracy: 0.8975\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=0.897, total=   2.0s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3268 - accuracy: 0.8557\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.8805\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=0.881, total=   1.9s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4057 - accuracy: 0.8006\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.9179 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=0.000, total=   1.9s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4776 - accuracy: 0.7758\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.5286 - accuracy: 0.9615\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=0.961, total=   1.8s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3865 - accuracy: 0.8549\n",
            "200/200 [==============================] - 0s 985us/step - loss: 0.3836 - accuracy: 0.8070\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=0.807, total=   1.8s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4507 - accuracy: 0.7841\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.5457 - accuracy: 0.9455\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=0.946, total=   1.9s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4182 - accuracy: 0.7923\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.4123 - accuracy: 0.9660\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=0.966, total=   1.9s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5928 - accuracy: 0.6422\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3082 - accuracy: 0.8550\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3159 - accuracy: 0.8598\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3041 - accuracy: 0.8565\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2939 - accuracy: 0.8573\n",
            "200/200 [==============================] - 0s 987us/step - loss: 0.2972 - accuracy: 0.9075\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=0.908, total=   6.0s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4965 - accuracy: 0.7482\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2411 - accuracy: 0.9159\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2393 - accuracy: 0.9103\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2277 - accuracy: 0.9165\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2276 - accuracy: 0.9213\n",
            "200/200 [==============================] - 0s 977us/step - loss: 0.2810 - accuracy: 0.9065\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=0.906, total=   6.2s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5315 - accuracy: 0.8089\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2833 - accuracy: 0.8995\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2655 - accuracy: 0.9057\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2648 - accuracy: 0.9032\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2595 - accuracy: 0.9019\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.9235\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=0.924, total=   6.2s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5710 - accuracy: 0.8315\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3443 - accuracy: 0.9238\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2901 - accuracy: 0.9193\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2642 - accuracy: 0.9185\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2520 - accuracy: 0.9162\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2595 - accuracy: 0.8680\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=0.868, total=   6.5s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4635 - accuracy: 0.8458\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2407 - accuracy: 0.9103\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2341 - accuracy: 0.9159\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2370 - accuracy: 0.9115\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2260 - accuracy: 0.9170\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2941 - accuracy: 0.8820\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=0.882, total=   6.3s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.3472 - accuracy: 0.8395\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2947 - accuracy: 0.8603\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2929 - accuracy: 0.8606\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3060 - accuracy: 0.8530\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2975 - accuracy: 0.8571\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.8735\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=0.873, total=   6.2s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4274 - accuracy: 0.8395\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3007 - accuracy: 0.8946\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3162 - accuracy: 0.8869\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3015 - accuracy: 0.8905\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2807 - accuracy: 0.8983\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3150 - accuracy: 0.8475\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=0.848, total=   6.3s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3015 - accuracy: 0.8926\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2403 - accuracy: 0.9121\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2308 - accuracy: 0.9094\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2405 - accuracy: 0.9132\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2406 - accuracy: 0.9055\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.9190\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=0.919, total=   6.2s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.4463 - accuracy: 0.7682\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3992 - accuracy: 0.8203\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4238 - accuracy: 0.7989\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4003 - accuracy: 0.8116\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2934 - accuracy: 0.8619\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2555 - accuracy: 0.8665\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=0.867, total=   6.4s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.3041 - accuracy: 0.8662\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2522 - accuracy: 0.9010\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2544 - accuracy: 0.9005\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.9098\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2527 - accuracy: 0.8997\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.8905\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=0.891, total=   6.5s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4790 - accuracy: 0.7634\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.6446\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5986 - accuracy: 0.6175\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.6329\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5933 - accuracy: 0.6982\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.7896 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=0.000, total=   6.4s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.4540 - accuracy: 0.8127\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4520 - accuracy: 0.8208\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4428 - accuracy: 0.8360\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4568 - accuracy: 0.8393\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4721 - accuracy: 0.8257\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.8543 - accuracy: 0.7600\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=0.760, total=   6.5s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.4689 - accuracy: 0.8342\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4131 - accuracy: 0.8416\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4203 - accuracy: 0.8339\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4243 - accuracy: 0.8348\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4476 - accuracy: 0.8147\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3702 - accuracy: 0.9085\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=0.909, total=   6.5s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.4405 - accuracy: 0.7882\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4789 - accuracy: 0.7792\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4604 - accuracy: 0.7913\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4799 - accuracy: 0.7419\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5154 - accuracy: 0.7197\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.6047 - accuracy: 0.9280\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=0.928, total=   7.0s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.3840 - accuracy: 0.8644\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4046 - accuracy: 0.8453\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4466 - accuracy: 0.8395\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4134 - accuracy: 0.8430\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4170 - accuracy: 0.8421\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2759 - accuracy: 0.8620\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=0.862, total=   6.4s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4960 - accuracy: 0.8095\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2496 - accuracy: 0.8970\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2323 - accuracy: 0.9077\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2368 - accuracy: 0.9090\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2312 - accuracy: 0.9071\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2347 - accuracy: 0.9108\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.2326 - accuracy: 0.9063\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.9035\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2306 - accuracy: 0.9116\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2402 - accuracy: 0.9010\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2545 - accuracy: 0.9120\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=0.912, total=  12.4s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5962 - accuracy: 0.8289\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3770 - accuracy: 0.9094\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3243 - accuracy: 0.9089\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.2938 - accuracy: 0.9063\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2841 - accuracy: 0.9037\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2723 - accuracy: 0.9063\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2668 - accuracy: 0.8996\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2620 - accuracy: 0.9012\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2659 - accuracy: 0.9017\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.8993\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.8940\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=0.894, total=  12.5s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.5030 - accuracy: 0.8069\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2490 - accuracy: 0.8990\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2496 - accuracy: 0.8975\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2271 - accuracy: 0.9050\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2340 - accuracy: 0.9057\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2386 - accuracy: 0.9008\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2351 - accuracy: 0.9042\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.2379 - accuracy: 0.9023\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.2329 - accuracy: 0.9049\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2470 - accuracy: 0.8968\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.9210\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=0.921, total=  12.8s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.6019 - accuracy: 0.7746\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3564 - accuracy: 0.9208\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2996 - accuracy: 0.9161\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2717 - accuracy: 0.9153\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2445 - accuracy: 0.9199\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2527 - accuracy: 0.9153\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2448 - accuracy: 0.9133\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2540 - accuracy: 0.9109\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2378 - accuracy: 0.9175\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2351 - accuracy: 0.9115\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.8790\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=0.879, total=  12.4s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.5804 - accuracy: 0.8596\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.9245\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.2858 - accuracy: 0.9243\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2524 - accuracy: 0.9229\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2549 - accuracy: 0.9196\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2335 - accuracy: 0.9211\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2406 - accuracy: 0.9148\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2326 - accuracy: 0.9137\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2329 - accuracy: 0.9189\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2483 - accuracy: 0.9098\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2759 - accuracy: 0.8695\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=0.869, total=  12.8s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.2944 - accuracy: 0.8635\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2339 - accuracy: 0.9012\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2275 - accuracy: 0.9064\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2290 - accuracy: 0.9104\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.8977\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2354 - accuracy: 0.9023\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.2321 - accuracy: 0.9085\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.8979\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.2351 - accuracy: 0.9071\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2296 - accuracy: 0.9044\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.9240\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=0.924, total=  12.8s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3291 - accuracy: 0.8373\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.2579 - accuracy: 0.8941\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.8906\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2540 - accuracy: 0.8962\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2586 - accuracy: 0.8834\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2582 - accuracy: 0.8908\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2415 - accuracy: 0.8993\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2508 - accuracy: 0.9039\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2400 - accuracy: 0.8995\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2382 - accuracy: 0.9000\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.9020\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=0.902, total=  12.7s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.2950 - accuracy: 0.8679\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2551 - accuracy: 0.8893\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2383 - accuracy: 0.8987\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2481 - accuracy: 0.8979\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2430 - accuracy: 0.8969\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.2395 - accuracy: 0.8988\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2492 - accuracy: 0.8969\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.8920\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2459 - accuracy: 0.8984\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2372 - accuracy: 0.9039\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2114 - accuracy: 0.9205\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=0.920, total=  12.8s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3095 - accuracy: 0.9010\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2514 - accuracy: 0.9057\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2510 - accuracy: 0.9021\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2229 - accuracy: 0.9151\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2275 - accuracy: 0.9140\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2303 - accuracy: 0.9144\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2240 - accuracy: 0.9131\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2280 - accuracy: 0.9165\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2301 - accuracy: 0.9078\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2232 - accuracy: 0.9141\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3600 - accuracy: 0.8000\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=0.800, total=  12.4s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.3409 - accuracy: 0.8645\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2610 - accuracy: 0.9076\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2706 - accuracy: 0.8977\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2656 - accuracy: 0.8993\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2670 - accuracy: 0.9018\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2584 - accuracy: 0.9063\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.2604 - accuracy: 0.9024\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2584 - accuracy: 0.9083\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.2535 - accuracy: 0.9060\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2714 - accuracy: 0.9015\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8940\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=0.894, total=  12.9s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.4080 - accuracy: 0.8151\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4664 - accuracy: 0.7905\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4580 - accuracy: 0.7543\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4794 - accuracy: 0.7210\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4279 - accuracy: 0.7809\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4385 - accuracy: 0.7659\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4272 - accuracy: 0.7839\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4338 - accuracy: 0.7806\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4392 - accuracy: 0.7822\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4444 - accuracy: 0.7741\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.9625\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=0.962, total=  12.5s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.4168 - accuracy: 0.7900\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4532 - accuracy: 0.7511\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4935 - accuracy: 0.7425\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6648 - accuracy: 0.6280\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6703 - accuracy: 0.6154\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6731 - accuracy: 0.6099\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6694 - accuracy: 0.6194\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6696 - accuracy: 0.6228\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6671 - accuracy: 0.6241\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6693 - accuracy: 0.6242\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.9915 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=0.000, total=  12.5s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.3878 - accuracy: 0.8430\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4413 - accuracy: 0.8039\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4527 - accuracy: 0.8127\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4634 - accuracy: 0.8030\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4809 - accuracy: 0.7957\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.7062 - accuracy: 0.5013\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.7005 - accuracy: 0.4877\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.7021 - accuracy: 0.4940\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6999 - accuracy: 0.5105\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6978 - accuracy: 0.5125\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.7003 - accuracy: 0.5000\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=0.500, total=  12.5s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.4110 - accuracy: 0.8337\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4349 - accuracy: 0.8429\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5565 - accuracy: 0.7807\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5110 - accuracy: 0.7637\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6688 - accuracy: 0.6189\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6653 - accuracy: 0.6269\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6692 - accuracy: 0.6214\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.6679 - accuracy: 0.6246\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.6675 - accuracy: 0.6242\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.6676 - accuracy: 0.6250\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.9047 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=0.000, total=  12.9s\n",
            "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.3592 - accuracy: 0.8655\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5928 - accuracy: 0.7716\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7573\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5143 - accuracy: 0.7815\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4085 - accuracy: 0.8447\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.6261 - accuracy: 0.7072\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6759 - accuracy: 0.6030\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6716 - accuracy: 0.6138\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6684 - accuracy: 0.6239\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.6676 - accuracy: 0.6254\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 1.0679 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=0.000, total=  12.6s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5479 - accuracy: 0.6752\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.6413 - accuracy: 0.9050\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.905, total=   2.0s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6234 - accuracy: 0.7571\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2519 - accuracy: 0.9030\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.903, total=   2.0s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5871 - accuracy: 0.7156\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.9190\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.919, total=   2.0s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5365 - accuracy: 0.7720\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2997 - accuracy: 0.8730\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.873, total=   2.5s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5229 - accuracy: 0.7424\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3669 - accuracy: 0.8770\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.877, total=   2.0s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.3886 - accuracy: 0.8410\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.9045\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=0.905, total=   2.1s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.3850 - accuracy: 0.8493\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2580 - accuracy: 0.9060\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=0.906, total=   2.0s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.3974 - accuracy: 0.7972\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.9145\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=0.914, total=   2.1s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.6666 - accuracy: 0.6141\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.9235 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=0.000, total=   2.0s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.4040 - accuracy: 0.8342\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.4112 - accuracy: 0.9095\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=0.910, total=   2.0s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5784 - accuracy: 0.6553\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.9901 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=0.000, total=   2.0s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5242 - accuracy: 0.7310\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.9889 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=0.000, total=   2.0s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.6278 - accuracy: 0.6681\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=0.500, total=   2.1s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.6138 - accuracy: 0.6133\n",
            "200/200 [==============================] - 1s 1ms/step - loss: 1.2926 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=0.000, total=   2.4s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5143 - accuracy: 0.8125\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.6205\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=0.621, total=   2.0s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5611 - accuracy: 0.6530\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3475 - accuracy: 0.8243\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3338 - accuracy: 0.8234\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3317 - accuracy: 0.8256\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3322 - accuracy: 0.8321\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3157 - accuracy: 0.9235\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=0.924, total=   6.5s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5328 - accuracy: 0.7182\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3016 - accuracy: 0.8788\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2961 - accuracy: 0.8859\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2921 - accuracy: 0.8805\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2939 - accuracy: 0.8781\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3153 - accuracy: 0.9185\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=0.919, total=   6.6s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5698 - accuracy: 0.7282\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3731 - accuracy: 0.8404\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3575 - accuracy: 0.8515\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3579 - accuracy: 0.8505\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3642 - accuracy: 0.8510\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2136 - accuracy: 0.9200\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=0.920, total=   6.9s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5814 - accuracy: 0.7443\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3428 - accuracy: 0.8823\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3422 - accuracy: 0.8645\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3464 - accuracy: 0.8656\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3497 - accuracy: 0.8623\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2625 - accuracy: 0.8775\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=0.877, total=   6.9s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5430 - accuracy: 0.7695\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3108 - accuracy: 0.8687\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2997 - accuracy: 0.8702\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2965 - accuracy: 0.8723\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2964 - accuracy: 0.8753\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2884 - accuracy: 0.8805\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=0.881, total=   6.6s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.3877 - accuracy: 0.7956\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3416 - accuracy: 0.8202\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3345 - accuracy: 0.8241\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3293 - accuracy: 0.8275\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3368 - accuracy: 0.8310\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3069 - accuracy: 0.9450\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=0.945, total=   6.7s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.4111 - accuracy: 0.8172\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3761 - accuracy: 0.8386\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3662 - accuracy: 0.8447\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3519 - accuracy: 0.8435\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3698 - accuracy: 0.8317\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2905 - accuracy: 0.8545\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=0.854, total=   6.7s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.3517 - accuracy: 0.8286\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3179 - accuracy: 0.8425\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3177 - accuracy: 0.8430\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3038 - accuracy: 0.8417\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3292 - accuracy: 0.8441\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.9160\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=0.916, total=   6.6s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5112 - accuracy: 0.7241\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4111 - accuracy: 0.7970\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4109 - accuracy: 0.7999\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4094 - accuracy: 0.7979\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4023 - accuracy: 0.8037\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.3147 - accuracy: 0.8360\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=0.836, total=   6.6s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.4087 - accuracy: 0.7901\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3567 - accuracy: 0.8201\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3633 - accuracy: 0.8279\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3464 - accuracy: 0.8254\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3404 - accuracy: 0.8358\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2836 - accuracy: 0.8755\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=0.876, total=   6.9s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5443 - accuracy: 0.7369\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6653 - accuracy: 0.6131\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6746 - accuracy: 0.6098\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6664 - accuracy: 0.6281\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6695 - accuracy: 0.6197\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 1.0842 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=0.000, total=   6.7s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5496 - accuracy: 0.7129\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6908 - accuracy: 0.6145\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6426 - accuracy: 0.6132\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.6268 - accuracy: 0.6169\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6689 - accuracy: 0.6231\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 1.2876 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=0.000, total=   6.7s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5925 - accuracy: 0.6613\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6988 - accuracy: 0.5094\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.7036 - accuracy: 0.4955\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.6993 - accuracy: 0.4973\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.7002 - accuracy: 0.5003\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.7081 - accuracy: 0.5000\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=0.500, total=   6.9s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5605 - accuracy: 0.6949\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6328 - accuracy: 0.6251\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.6731 - accuracy: 0.5988\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6658 - accuracy: 0.6259\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6676 - accuracy: 0.6210\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 1.1305 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=0.000, total=   7.0s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5237 - accuracy: 0.7932\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6375 - accuracy: 0.6532\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6641 - accuracy: 0.6081\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6433 - accuracy: 0.6559\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6704 - accuracy: 0.6082\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 1.1105 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=0.000, total=   6.7s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5279 - accuracy: 0.7252\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3206 - accuracy: 0.8645\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3059 - accuracy: 0.8765\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2943 - accuracy: 0.8818\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3099 - accuracy: 0.8670\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3040 - accuracy: 0.8735\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3112 - accuracy: 0.8698\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2958 - accuracy: 0.8739\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2966 - accuracy: 0.8735\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2975 - accuracy: 0.8743\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.9030\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=0.903, total=  12.3s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5640 - accuracy: 0.7392\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3597 - accuracy: 0.8755\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3358 - accuracy: 0.8856\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3296 - accuracy: 0.8817\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3117 - accuracy: 0.8852\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3089 - accuracy: 0.8803\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3097 - accuracy: 0.8812\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3001 - accuracy: 0.8815\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3003 - accuracy: 0.8880\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3040 - accuracy: 0.8833\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2719 - accuracy: 0.8950\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=0.895, total=  12.3s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5353 - accuracy: 0.7965\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3385 - accuracy: 0.8306\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3194 - accuracy: 0.8426\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3270 - accuracy: 0.8428\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3132 - accuracy: 0.8527\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3191 - accuracy: 0.8415\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.8424\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3181 - accuracy: 0.8443\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3159 - accuracy: 0.8406\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3177 - accuracy: 0.8328\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.1982 - accuracy: 0.9190\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=0.919, total=  12.8s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5332 - accuracy: 0.7246\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3425 - accuracy: 0.8679\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3139 - accuracy: 0.8753\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3085 - accuracy: 0.8811\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3183 - accuracy: 0.8768\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2939 - accuracy: 0.8855\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3071 - accuracy: 0.8829\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3009 - accuracy: 0.8908\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2872 - accuracy: 0.8901\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3009 - accuracy: 0.8771\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.8825\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=0.882, total=  12.5s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5092 - accuracy: 0.8101\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3105 - accuracy: 0.8703\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2998 - accuracy: 0.8749\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3123 - accuracy: 0.8715\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2959 - accuracy: 0.8761\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3003 - accuracy: 0.8664\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3035 - accuracy: 0.8667\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.2935 - accuracy: 0.8741\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2973 - accuracy: 0.8688\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.2854 - accuracy: 0.8739\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2626 - accuracy: 0.8845\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=0.885, total=  12.8s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.4049 - accuracy: 0.8194\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3437 - accuracy: 0.8491\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3429 - accuracy: 0.8554\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8557\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8468\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3551 - accuracy: 0.8517\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3431 - accuracy: 0.8565\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3558 - accuracy: 0.8440\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3493 - accuracy: 0.8519\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3358 - accuracy: 0.8633\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.8525\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=0.853, total=  13.7s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.4201 - accuracy: 0.7812\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3781 - accuracy: 0.8156\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3797 - accuracy: 0.8220\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3881 - accuracy: 0.8240\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3979 - accuracy: 0.8102\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3842 - accuracy: 0.8185\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3873 - accuracy: 0.8159\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3856 - accuracy: 0.8190\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3853 - accuracy: 0.8248\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4075 - accuracy: 0.8082\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.9185\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=0.919, total=  13.2s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3591 - accuracy: 0.8482\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8621\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3188 - accuracy: 0.8674\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3100 - accuracy: 0.8749\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2991 - accuracy: 0.8767\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2974 - accuracy: 0.8791\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3021 - accuracy: 0.8773\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3084 - accuracy: 0.8724\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3087 - accuracy: 0.8848\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3201 - accuracy: 0.8710\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.2196 - accuracy: 0.9175\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=0.918, total=  12.8s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.4001 - accuracy: 0.8255\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3642 - accuracy: 0.8596\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3654 - accuracy: 0.8615\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3650 - accuracy: 0.8617\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3667 - accuracy: 0.8619\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3532 - accuracy: 0.8673\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3696 - accuracy: 0.8592\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3806 - accuracy: 0.8524\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3610 - accuracy: 0.8598\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3519 - accuracy: 0.8711\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.9135\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=0.914, total=  12.1s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.3786 - accuracy: 0.8493\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3278 - accuracy: 0.8839\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3212 - accuracy: 0.8910\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3150 - accuracy: 0.8859\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3275 - accuracy: 0.8865\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3311 - accuracy: 0.8759\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3417 - accuracy: 0.8801\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3240 - accuracy: 0.8782\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3084 - accuracy: 0.8862\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3217 - accuracy: 0.8872\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.8975\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=0.897, total=  12.4s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5150 - accuracy: 0.7153\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6530 - accuracy: 0.6164\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.7946 - accuracy: 0.5958\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6699 - accuracy: 0.6193\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6662 - accuracy: 0.6220\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.7182 - accuracy: 0.6107\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6672 - accuracy: 0.6264\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6646 - accuracy: 0.6370\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6727 - accuracy: 0.6060\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6668 - accuracy: 0.6173\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 1.0453 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=0.000, total=  12.6s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5320 - accuracy: 0.7169\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.5827 - accuracy: 0.6100\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6147 - accuracy: 0.6071\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6836 - accuracy: 0.6130\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6265 - accuracy: 0.6050\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6656 - accuracy: 0.6274\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6649 - accuracy: 0.6069\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6867 - accuracy: 0.6153\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.7016 - accuracy: 0.6182\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.7262 - accuracy: 0.5985\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.7944 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=0.000, total=  12.6s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.6005 - accuracy: 0.6705\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6473 - accuracy: 0.5786\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6994 - accuracy: 0.4962\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.7002 - accuracy: 0.5050\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.7040 - accuracy: 0.4968\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.7038 - accuracy: 0.4888\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6977 - accuracy: 0.5143\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6990 - accuracy: 0.5024\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.7010 - accuracy: 0.4917\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.7001 - accuracy: 0.5024\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=0.500, total=  12.5s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5489 - accuracy: 0.7476\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6655 - accuracy: 0.6299\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6876 - accuracy: 0.6496\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6488 - accuracy: 0.6449\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6586 - accuracy: 0.6555\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6690 - accuracy: 0.6249\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6590 - accuracy: 0.6384\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6710 - accuracy: 0.6185\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6693 - accuracy: 0.6176\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6714 - accuracy: 0.6201\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 1.0000\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=1.000, total=  12.5s\n",
            "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 2s 1ms/step - loss: 0.5700 - accuracy: 0.6736\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6729 - accuracy: 0.6163\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6701 - accuracy: 0.6138\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6721 - accuracy: 0.6151\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6685 - accuracy: 0.6192\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6624 - accuracy: 0.6343\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6747 - accuracy: 0.6156\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6727 - accuracy: 0.6118\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6677 - accuracy: 0.6257\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.6688 - accuracy: 0.6259\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 1.0523 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=0.000, total=  12.4s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.6064 - accuracy: 0.8611\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9145\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.914, total=   1.7s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.6287 - accuracy: 0.6706\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8920\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.892, total=   1.4s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.5848 - accuracy: 0.7906\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2335 - accuracy: 0.9180\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.918, total=   1.4s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.6165 - accuracy: 0.8685\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.9080\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.908, total=   1.4s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7750\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.8710\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.871, total=   1.4s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.3232 - accuracy: 0.8438\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8955\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=0.896, total=   1.4s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3060 - accuracy: 0.8624\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8720\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=0.872, total=   1.5s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.3014 - accuracy: 0.8862\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2148 - accuracy: 0.9150\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=0.915, total=   1.4s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2737 - accuracy: 0.8870\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2423 - accuracy: 0.8960\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=0.896, total=   1.4s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.3100 - accuracy: 0.8359\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2600 - accuracy: 0.8890\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=0.889, total=   1.3s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2625 - accuracy: 0.8957\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.9265\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=0.927, total=   1.3s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2605 - accuracy: 0.8952\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2291 - accuracy: 0.9000\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=0.900, total=   1.7s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.8956\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2583 - accuracy: 0.8915\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=0.891, total=   1.5s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.6668 - accuracy: 0.6194\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 1.0316 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=0.000, total=   1.4s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2590 - accuracy: 0.8893\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3088 - accuracy: 0.8340\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=0.834, total=   1.4s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.6237 - accuracy: 0.7979\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.4150 - accuracy: 0.9210\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.3518 - accuracy: 0.9259\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.3169 - accuracy: 0.9189\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2891 - accuracy: 0.9214\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.9015\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=0.901, total=   3.8s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.5743 - accuracy: 0.8822\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2150 - accuracy: 0.9121\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.1904 - accuracy: 0.9268\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.1844 - accuracy: 0.9239\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1941 - accuracy: 0.9199\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.8960\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=0.896, total=   3.8s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.5934 - accuracy: 0.6631\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.3686 - accuracy: 0.9184\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.3087 - accuracy: 0.9242\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2754 - accuracy: 0.9239\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2624 - accuracy: 0.9210\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.9195\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=0.919, total=   3.8s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.5490 - accuracy: 0.8520\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.1949 - accuracy: 0.9275\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.1926 - accuracy: 0.9235\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.1795 - accuracy: 0.9312\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1892 - accuracy: 0.9258\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.8930\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=0.893, total=   3.8s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.5908 - accuracy: 0.7718\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.1918 - accuracy: 0.9284\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.9314\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1861 - accuracy: 0.9301\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1842 - accuracy: 0.9293\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2767 - accuracy: 0.8875\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=0.887, total=   3.9s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.3189 - accuracy: 0.8493\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2083 - accuracy: 0.9169\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2001 - accuracy: 0.9166\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2030 - accuracy: 0.9176\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2003 - accuracy: 0.9180\n",
            "100/100 [==============================] - 1s 1ms/step - loss: 0.1913 - accuracy: 0.9335\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=0.933, total=   4.1s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3679 - accuracy: 0.8783\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2107 - accuracy: 0.9152\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.1985 - accuracy: 0.9172\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.1993 - accuracy: 0.9175\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9148\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9110\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=0.911, total=   3.9s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3593 - accuracy: 0.8433\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2021 - accuracy: 0.9203\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2011 - accuracy: 0.9233\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1967 - accuracy: 0.9203\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2064 - accuracy: 0.9151\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.9200\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=0.920, total=   3.8s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2878 - accuracy: 0.8657\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.1898 - accuracy: 0.9233\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1766 - accuracy: 0.9329\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1906 - accuracy: 0.9267\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1881 - accuracy: 0.9277\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2614 - accuracy: 0.8770\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=0.877, total=   4.0s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2844 - accuracy: 0.8812\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1846 - accuracy: 0.9252\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1855 - accuracy: 0.9316\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1743 - accuracy: 0.9344\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1890 - accuracy: 0.9278\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2365 - accuracy: 0.8960\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=0.896, total=   4.1s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2487 - accuracy: 0.9115\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2379 - accuracy: 0.9053\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2312 - accuracy: 0.9183\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2277 - accuracy: 0.9086\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2439 - accuracy: 0.9110\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.8740\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=0.874, total=   4.3s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2777 - accuracy: 0.8848\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2334 - accuracy: 0.9036\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3023 - accuracy: 0.8824\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2503 - accuracy: 0.8993\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2220 - accuracy: 0.9146\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9755\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=0.975, total=   4.2s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2561 - accuracy: 0.8977\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2557 - accuracy: 0.8914\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2246 - accuracy: 0.9091\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2399 - accuracy: 0.9041\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2310 - accuracy: 0.9125\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.8625\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=0.863, total=   4.0s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.3005 - accuracy: 0.8744\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2372 - accuracy: 0.9157\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2234 - accuracy: 0.9154\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2305 - accuracy: 0.9099\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2370 - accuracy: 0.9097\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3170 - accuracy: 0.8810\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=0.881, total=   3.9s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2534 - accuracy: 0.8967\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2313 - accuracy: 0.9151\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2249 - accuracy: 0.9187\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2607 - accuracy: 0.9118\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 0.2532 - accuracy: 0.8994\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8365\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=0.836, total=   3.9s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.6536\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2138 - accuracy: 0.9195\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1909 - accuracy: 0.9197\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1915 - accuracy: 0.9234\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2040 - accuracy: 0.9153\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1907 - accuracy: 0.9220\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1924 - accuracy: 0.9195\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1970 - accuracy: 0.9202\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1915 - accuracy: 0.9192\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1926 - accuracy: 0.9194\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.9085\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=0.909, total=   7.7s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 2s 2ms/step - loss: 0.5239 - accuracy: 0.7349\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2092 - accuracy: 0.9201\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1911 - accuracy: 0.9206\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1992 - accuracy: 0.9175\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1919 - accuracy: 0.9182\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1912 - accuracy: 0.9195\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1906 - accuracy: 0.9210\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1760 - accuracy: 0.9298\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1906 - accuracy: 0.9242\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1876 - accuracy: 0.9229\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.8955\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=0.896, total=   7.8s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6066 - accuracy: 0.7519\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2117 - accuracy: 0.9216\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2023 - accuracy: 0.9163\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2052 - accuracy: 0.9171\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1903 - accuracy: 0.9255\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1888 - accuracy: 0.9244\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1911 - accuracy: 0.9222\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1919 - accuracy: 0.9243\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.9249\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1839 - accuracy: 0.9299\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2033 - accuracy: 0.9190\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=0.919, total=   7.8s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5799 - accuracy: 0.8309\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1985 - accuracy: 0.9282\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1823 - accuracy: 0.9299\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1944 - accuracy: 0.9246\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1811 - accuracy: 0.9301\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1853 - accuracy: 0.9281\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.9274\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1918 - accuracy: 0.9258\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1881 - accuracy: 0.9286\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1903 - accuracy: 0.9241\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2823 - accuracy: 0.8725\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=0.873, total=   8.0s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5536 - accuracy: 0.7328\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2030 - accuracy: 0.9288\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1872 - accuracy: 0.9291\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.9299\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1862 - accuracy: 0.9279\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.9283\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1889 - accuracy: 0.9244\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.9279\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1849 - accuracy: 0.9283\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1701 - accuracy: 0.9343\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.8960\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=0.896, total=   7.8s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3410 - accuracy: 0.8292\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2067 - accuracy: 0.9155\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2013 - accuracy: 0.9183\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2086 - accuracy: 0.9157\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2002 - accuracy: 0.9164\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2003 - accuracy: 0.9214\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1901 - accuracy: 0.9239\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1960 - accuracy: 0.9159\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1881 - accuracy: 0.9261\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1924 - accuracy: 0.9207\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3008 - accuracy: 0.8960\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=0.896, total=   8.1s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8374\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1985 - accuracy: 0.9239\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1944 - accuracy: 0.9220\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1900 - accuracy: 0.9246\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1946 - accuracy: 0.9200\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1970 - accuracy: 0.9228\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1958 - accuracy: 0.9200\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1999 - accuracy: 0.9210\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2000 - accuracy: 0.9185\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1978 - accuracy: 0.9215\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2736 - accuracy: 0.8900\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=0.890, total=   8.1s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2817 - accuracy: 0.9003\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2038 - accuracy: 0.9178\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1955 - accuracy: 0.9225\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1940 - accuracy: 0.9174\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1889 - accuracy: 0.9230\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1999 - accuracy: 0.9231\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1872 - accuracy: 0.9236\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2046 - accuracy: 0.9154\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1870 - accuracy: 0.9246\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1937 - accuracy: 0.9203\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.9210\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=0.921, total=   8.1s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2575 - accuracy: 0.9094\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1902 - accuracy: 0.9281\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2042 - accuracy: 0.9211\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1930 - accuracy: 0.9217\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1884 - accuracy: 0.9291\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.9304\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1820 - accuracy: 0.9337\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1924 - accuracy: 0.9226\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1856 - accuracy: 0.9277\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1862 - accuracy: 0.9238\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2772 - accuracy: 0.8760\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=0.876, total=   8.0s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2871 - accuracy: 0.8804\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1891 - accuracy: 0.9248\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1768 - accuracy: 0.9284\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1854 - accuracy: 0.9286\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.9244\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1825 - accuracy: 0.9278\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.9325\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.9266\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1711 - accuracy: 0.9348\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.1886 - accuracy: 0.9272\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3032 - accuracy: 0.8585\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=0.859, total=   8.1s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2601 - accuracy: 0.8940\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2104 - accuracy: 0.9127\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2227 - accuracy: 0.9119\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.8869\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2992 - accuracy: 0.8846\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2534 - accuracy: 0.9039\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2581 - accuracy: 0.9006\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2292 - accuracy: 0.9019\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2466 - accuracy: 0.8953\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2214 - accuracy: 0.9144\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.9345\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=0.934, total=   8.3s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2899 - accuracy: 0.8835\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.8953\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2472 - accuracy: 0.9039\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2280 - accuracy: 0.9118\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2247 - accuracy: 0.8988\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2373 - accuracy: 0.9044\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2397 - accuracy: 0.9094\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2595 - accuracy: 0.8952\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2215 - accuracy: 0.9126\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2114 - accuracy: 0.9146\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9475\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=0.947, total=   8.1s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2596 - accuracy: 0.8984\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2261 - accuracy: 0.9133\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2347 - accuracy: 0.9127\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2174 - accuracy: 0.9181\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.9156\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2325 - accuracy: 0.9072\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2601 - accuracy: 0.9018\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2248 - accuracy: 0.9160\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2371 - accuracy: 0.9081\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2339 - accuracy: 0.9083\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2709 - accuracy: 0.8880\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=0.888, total=   9.0s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.9055\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2142 - accuracy: 0.9238\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2143 - accuracy: 0.9200\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2412 - accuracy: 0.9132\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3538 - accuracy: 0.8903\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2516 - accuracy: 0.9051\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2493 - accuracy: 0.9199\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2323 - accuracy: 0.9167\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2362 - accuracy: 0.9185\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.9120\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8095\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=0.809, total=   8.0s\n",
            "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2842 - accuracy: 0.8787\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2196 - accuracy: 0.9151\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2188 - accuracy: 0.9204\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2189 - accuracy: 0.9177\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2247 - accuracy: 0.9164\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2342 - accuracy: 0.9132\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2260 - accuracy: 0.9203\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2290 - accuracy: 0.9139\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2298 - accuracy: 0.9231\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2375 - accuracy: 0.9167\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7810\n",
            "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=0.781, total=   8.2s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5649 - accuracy: 0.7211\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.9050\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.905, total=   1.7s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5976 - accuracy: 0.7671\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2373 - accuracy: 0.9040\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.904, total=   1.7s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5990 - accuracy: 0.7172\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.9205\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.920, total=   1.6s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5832 - accuracy: 0.7940\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2746 - accuracy: 0.8690\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.869, total=   1.5s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6260 - accuracy: 0.7013\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.8455\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.845, total=   1.6s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3501 - accuracy: 0.8342\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2328 - accuracy: 0.9190\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=0.919, total=   1.6s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
            "400/400 [==============================] - 2s 3ms/step - loss: 0.3311 - accuracy: 0.8813\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3006 - accuracy: 0.8655\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=0.865, total=   2.0s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.8724\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9150\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=0.915, total=   1.6s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3654 - accuracy: 0.8290\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.8980\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=0.898, total=   1.7s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3397 - accuracy: 0.8700\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2915 - accuracy: 0.8650\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=0.865, total=   1.6s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3808 - accuracy: 0.8135\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.6022 - accuracy: 0.6580\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=0.658, total=   1.6s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3671 - accuracy: 0.8458\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.6327 - accuracy: 0.6920\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=0.692, total=   1.6s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3590 - accuracy: 0.8575\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8905\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=0.891, total=   1.6s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3646 - accuracy: 0.8389\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3995 - accuracy: 0.8530\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=0.853, total=   1.6s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4608 - accuracy: 0.8215\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.4071 - accuracy: 0.9050\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=0.905, total=   1.6s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5698 - accuracy: 0.6589\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3375 - accuracy: 0.9092\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3008 - accuracy: 0.9169\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2805 - accuracy: 0.9141\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2580 - accuracy: 0.9191\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.9245\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=0.924, total=   4.4s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5925 - accuracy: 0.7683\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2468 - accuracy: 0.9093\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2496 - accuracy: 0.9064\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2374 - accuracy: 0.9101\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2410 - accuracy: 0.9071\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.9095\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=0.910, total=   4.5s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6043 - accuracy: 0.7010\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2972 - accuracy: 0.8953\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2984 - accuracy: 0.8923\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2778 - accuracy: 0.9000\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2690 - accuracy: 0.9022\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2021 - accuracy: 0.9225\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=0.923, total=   4.9s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5722 - accuracy: 0.6566\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3888 - accuracy: 0.8936\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8923\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3131 - accuracy: 0.9052\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3055 - accuracy: 0.9014\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.8980\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=0.898, total=   4.8s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5563 - accuracy: 0.7819\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2417 - accuracy: 0.9087\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2379 - accuracy: 0.9060\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2279 - accuracy: 0.9133\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.9062\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2783 - accuracy: 0.8880\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=0.888, total=   4.9s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8560\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2358 - accuracy: 0.9064\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2328 - accuracy: 0.9043\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2441 - accuracy: 0.8983\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2369 - accuracy: 0.9061\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2092 - accuracy: 0.9250\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=0.925, total=   4.6s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3544 - accuracy: 0.8453\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2558 - accuracy: 0.8993\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2674 - accuracy: 0.8913\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2590 - accuracy: 0.8938\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2515 - accuracy: 0.9022\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2859 - accuracy: 0.9095\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=0.910, total=   4.4s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8506\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2617 - accuracy: 0.9013\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2690 - accuracy: 0.8946\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2616 - accuracy: 0.9046\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2717 - accuracy: 0.8995\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9220\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=0.922, total=   4.8s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8537\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2612 - accuracy: 0.8999\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2605 - accuracy: 0.8919\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.8983\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2431 - accuracy: 0.9074\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2783 - accuracy: 0.9030\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=0.903, total=   4.7s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8776\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2400 - accuracy: 0.9121\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2535 - accuracy: 0.9047\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2398 - accuracy: 0.9090\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2506 - accuracy: 0.9049\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3254 - accuracy: 0.8345\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=0.835, total=   4.5s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3662 - accuracy: 0.8441\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3624 - accuracy: 0.8533\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3468 - accuracy: 0.8561\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4863 - accuracy: 0.7363\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6951 - accuracy: 0.6466\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 1.1093 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=0.000, total=   4.6s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3888 - accuracy: 0.8479\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8607\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3637 - accuracy: 0.8459\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3898 - accuracy: 0.8561\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3675 - accuracy: 0.8472\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.9465\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=0.947, total=   4.5s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3419 - accuracy: 0.8719\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4194 - accuracy: 0.7958\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4609 - accuracy: 0.7648\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4665 - accuracy: 0.7913\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4432 - accuracy: 0.8214\n",
            "100/100 [==============================] - 1s 1ms/step - loss: 0.3750 - accuracy: 0.8715\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=0.872, total=   5.0s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3536 - accuracy: 0.8328\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3659 - accuracy: 0.8362\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4457 - accuracy: 0.7975\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.7891\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4510 - accuracy: 0.7736\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.9225\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=0.923, total=   4.7s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3697 - accuracy: 0.8202\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4876 - accuracy: 0.7687\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6681 - accuracy: 0.6222\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6673 - accuracy: 0.6207\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6620 - accuracy: 0.6304\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 1.0116 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=0.000, total=   4.8s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5839 - accuracy: 0.8262\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2707 - accuracy: 0.9029\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2567 - accuracy: 0.9084\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2554 - accuracy: 0.9028\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2403 - accuracy: 0.9073\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2350 - accuracy: 0.9080\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.9009\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2389 - accuracy: 0.9089\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2312 - accuracy: 0.9115\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2459 - accuracy: 0.9040\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2553 - accuracy: 0.9265\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=0.927, total=   8.5s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6059 - accuracy: 0.6331\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.9101\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3029 - accuracy: 0.9177\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.9124\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2743 - accuracy: 0.9095\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2648 - accuracy: 0.9078\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2501 - accuracy: 0.9151\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2355 - accuracy: 0.9162\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2387 - accuracy: 0.9204\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2376 - accuracy: 0.9161\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3422 - accuracy: 0.9140\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=0.914, total=   8.2s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5839 - accuracy: 0.7798\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2807 - accuracy: 0.8484\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2689 - accuracy: 0.9177\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2628 - accuracy: 0.9149\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2532 - accuracy: 0.9153\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.9175\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2534 - accuracy: 0.9159\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2421 - accuracy: 0.9227\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2559 - accuracy: 0.9110\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2497 - accuracy: 0.9152\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1991 - accuracy: 0.9260\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=0.926, total=   8.2s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6183 - accuracy: 0.8435\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4159 - accuracy: 0.9177\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3484 - accuracy: 0.9230\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3100 - accuracy: 0.9255\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2845 - accuracy: 0.9207\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2698 - accuracy: 0.9195\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2577 - accuracy: 0.9215\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2442 - accuracy: 0.9226\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2455 - accuracy: 0.9165\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2398 - accuracy: 0.9164\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.8720\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=0.872, total=   8.5s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.6283\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3640 - accuracy: 0.9184\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.9180\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2956 - accuracy: 0.9204\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2935 - accuracy: 0.9178\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2814 - accuracy: 0.9121\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2923 - accuracy: 0.9134\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2620 - accuracy: 0.9186\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2492 - accuracy: 0.9202\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2718 - accuracy: 0.9083\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8960\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=0.896, total=   8.1s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3781 - accuracy: 0.8127\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2810 - accuracy: 0.8859\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2829 - accuracy: 0.8891\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2951 - accuracy: 0.8781\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2688 - accuracy: 0.8979\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2803 - accuracy: 0.8910\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2758 - accuracy: 0.8922\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2869 - accuracy: 0.8883\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2679 - accuracy: 0.8940\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2770 - accuracy: 0.8907\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.9205\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=0.920, total=   8.3s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8216\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2349 - accuracy: 0.9016\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2551 - accuracy: 0.8927\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2441 - accuracy: 0.8977\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2478 - accuracy: 0.8941\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2396 - accuracy: 0.9027\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2355 - accuracy: 0.8976\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2452 - accuracy: 0.9000\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2433 - accuracy: 0.9025\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2400 - accuracy: 0.8988\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.9110\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=0.911, total=   8.6s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3587 - accuracy: 0.8487\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2618 - accuracy: 0.8984\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2568 - accuracy: 0.9020\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2612 - accuracy: 0.8988\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2605 - accuracy: 0.8987\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2629 - accuracy: 0.8945\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2538 - accuracy: 0.9021\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2666 - accuracy: 0.9005\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2568 - accuracy: 0.9061\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2607 - accuracy: 0.9005\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9165\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=0.916, total=   8.9s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 2s 2ms/step - loss: 0.3431 - accuracy: 0.8877\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2520 - accuracy: 0.8997\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2281 - accuracy: 0.9146\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2564 - accuracy: 0.9021\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2395 - accuracy: 0.9062\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2437 - accuracy: 0.9085\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2304 - accuracy: 0.9159\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2160 - accuracy: 0.9148\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2313 - accuracy: 0.9095\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2350 - accuracy: 0.9047\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2896 - accuracy: 0.8655\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=0.865, total=   9.1s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3904 - accuracy: 0.8262\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2988 - accuracy: 0.8994\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2987 - accuracy: 0.8970\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3039 - accuracy: 0.8888\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2928 - accuracy: 0.8950\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3034 - accuracy: 0.8930\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3137 - accuracy: 0.8882\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2810 - accuracy: 0.8945\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2993 - accuracy: 0.8880\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2881 - accuracy: 0.8960\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3834 - accuracy: 0.8885\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=0.888, total=   8.7s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3605 - accuracy: 0.8526\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4574 - accuracy: 0.8114\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4411 - accuracy: 0.7802\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4405 - accuracy: 0.7711\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7317\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5763 - accuracy: 0.6139\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5619 - accuracy: 0.6226\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5989 - accuracy: 0.6176\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5774 - accuracy: 0.6096\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5706 - accuracy: 0.6153\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.7708 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=0.000, total=   8.5s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4141 - accuracy: 0.8475\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4224 - accuracy: 0.8436\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4077 - accuracy: 0.8516\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4261 - accuracy: 0.8378\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4295 - accuracy: 0.8287\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3931 - accuracy: 0.8624\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4170 - accuracy: 0.8488\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4520 - accuracy: 0.8231\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4235 - accuracy: 0.8447\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4278 - accuracy: 0.8450\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3823 - accuracy: 0.8650\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=0.865, total=   8.5s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3673 - accuracy: 0.8491\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8612\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3917 - accuracy: 0.8563\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4348 - accuracy: 0.8282\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3919 - accuracy: 0.8464\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3908 - accuracy: 0.8524\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4329 - accuracy: 0.8272\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4881 - accuracy: 0.8071\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4627 - accuracy: 0.8039\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4089 - accuracy: 0.8328\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3838 - accuracy: 0.8650\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=0.865, total=   8.2s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8518\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4275 - accuracy: 0.8110\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4276 - accuracy: 0.8319\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4219 - accuracy: 0.8409\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4025 - accuracy: 0.8520\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3984 - accuracy: 0.8546\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4073 - accuracy: 0.8575\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4452 - accuracy: 0.8283\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4235 - accuracy: 0.8407\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3960 - accuracy: 0.8574\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.6103 - accuracy: 0.7965\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=0.797, total=   8.3s\n",
            "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3587 - accuracy: 0.8683\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3736 - accuracy: 0.8707\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3140 - accuracy: 0.8838\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3008 - accuracy: 0.8867\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2847 - accuracy: 0.8885\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3211 - accuracy: 0.8736\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8752\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3227 - accuracy: 0.8829\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3788 - accuracy: 0.8648\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4341 - accuracy: 0.8592\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8090\n",
            "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=0.809, total=   8.5s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6425 - accuracy: 0.8017\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2368 - accuracy: 0.9345\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.934, total=   1.7s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.7673\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.8995\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.900, total=   1.7s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6000 - accuracy: 0.7080\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9200\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.920, total=   1.7s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6246 - accuracy: 0.7433\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2702 - accuracy: 0.8710\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.871, total=   1.6s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6040 - accuracy: 0.7972\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.8820\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.882, total=   2.1s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3962 - accuracy: 0.8428\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.9100\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=0.910, total=   1.6s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4795 - accuracy: 0.7419\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.9005\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=0.900, total=   1.6s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4173 - accuracy: 0.8544\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.9155\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=0.915, total=   1.7s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4456 - accuracy: 0.8233\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8255\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=0.826, total=   1.6s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4201 - accuracy: 0.8065\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.8820\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=0.882, total=   1.6s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5187 - accuracy: 0.7704\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.4160 - accuracy: 0.7205\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=0.720, total=   1.7s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5581 - accuracy: 0.7835\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.5895\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=0.590, total=   1.7s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5490 - accuracy: 0.6665\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.8920\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=0.892, total=   1.7s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4319 - accuracy: 0.8175\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.6245\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=0.624, total=   1.7s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
            "400/400 [==============================] - 2s 2ms/step - loss: 0.5016 - accuracy: 0.7829\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.7601 - accuracy: 0.2860\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=0.286, total=   2.0s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6078 - accuracy: 0.7219\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3588 - accuracy: 0.8017\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3424 - accuracy: 0.8256\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8342\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3367 - accuracy: 0.8364\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.9160\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=0.916, total=   4.8s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5881 - accuracy: 0.7055\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3593 - accuracy: 0.7806\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3489 - accuracy: 0.7861\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3260 - accuracy: 0.8233\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3342 - accuracy: 0.8273\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.9160\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=0.916, total=   4.7s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6152 - accuracy: 0.6443\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3390 - accuracy: 0.8373\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8379\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3124 - accuracy: 0.8412\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3184 - accuracy: 0.8484\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2031 - accuracy: 0.9210\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=0.921, total=   4.8s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6104 - accuracy: 0.6897\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3629 - accuracy: 0.7886\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3547 - accuracy: 0.8305\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8303\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3627 - accuracy: 0.8205\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8925\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=0.892, total=   4.7s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6108 - accuracy: 0.6672\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3429 - accuracy: 0.8100\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8774\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3192 - accuracy: 0.8760\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3000 - accuracy: 0.8851\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8895\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=0.890, total=   4.8s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.7853\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3375 - accuracy: 0.8572\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3418 - accuracy: 0.8542\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.8547\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3578 - accuracy: 0.8488\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8405\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=0.840, total=   4.7s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4061 - accuracy: 0.8451\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.8671\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3110 - accuracy: 0.8811\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3044 - accuracy: 0.8817\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3312 - accuracy: 0.8691\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2600 - accuracy: 0.8735\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=0.873, total=   4.6s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4004 - accuracy: 0.8382\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2824 - accuracy: 0.8951\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2991 - accuracy: 0.8898\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2821 - accuracy: 0.8969\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2857 - accuracy: 0.8992\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2359 - accuracy: 0.9205\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=0.920, total=   4.8s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4199 - accuracy: 0.8052\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3362 - accuracy: 0.8600\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3350 - accuracy: 0.8622\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3370 - accuracy: 0.8615\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8693\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2359 - accuracy: 0.8595\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=0.859, total=   4.7s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3751 - accuracy: 0.8364\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3038 - accuracy: 0.8704\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3039 - accuracy: 0.8642\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2880 - accuracy: 0.8760\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2907 - accuracy: 0.8768\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2909 - accuracy: 0.8635\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=0.863, total=   5.1s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4654 - accuracy: 0.7883\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5508 - accuracy: 0.7457\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6010 - accuracy: 0.7060\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5622 - accuracy: 0.7422\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7668\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.5759 - accuracy: 0.7970\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=0.797, total=   5.5s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5542 - accuracy: 0.6473\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6133 - accuracy: 0.6274\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6670 - accuracy: 0.6202\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6642 - accuracy: 0.6274\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6637 - accuracy: 0.6255\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.9308 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=0.000, total=   4.6s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6224 - accuracy: 0.6226\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5662 - accuracy: 0.7180\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5566 - accuracy: 0.7228\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5247 - accuracy: 0.7610\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7443\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.8895\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=0.890, total=   4.6s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5480 - accuracy: 0.7541\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4993 - accuracy: 0.8039\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5218 - accuracy: 0.7769\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5145 - accuracy: 0.7794\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4986 - accuracy: 0.7936\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.8889 - accuracy: 0.3530\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=0.353, total=   4.7s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4996 - accuracy: 0.8311\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4465 - accuracy: 0.8357\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7699\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7757\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5529 - accuracy: 0.7448\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.4590\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=0.459, total=   4.9s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6128 - accuracy: 0.7203\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3747 - accuracy: 0.8791\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3370 - accuracy: 0.8937\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3324 - accuracy: 0.8856\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3189 - accuracy: 0.8937\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3112 - accuracy: 0.8927\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3049 - accuracy: 0.8905\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2972 - accuracy: 0.8942\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3017 - accuracy: 0.8887\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3007 - accuracy: 0.8896\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.8975\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=0.897, total=   8.6s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5987 - accuracy: 0.7103\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3198 - accuracy: 0.8239\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3078 - accuracy: 0.8679\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3166 - accuracy: 0.8736\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2963 - accuracy: 0.8779\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2929 - accuracy: 0.8711\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3023 - accuracy: 0.8753\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2885 - accuracy: 0.8865\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2984 - accuracy: 0.8757\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2872 - accuracy: 0.8786\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.9165\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=0.916, total=   8.7s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6231 - accuracy: 0.6999\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3642 - accuracy: 0.8741\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8920\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3355 - accuracy: 0.8819\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8829\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3204 - accuracy: 0.8797\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8833\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3253 - accuracy: 0.8819\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3126 - accuracy: 0.8880\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3123 - accuracy: 0.8836\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.9245\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=0.924, total=   8.9s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.7305\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3726 - accuracy: 0.7903\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8286\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3344 - accuracy: 0.8258\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3412 - accuracy: 0.8340\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8239\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3489 - accuracy: 0.8297\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3327 - accuracy: 0.8359\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8279\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8404\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2973 - accuracy: 0.8905\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=0.891, total=   8.9s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6100 - accuracy: 0.7345\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8672\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3140 - accuracy: 0.8748\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.8758\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2967 - accuracy: 0.8784\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2953 - accuracy: 0.8802\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2966 - accuracy: 0.8782\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2854 - accuracy: 0.8792\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2911 - accuracy: 0.8745\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3008 - accuracy: 0.8680\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2836 - accuracy: 0.8775\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=0.877, total=   9.1s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4326 - accuracy: 0.7681\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2974 - accuracy: 0.8658\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3233 - accuracy: 0.8444\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3023 - accuracy: 0.8538\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3110 - accuracy: 0.8558\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3029 - accuracy: 0.8605\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3144 - accuracy: 0.8633\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3161 - accuracy: 0.8518\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3190 - accuracy: 0.8545\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3004 - accuracy: 0.8611\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.9300\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=0.930, total=   8.8s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3731 - accuracy: 0.8442\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3107 - accuracy: 0.8659\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3147 - accuracy: 0.8622\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2996 - accuracy: 0.8687\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3129 - accuracy: 0.8559\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3061 - accuracy: 0.8692\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2954 - accuracy: 0.8638\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3063 - accuracy: 0.8614\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3001 - accuracy: 0.8660\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3163 - accuracy: 0.8629\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.8895\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=0.890, total=   9.1s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3956 - accuracy: 0.8494\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3101 - accuracy: 0.8857\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3022 - accuracy: 0.8877\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2979 - accuracy: 0.8877\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3051 - accuracy: 0.8870\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8842\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3040 - accuracy: 0.8879\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3202 - accuracy: 0.8782\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2920 - accuracy: 0.8906\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3022 - accuracy: 0.8899\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.9160\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=0.916, total=   9.5s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4250 - accuracy: 0.7682\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3607 - accuracy: 0.8176\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3538 - accuracy: 0.8229\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3554 - accuracy: 0.8105\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3550 - accuracy: 0.8138\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8228\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3402 - accuracy: 0.8209\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3461 - accuracy: 0.8270\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3542 - accuracy: 0.8182\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3578 - accuracy: 0.8061\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3134 - accuracy: 0.8820\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=0.882, total=   9.1s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3703 - accuracy: 0.8363\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3140 - accuracy: 0.8650\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2987 - accuracy: 0.8693\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3001 - accuracy: 0.8776\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3070 - accuracy: 0.8607\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2962 - accuracy: 0.8678\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3013 - accuracy: 0.8621\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.3120 - accuracy: 0.8622\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2995 - accuracy: 0.8710\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.2869 - accuracy: 0.8673\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2553 - accuracy: 0.8645\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=0.864, total=   9.2s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5188 - accuracy: 0.6981\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5616 - accuracy: 0.6528\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6215 - accuracy: 0.6840\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6008 - accuracy: 0.6194\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5541 - accuracy: 0.6351\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5627 - accuracy: 0.6101\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6470 - accuracy: 0.6113\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6647 - accuracy: 0.6280\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6650 - accuracy: 0.6246\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6661 - accuracy: 0.6204\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.8144 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=0.000, total=   8.6s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4755 - accuracy: 0.7432\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5694 - accuracy: 0.6207\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5978 - accuracy: 0.6060\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6777 - accuracy: 0.6170\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6219 - accuracy: 0.6144\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6396 - accuracy: 0.6176\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5705 - accuracy: 0.6090\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5653 - accuracy: 0.6163\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6301 - accuracy: 0.6157\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5864 - accuracy: 0.6290\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.9925\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=0.993, total=   9.1s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5492 - accuracy: 0.7337\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.7480 - accuracy: 0.5340\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.7140 - accuracy: 0.4973\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6982 - accuracy: 0.5082\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6976 - accuracy: 0.5055\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6977 - accuracy: 0.4958\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6988 - accuracy: 0.4993\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6971 - accuracy: 0.5012\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6965 - accuracy: 0.5099\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6984 - accuracy: 0.4939\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=0.500, total=   9.1s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4944 - accuracy: 0.7789\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.7498\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6418 - accuracy: 0.6941\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6552 - accuracy: 0.6943\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6948 - accuracy: 0.7062\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6311 - accuracy: 0.6890\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5494 - accuracy: 0.7420\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5520 - accuracy: 0.7574\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6113 - accuracy: 0.6829\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.6339 - accuracy: 0.6596\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.8106 - accuracy: 0.2965\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=0.296, total=   8.7s\n",
            "[CV] batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5217 - accuracy: 0.7087\n",
            "Epoch 2/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4937 - accuracy: 0.7610\n",
            "Epoch 3/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4611 - accuracy: 0.8022\n",
            "Epoch 4/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4473 - accuracy: 0.8048\n",
            "Epoch 5/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4389 - accuracy: 0.8176\n",
            "Epoch 6/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4828 - accuracy: 0.8165\n",
            "Epoch 7/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.4722 - accuracy: 0.7873\n",
            "Epoch 8/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.6607\n",
            "Epoch 9/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5216 - accuracy: 0.6653\n",
            "Epoch 10/10\n",
            "400/400 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.6546\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.9350\n",
            "[CV]  batch_size=20, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=0.935, total=   8.9s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
            "267/267 [==============================] - 2s 2ms/step - loss: 0.6115 - accuracy: 0.6182\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.7593 - accuracy: 0.7995\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.799, total=   1.9s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5843 - accuracy: 0.8226\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8945\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.895, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6195 - accuracy: 0.7398\n",
            "67/67 [==============================] - 0s 1ms/step - loss: 0.2583 - accuracy: 0.9160\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.916, total=   1.4s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6241 - accuracy: 0.6330\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.8253 - accuracy: 0.7125\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.712, total=   1.5s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6449 - accuracy: 0.6864\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.8410\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.841, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3935 - accuracy: 0.8933\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9210\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=0.921, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3512 - accuracy: 0.8294\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.9110\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=0.911, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2967 - accuracy: 0.9060\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9245\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=0.924, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3037 - accuracy: 0.9000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.8980\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=0.898, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4078 - accuracy: 0.8568\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.8820\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=0.882, total=   1.9s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2829 - accuracy: 0.8832\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.9250\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=0.925, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2585 - accuracy: 0.8847\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9295\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=0.929, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2738 - accuracy: 0.8867\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.9190\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=0.919, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2710 - accuracy: 0.8934\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.9080\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=0.908, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2518 - accuracy: 0.9020\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.8620\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=0.862, total=   1.5s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5897 - accuracy: 0.6275\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3375 - accuracy: 0.9142\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3064 - accuracy: 0.9189\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2792 - accuracy: 0.9176\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2645 - accuracy: 0.9172\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.9130\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=0.913, total=   3.9s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6080 - accuracy: 0.6692\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2543 - accuracy: 0.9223\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1912 - accuracy: 0.9279\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1915 - accuracy: 0.9235\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.9246\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8905\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=0.891, total=   3.8s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6054 - accuracy: 0.8527\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2417 - accuracy: 0.9192\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2009 - accuracy: 0.9220\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1879 - accuracy: 0.9280\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2039 - accuracy: 0.9186\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9200\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=0.920, total=   4.1s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6479 - accuracy: 0.8223\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4409 - accuracy: 0.9159\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3735 - accuracy: 0.9212\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3406 - accuracy: 0.9219\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3085 - accuracy: 0.9293\n",
            "67/67 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.8790\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=0.879, total=   4.4s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5911 - accuracy: 0.7273\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2033 - accuracy: 0.9276\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1838 - accuracy: 0.9314\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1840 - accuracy: 0.9291\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1853 - accuracy: 0.9319\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.8795\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=0.879, total=   4.0s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2922 - accuracy: 0.8756\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1925 - accuracy: 0.9247\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9196\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1870 - accuracy: 0.9221\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.9225\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8975\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=0.897, total=   3.9s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8317\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1987 - accuracy: 0.9223\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1965 - accuracy: 0.9221\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1983 - accuracy: 0.9170\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1873 - accuracy: 0.9219\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.1736 - accuracy: 0.9425\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=0.942, total=   4.0s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2999 - accuracy: 0.8828\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1987 - accuracy: 0.9195\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2095 - accuracy: 0.9144\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1978 - accuracy: 0.9190\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1910 - accuracy: 0.9216\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9190\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=0.919, total=   4.1s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2948 - accuracy: 0.8907\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1907 - accuracy: 0.9237\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1854 - accuracy: 0.9281\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1889 - accuracy: 0.9223\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1921 - accuracy: 0.9223\n",
            "67/67 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.8945\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=0.895, total=   4.0s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.9018\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.9288\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1865 - accuracy: 0.9284\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1821 - accuracy: 0.9293\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1827 - accuracy: 0.9230\n",
            "67/67 [==============================] - 0s 1ms/step - loss: 0.2185 - accuracy: 0.8975\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=0.897, total=   4.0s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3112 - accuracy: 0.8610\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2226 - accuracy: 0.9098\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2103 - accuracy: 0.9174\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2207 - accuracy: 0.9084\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2316 - accuracy: 0.9093\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.7845\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=0.785, total=   4.1s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2745 - accuracy: 0.8800\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2279 - accuracy: 0.9120\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2113 - accuracy: 0.9166\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2161 - accuracy: 0.9117\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2191 - accuracy: 0.9080\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.8725\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=0.873, total=   4.1s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2505 - accuracy: 0.8976\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2204 - accuracy: 0.9130\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2454 - accuracy: 0.9011\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2315 - accuracy: 0.9118\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2213 - accuracy: 0.9070\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9190\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=0.919, total=   4.3s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2397 - accuracy: 0.9034\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2210 - accuracy: 0.9127\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.2257 - accuracy: 0.9107\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2066 - accuracy: 0.9259\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2380 - accuracy: 0.9131\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9220\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=0.922, total=   4.2s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.8776\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2158 - accuracy: 0.9242\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2128 - accuracy: 0.9256\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2150 - accuracy: 0.9225\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.2182 - accuracy: 0.9120\n",
            "67/67 [==============================] - 0s 1ms/step - loss: 0.3538 - accuracy: 0.8575\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=0.858, total=   4.2s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6375 - accuracy: 0.7324\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2567 - accuracy: 0.9178\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1970 - accuracy: 0.9216\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2034 - accuracy: 0.9172\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1997 - accuracy: 0.9172\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1903 - accuracy: 0.9233\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1866 - accuracy: 0.9242\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1892 - accuracy: 0.9244\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1935 - accuracy: 0.9191\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2107 - accuracy: 0.9123\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.8980\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=0.898, total=   7.1s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6031 - accuracy: 0.8824\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2278 - accuracy: 0.9208\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1965 - accuracy: 0.9232\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1965 - accuracy: 0.9200\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1881 - accuracy: 0.9242\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1817 - accuracy: 0.9265\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1897 - accuracy: 0.9240\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1999 - accuracy: 0.9197\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.1776 - accuracy: 0.9296\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1860 - accuracy: 0.9233\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.8950\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=0.895, total=   7.6s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6301 - accuracy: 0.7080\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2733 - accuracy: 0.9188\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1983 - accuracy: 0.9214\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1955 - accuracy: 0.9216\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1933 - accuracy: 0.9220\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1972 - accuracy: 0.9228\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2011 - accuracy: 0.9151\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1958 - accuracy: 0.9198\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1969 - accuracy: 0.9188\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1975 - accuracy: 0.9205\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9235\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=0.924, total=   7.3s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6183 - accuracy: 0.6720\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2599 - accuracy: 0.9233\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.1902 - accuracy: 0.9325\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1869 - accuracy: 0.9303\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1872 - accuracy: 0.9279\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1901 - accuracy: 0.9292\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1870 - accuracy: 0.9289\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.1964 - accuracy: 0.9232\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1876 - accuracy: 0.9280\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1888 - accuracy: 0.9281\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.8925\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=0.892, total=   7.5s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6206 - accuracy: 0.8046\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2346 - accuracy: 0.9246\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1909 - accuracy: 0.9233\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1845 - accuracy: 0.9270\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1820 - accuracy: 0.9322\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.9276\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1889 - accuracy: 0.9242\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.9312\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1873 - accuracy: 0.9275\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1808 - accuracy: 0.9309\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.8815\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=0.882, total=   7.4s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3481 - accuracy: 0.8198\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2058 - accuracy: 0.9182\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.2016 - accuracy: 0.9188\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1943 - accuracy: 0.9199\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1940 - accuracy: 0.9211\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1982 - accuracy: 0.9187\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1910 - accuracy: 0.9182\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9172\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1976 - accuracy: 0.9180\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1976 - accuracy: 0.9207\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9335\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=0.933, total=   7.8s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2909 - accuracy: 0.8633\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1921 - accuracy: 0.9215\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1909 - accuracy: 0.9242\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2045 - accuracy: 0.9182\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.9233\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1873 - accuracy: 0.9232\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1896 - accuracy: 0.9212\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1871 - accuracy: 0.9250\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1929 - accuracy: 0.9220\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1837 - accuracy: 0.9291\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8870\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=0.887, total=   6.9s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3901 - accuracy: 0.8632\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2109 - accuracy: 0.9160\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2025 - accuracy: 0.9183\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1983 - accuracy: 0.9211\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1828 - accuracy: 0.9245\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1865 - accuracy: 0.9247\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1826 - accuracy: 0.9252\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1878 - accuracy: 0.9257\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9219\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1941 - accuracy: 0.9180\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9225\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=0.923, total=   6.8s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3878 - accuracy: 0.8895\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1929 - accuracy: 0.9314\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.1961 - accuracy: 0.9258\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.1863 - accuracy: 0.9314\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1826 - accuracy: 0.9291\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1979 - accuracy: 0.9216\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1880 - accuracy: 0.9253\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1903 - accuracy: 0.9247\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1889 - accuracy: 0.9248\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.9254\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9115\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=0.911, total=   7.4s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3704 - accuracy: 0.8954\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1964 - accuracy: 0.9268\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1894 - accuracy: 0.9274\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1897 - accuracy: 0.9292\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1930 - accuracy: 0.9274\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1863 - accuracy: 0.9240\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1938 - accuracy: 0.9233\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1881 - accuracy: 0.9243\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.9303\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.1882 - accuracy: 0.9225\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.8970\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=0.897, total=   7.0s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2660 - accuracy: 0.8899\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2147 - accuracy: 0.9152\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2353 - accuracy: 0.9082\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2256 - accuracy: 0.9085\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2200 - accuracy: 0.9101\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2092 - accuracy: 0.9168\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2246 - accuracy: 0.9090\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2265 - accuracy: 0.9113\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2130 - accuracy: 0.9177\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2301 - accuracy: 0.9093\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9250\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=0.925, total=   7.0s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2925 - accuracy: 0.8673\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2308 - accuracy: 0.9061\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2263 - accuracy: 0.9131\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2111 - accuracy: 0.9195\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2041 - accuracy: 0.9219\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2069 - accuracy: 0.9197\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2275 - accuracy: 0.9145\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2199 - accuracy: 0.9141\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2144 - accuracy: 0.9132\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2159 - accuracy: 0.9168\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9645\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=0.965, total=   7.1s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2757 - accuracy: 0.8908\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2194 - accuracy: 0.9145\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2360 - accuracy: 0.9121\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2153 - accuracy: 0.9139\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2368 - accuracy: 0.9032\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2496 - accuracy: 0.8978\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2349 - accuracy: 0.9135\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2295 - accuracy: 0.9189\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2356 - accuracy: 0.9099\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2341 - accuracy: 0.9136\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.9100\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=0.910, total=   6.5s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2586 - accuracy: 0.8900\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2207 - accuracy: 0.9195\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2208 - accuracy: 0.9212\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2001 - accuracy: 0.9262\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2205 - accuracy: 0.9117\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2289 - accuracy: 0.9106\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2213 - accuracy: 0.9159\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2095 - accuracy: 0.9202\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9163\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2188 - accuracy: 0.9127\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9040\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=0.904, total=   6.3s\n",
            "[CV] batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2746 - accuracy: 0.8978\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2065 - accuracy: 0.9213\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2311 - accuracy: 0.9159\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2185 - accuracy: 0.9171\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2125 - accuracy: 0.9169\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.9206\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2180 - accuracy: 0.9187\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2153 - accuracy: 0.9179\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2026 - accuracy: 0.9281\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2303 - accuracy: 0.9155\n",
            "67/67 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.8180\n",
            "[CV]  batch_size=30, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=0.818, total=   6.7s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6082 - accuracy: 0.6478\n",
            "67/67 [==============================] - 0s 1ms/step - loss: 0.4009 - accuracy: 0.8965\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.896, total=   1.4s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6614 - accuracy: 0.7085\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.9255\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.925, total=   1.4s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6611 - accuracy: 0.6720\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.9170\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.917, total=   1.4s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6416 - accuracy: 0.8280\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.9075\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.908, total=   1.5s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6114 - accuracy: 0.6296\n",
            "67/67 [==============================] - 0s 1ms/step - loss: 0.8024 - accuracy: 0.7980\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.798, total=   1.4s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4317 - accuracy: 0.8589\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.8640\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=0.864, total=   1.4s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3609 - accuracy: 0.8392\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8370\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=0.837, total=   1.5s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3324 - accuracy: 0.8787\n",
            "67/67 [==============================] - 0s 1ms/step - loss: 0.2006 - accuracy: 0.9190\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=0.919, total=   1.5s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3248 - accuracy: 0.8697\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.8780\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=0.878, total=   1.4s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8357\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.9035\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=0.904, total=   1.8s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4413 - accuracy: 0.7646\n",
            "67/67 [==============================] - 0s 1ms/step - loss: 0.3529 - accuracy: 0.9515\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=0.951, total=   1.5s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8757\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7835\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=0.784, total=   1.4s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3811 - accuracy: 0.8541\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9115\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=0.911, total=   1.5s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3923 - accuracy: 0.8379\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.9070\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=0.907, total=   1.4s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4024 - accuracy: 0.8331\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.8975\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=0.897, total=   1.5s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6080 - accuracy: 0.7168\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2951 - accuracy: 0.8515\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2734 - accuracy: 0.8835\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8949\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2619 - accuracy: 0.8920\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.9105\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=0.910, total=   3.6s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6347 - accuracy: 0.8391\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3183 - accuracy: 0.9156\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2722 - accuracy: 0.9116\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2638 - accuracy: 0.9159\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2642 - accuracy: 0.9104\n",
            "67/67 [==============================] - 0s 1ms/step - loss: 0.2692 - accuracy: 0.8940\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=0.894, total=   3.7s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6208 - accuracy: 0.7976\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2788 - accuracy: 0.8902\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2621 - accuracy: 0.8950\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2480 - accuracy: 0.8964\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2455 - accuracy: 0.9030\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9210\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=0.921, total=   3.7s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6162 - accuracy: 0.7699\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2583 - accuracy: 0.9094\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2579 - accuracy: 0.9044\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2453 - accuracy: 0.9045\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2492 - accuracy: 0.9066\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.8875\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=0.887, total=   4.0s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6355 - accuracy: 0.6065\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4123 - accuracy: 0.8558\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.9062\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.9077\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3179 - accuracy: 0.9038\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.8885\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=0.888, total=   3.8s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3595 - accuracy: 0.8637\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.9061\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.9028\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2361 - accuracy: 0.9063\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2308 - accuracy: 0.9067\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.9085\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=0.909, total=   3.8s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3326 - accuracy: 0.8445\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2210 - accuracy: 0.9159\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2344 - accuracy: 0.9070\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2302 - accuracy: 0.9124\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2318 - accuracy: 0.9048\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.9020\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=0.902, total=   3.8s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3801 - accuracy: 0.7952\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2720 - accuracy: 0.8983\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2594 - accuracy: 0.9055\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2643 - accuracy: 0.8956\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.9044\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9190\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=0.919, total=   3.7s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3738 - accuracy: 0.8037\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2609 - accuracy: 0.9036\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2592 - accuracy: 0.9003\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2568 - accuracy: 0.8979\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2542 - accuracy: 0.8992\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.8935\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=0.893, total=   3.9s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.8657\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2439 - accuracy: 0.9040\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2348 - accuracy: 0.9131\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2373 - accuracy: 0.9103\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2354 - accuracy: 0.9100\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.8445\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=0.845, total=   3.9s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.7789\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3552 - accuracy: 0.8414\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3641 - accuracy: 0.8377\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3671 - accuracy: 0.8269\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4111 - accuracy: 0.8400\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.9085\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=0.909, total=   3.6s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3739 - accuracy: 0.8378\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2963 - accuracy: 0.8847\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8698\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4656 - accuracy: 0.7524\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3558 - accuracy: 0.8455\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.9320\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=0.932, total=   3.7s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3587 - accuracy: 0.8343\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2986 - accuracy: 0.8793\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3403 - accuracy: 0.8722\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3495 - accuracy: 0.8615\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3297 - accuracy: 0.8620\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.9090\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=0.909, total=   4.1s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8556\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3122 - accuracy: 0.8766\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3823 - accuracy: 0.8351\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4278 - accuracy: 0.8011\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4251 - accuracy: 0.8094\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.9200\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=0.920, total=   3.8s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4132 - accuracy: 0.8400\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3763 - accuracy: 0.8681\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8825\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3788 - accuracy: 0.8673\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3750 - accuracy: 0.8612\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.9265\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=0.927, total=   3.7s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6501 - accuracy: 0.6272\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4092 - accuracy: 0.8459\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3419 - accuracy: 0.8106\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8032\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3174 - accuracy: 0.8107\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3123 - accuracy: 0.8666\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3106 - accuracy: 0.8644\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2977 - accuracy: 0.8650\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3060 - accuracy: 0.8552\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3026 - accuracy: 0.8598\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.9025\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=0.902, total=   6.5s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6565 - accuracy: 0.8127\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4805 - accuracy: 0.9020\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4124 - accuracy: 0.9188\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3789 - accuracy: 0.9154\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3555 - accuracy: 0.9144\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3344 - accuracy: 0.9160\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3222 - accuracy: 0.9045\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3101 - accuracy: 0.9033\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.9108\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2838 - accuracy: 0.9075\n",
            "67/67 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.8850\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=0.885, total=   6.4s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6284 - accuracy: 0.6595\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.8971\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2560 - accuracy: 0.8971\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2527 - accuracy: 0.8970\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2464 - accuracy: 0.9034\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2470 - accuracy: 0.9026\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2394 - accuracy: 0.9024\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2375 - accuracy: 0.9079\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2328 - accuracy: 0.9045\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2377 - accuracy: 0.9034\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9190\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=0.919, total=   6.3s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6337 - accuracy: 0.7651\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3165 - accuracy: 0.9207\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2687 - accuracy: 0.9189\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2648 - accuracy: 0.9184\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2462 - accuracy: 0.9238\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2543 - accuracy: 0.9207\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.9226\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2443 - accuracy: 0.9208\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2305 - accuracy: 0.9242\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2306 - accuracy: 0.9232\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.8875\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=0.887, total=   6.4s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6493 - accuracy: 0.6197\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4163 - accuracy: 0.7566\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3612 - accuracy: 0.8968\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3386 - accuracy: 0.8980\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3260 - accuracy: 0.9073\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3078 - accuracy: 0.9043\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3067 - accuracy: 0.8990\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3083 - accuracy: 0.9016\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3014 - accuracy: 0.9028\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2971 - accuracy: 0.8964\n",
            "67/67 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8965\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=0.896, total=   6.7s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3517 - accuracy: 0.8430\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2320 - accuracy: 0.9105\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2327 - accuracy: 0.9120\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2458 - accuracy: 0.9043\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2259 - accuracy: 0.9082\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2295 - accuracy: 0.9106\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2254 - accuracy: 0.9149\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2288 - accuracy: 0.9122\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2291 - accuracy: 0.9086\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2233 - accuracy: 0.9140\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.9090\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=0.909, total=   6.8s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3503 - accuracy: 0.8690\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2493 - accuracy: 0.9055\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2358 - accuracy: 0.9038\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2443 - accuracy: 0.9038\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2339 - accuracy: 0.9089\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2342 - accuracy: 0.9093\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2369 - accuracy: 0.9082\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2332 - accuracy: 0.9107\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.9016\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2363 - accuracy: 0.9107\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2698 - accuracy: 0.8905\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=0.891, total=   7.4s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3909 - accuracy: 0.8101\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2743 - accuracy: 0.8997\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2601 - accuracy: 0.8974\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2675 - accuracy: 0.8954\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2640 - accuracy: 0.8919\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2702 - accuracy: 0.8981\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2649 - accuracy: 0.8958\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2697 - accuracy: 0.8970\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2696 - accuracy: 0.8996\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2614 - accuracy: 0.8978\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9140\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=0.914, total=   7.0s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3511 - accuracy: 0.8348\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2673 - accuracy: 0.8959\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2543 - accuracy: 0.9024\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.9078\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2548 - accuracy: 0.8979\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2532 - accuracy: 0.9015\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.2675 - accuracy: 0.8991\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2533 - accuracy: 0.9017\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2647 - accuracy: 0.8967\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2610 - accuracy: 0.8958\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8840\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=0.884, total=   7.2s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3893 - accuracy: 0.8133\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2469 - accuracy: 0.9151\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2613 - accuracy: 0.9042\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.9098\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2498 - accuracy: 0.9032\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2457 - accuracy: 0.9113\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.9115\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2420 - accuracy: 0.9116\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2394 - accuracy: 0.9120\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.9045\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9325\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=0.933, total=   7.3s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3826 - accuracy: 0.8282\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4441 - accuracy: 0.7609\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4300 - accuracy: 0.7859\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4010 - accuracy: 0.8086\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4156 - accuracy: 0.8084\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4082 - accuracy: 0.8077\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4170 - accuracy: 0.8037\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4112 - accuracy: 0.7957\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4151 - accuracy: 0.7929\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4420 - accuracy: 0.7993\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.9245\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=0.924, total=   7.1s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3214 - accuracy: 0.8586\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8437\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3131 - accuracy: 0.8620\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8582\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3123 - accuracy: 0.8771\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3627 - accuracy: 0.8523\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8691\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.8779\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8740\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3294 - accuracy: 0.8790\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.9620\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=0.962, total=   7.4s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3675 - accuracy: 0.8121\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3535 - accuracy: 0.8254\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3370 - accuracy: 0.8271\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4122 - accuracy: 0.8109\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4588 - accuracy: 0.8223\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4332 - accuracy: 0.8319\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4534 - accuracy: 0.8175\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4359 - accuracy: 0.8281\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4444 - accuracy: 0.8247\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4237 - accuracy: 0.8340\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7315\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=0.732, total=   7.3s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3705 - accuracy: 0.8300\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8500\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3412 - accuracy: 0.8439\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3543 - accuracy: 0.8353\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3691 - accuracy: 0.8593\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3891 - accuracy: 0.8469\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4009 - accuracy: 0.8391\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3916 - accuracy: 0.8386\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4109 - accuracy: 0.8350\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3950 - accuracy: 0.8512\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8720\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=0.872, total=   7.3s\n",
            "[CV] batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3266 - accuracy: 0.8789\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3033 - accuracy: 0.8840\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3082 - accuracy: 0.8879\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2961 - accuracy: 0.8928\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3288 - accuracy: 0.8743\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3118 - accuracy: 0.8870\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8725\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3080 - accuracy: 0.8816\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3559 - accuracy: 0.8701\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3696 - accuracy: 0.8629\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.6945\n",
            "[CV]  batch_size=30, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=0.695, total=   7.7s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6338 - accuracy: 0.6538\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.8580\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.858, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6440 - accuracy: 0.7330\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.9025\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.902, total=   1.7s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6498 - accuracy: 0.6732\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.9110\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.911, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6443 - accuracy: 0.6987\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.8765\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.877, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6386 - accuracy: 0.7063\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.8365\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.836, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4144 - accuracy: 0.8190\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.8870\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=0.887, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4329 - accuracy: 0.7575\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.9095\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=0.910, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4799 - accuracy: 0.7144\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9220\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=0.922, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
            "267/267 [==============================] - 2s 2ms/step - loss: 0.5225 - accuracy: 0.6973\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.8990\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=0.899, total=   2.0s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4089 - accuracy: 0.8107\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.8920\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=0.892, total=   1.7s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.4389 - accuracy: 0.8072\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.9535\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=0.953, total=   1.7s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4892 - accuracy: 0.7696\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.7759 - accuracy: 0.4360\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=0.436, total=   1.7s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5170 - accuracy: 0.7368\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.8995\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=0.900, total=   1.6s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.4690 - accuracy: 0.7515\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.8745\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=0.874, total=   1.7s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4515 - accuracy: 0.7802\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.7765\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=0.776, total=   1.7s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6242 - accuracy: 0.6909\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3685 - accuracy: 0.8099\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8575\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3121 - accuracy: 0.8631\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3109 - accuracy: 0.8637\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.9250\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=0.925, total=   4.2s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6491 - accuracy: 0.6724\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.4049 - accuracy: 0.8564\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3770 - accuracy: 0.8609\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.8778\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3565 - accuracy: 0.8654\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.8985\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=0.899, total=   4.3s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6552 - accuracy: 0.6165\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3678 - accuracy: 0.8277\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3146 - accuracy: 0.8458\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3175 - accuracy: 0.8409\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3214 - accuracy: 0.8446\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.9205\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=0.920, total=   4.5s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 2s 2ms/step - loss: 0.6336 - accuracy: 0.7471\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3797 - accuracy: 0.8667\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8625\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3464 - accuracy: 0.8745\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8635\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.8775\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=0.877, total=   4.5s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6436 - accuracy: 0.7126\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3400 - accuracy: 0.8595\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3196 - accuracy: 0.8673\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3139 - accuracy: 0.8670\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3061 - accuracy: 0.8694\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8795\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=0.879, total=   4.1s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3952 - accuracy: 0.8373\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3213 - accuracy: 0.8723\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3125 - accuracy: 0.8717\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3054 - accuracy: 0.8737\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3087 - accuracy: 0.8743\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9455\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=0.946, total=   4.2s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4093 - accuracy: 0.7997\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3409 - accuracy: 0.8521\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3383 - accuracy: 0.8625\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3161 - accuracy: 0.8709\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8600\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.9325\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=0.933, total=   4.1s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4235 - accuracy: 0.8171\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3262 - accuracy: 0.8886\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3198 - accuracy: 0.8791\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3157 - accuracy: 0.8778\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3220 - accuracy: 0.8785\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.9145\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=0.914, total=   4.0s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3874 - accuracy: 0.8202\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3148 - accuracy: 0.8587\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2950 - accuracy: 0.8668\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2938 - accuracy: 0.8748\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3075 - accuracy: 0.8661\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.8710\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=0.871, total=   4.0s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4274 - accuracy: 0.7779\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3095 - accuracy: 0.8762\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3080 - accuracy: 0.8677\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8656\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3076 - accuracy: 0.8751\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.9160\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=0.916, total=   4.1s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5773 - accuracy: 0.6371\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5230 - accuracy: 0.6574\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5115 - accuracy: 0.6770\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.6864\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5128 - accuracy: 0.6533\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.9550\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=0.955, total=   4.1s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4499 - accuracy: 0.7609\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4545 - accuracy: 0.7446\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4184 - accuracy: 0.7706\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6446 - accuracy: 0.6130\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6247 - accuracy: 0.6191\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.8526 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=0.000, total=   4.0s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 2s 2ms/step - loss: 0.5509 - accuracy: 0.6910\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5196 - accuracy: 0.7266\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5813 - accuracy: 0.6699\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6985 - accuracy: 0.5118\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6962 - accuracy: 0.5008\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.7029 - accuracy: 0.5000\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=0.500, total=   4.6s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4943 - accuracy: 0.7631\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4353 - accuracy: 0.8170\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4500 - accuracy: 0.8077\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.4710 - accuracy: 0.7941\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.8117\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.7519 - accuracy: 0.9175\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=0.918, total=   4.3s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5003 - accuracy: 0.7506\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.6996\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.6861\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5752 - accuracy: 0.6525\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.6703\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.9755\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=0.975, total=   4.3s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6506 - accuracy: 0.6497\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4537 - accuracy: 0.7724\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4160 - accuracy: 0.7997\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.4233 - accuracy: 0.7982\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4099 - accuracy: 0.7973\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4022 - accuracy: 0.8007\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4089 - accuracy: 0.7912\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3973 - accuracy: 0.8004\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3997 - accuracy: 0.7947\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3979 - accuracy: 0.7928\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.9080\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=0.908, total=   7.6s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6696 - accuracy: 0.7079\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.5131 - accuracy: 0.8804\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.4543 - accuracy: 0.8963\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4226 - accuracy: 0.8865\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3973 - accuracy: 0.8818\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3823 - accuracy: 0.8846\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3678 - accuracy: 0.8827\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3645 - accuracy: 0.8834\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3680 - accuracy: 0.8703\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8864\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.8790\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=0.879, total=   7.8s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6375 - accuracy: 0.7012\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3753 - accuracy: 0.8621\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3481 - accuracy: 0.8688\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3283 - accuracy: 0.8812\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3169 - accuracy: 0.8841\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3139 - accuracy: 0.8772\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3186 - accuracy: 0.8822\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.2981 - accuracy: 0.8895\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2933 - accuracy: 0.8861\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3078 - accuracy: 0.8836\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9195\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=0.919, total=   7.8s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6159 - accuracy: 0.6482\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3759 - accuracy: 0.8542\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3355 - accuracy: 0.8731\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3188 - accuracy: 0.8822\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3318 - accuracy: 0.8765\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3196 - accuracy: 0.8818\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3089 - accuracy: 0.8876\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3013 - accuracy: 0.8887\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3039 - accuracy: 0.8891\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3106 - accuracy: 0.8832\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8945\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=0.895, total=   7.6s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6352 - accuracy: 0.6462\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3631 - accuracy: 0.8217\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3371 - accuracy: 0.8788\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3258 - accuracy: 0.8838\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3130 - accuracy: 0.8877\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3097 - accuracy: 0.8964\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3083 - accuracy: 0.8830\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3015 - accuracy: 0.8905\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2947 - accuracy: 0.8956\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3041 - accuracy: 0.8853\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8805\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=0.881, total=   7.4s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3815 - accuracy: 0.8062\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3131 - accuracy: 0.8669\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2896 - accuracy: 0.8739\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3047 - accuracy: 0.8685\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2913 - accuracy: 0.8668\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2902 - accuracy: 0.8736\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2960 - accuracy: 0.8687\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3145 - accuracy: 0.8585\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3070 - accuracy: 0.8661\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2851 - accuracy: 0.8738\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.9250\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=0.925, total=   7.4s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.7345\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4098 - accuracy: 0.7882\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4085 - accuracy: 0.7912\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4094 - accuracy: 0.7873\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4136 - accuracy: 0.7909\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.4010 - accuracy: 0.7961\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3863 - accuracy: 0.8090\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3958 - accuracy: 0.7935\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3985 - accuracy: 0.7942\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.4050 - accuracy: 0.7891\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8815\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=0.882, total=   8.0s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4210 - accuracy: 0.8264\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3476 - accuracy: 0.8451\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8504\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3388 - accuracy: 0.8479\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3449 - accuracy: 0.8426\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.8478\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3478 - accuracy: 0.8422\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3383 - accuracy: 0.8481\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3290 - accuracy: 0.8532\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.8446\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.9180\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=0.918, total=   7.7s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4852 - accuracy: 0.7498\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4066 - accuracy: 0.7942\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4128 - accuracy: 0.7937\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.4046 - accuracy: 0.7934\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3920 - accuracy: 0.8031\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3988 - accuracy: 0.8009\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3983 - accuracy: 0.8021\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3989 - accuracy: 0.7958\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3989 - accuracy: 0.7987\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.3948 - accuracy: 0.7980\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8805\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=0.881, total=   8.0s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4254 - accuracy: 0.8421\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.3095 - accuracy: 0.8780\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.2889 - accuracy: 0.8812\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.2885 - accuracy: 0.8863\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.8847\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2885 - accuracy: 0.8860\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2756 - accuracy: 0.8878\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2874 - accuracy: 0.8881\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.2797 - accuracy: 0.8936\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.2840 - accuracy: 0.8864\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8490\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=0.849, total=   7.9s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4754 - accuracy: 0.7897\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4497 - accuracy: 0.7957\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4896 - accuracy: 0.7890\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.4655 - accuracy: 0.7902\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4620 - accuracy: 0.7959\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5018 - accuracy: 0.7748\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5115 - accuracy: 0.7752\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5790 - accuracy: 0.7356\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5705 - accuracy: 0.7356\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5519 - accuracy: 0.7494\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.6085\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=0.609, total=   7.5s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4114 - accuracy: 0.7822\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4524 - accuracy: 0.7585\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4852 - accuracy: 0.7400\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4291 - accuracy: 0.8045\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4574 - accuracy: 0.7783\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.4979 - accuracy: 0.7180\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5234 - accuracy: 0.6593\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.5185 - accuracy: 0.6904\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5092 - accuracy: 0.6810\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5118 - accuracy: 0.6793\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.9275 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=0.000, total=   7.8s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4855 - accuracy: 0.7114\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.5254 - accuracy: 0.6886\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5555 - accuracy: 0.6880\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7162\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.5816 - accuracy: 0.6788\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.5691 - accuracy: 0.6715\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.6261 - accuracy: 0.6300\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.5508 - accuracy: 0.6906\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.7060 - accuracy: 0.5027\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6757 - accuracy: 0.5304\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.5040\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=0.504, total=   7.9s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.5150 - accuracy: 0.7301\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.6742\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5191 - accuracy: 0.6782\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5701 - accuracy: 0.6603\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.6661\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5541 - accuracy: 0.6641\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5625 - accuracy: 0.6281\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5723 - accuracy: 0.6419\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5491 - accuracy: 0.6631\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.5607 - accuracy: 0.6384\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.9595\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=0.960, total=   7.5s\n",
            "[CV] batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4336 - accuracy: 0.8090\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4314 - accuracy: 0.8321\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 1s 3ms/step - loss: 0.4947 - accuracy: 0.8117\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.8105\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6146 - accuracy: 0.7194\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6377 - accuracy: 0.6610\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6624 - accuracy: 0.6312\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6698 - accuracy: 0.6099\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6621 - accuracy: 0.6317\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 1s 2ms/step - loss: 0.6689 - accuracy: 0.6202\n",
            "67/67 [==============================] - 1s 2ms/step - loss: 1.0761 - accuracy: 0.0000e+00\n",
            "[CV]  batch_size=30, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=0.000, total=   8.0s\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 405 out of 405 | elapsed: 36.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "334/334 [==============================] - 1s 1ms/step - loss: 0.3502 - accuracy: 0.8674\n",
            "Epoch 2/5\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.3672 - accuracy: 0.8600\n",
            "Epoch 3/5\n",
            "334/334 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8667\n",
            "Epoch 4/5\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.3680 - accuracy: 0.8675\n",
            "Epoch 5/5\n",
            "334/334 [==============================] - 0s 1ms/step - loss: 0.3893 - accuracy: 0.8519\n",
            "Best: 0.9192000031471252, using {'batch_size': 30, 'dropout_rate': 0.2, 'epochs': 5, 'learn_rate': 0.2}\n",
            "0.8956000089645386 (0.026033459147386157) with: {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 1, 'learn_rate': 0.001}\n",
            "0.9007999897003174 (0.019602549272791696) with: {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 1, 'learn_rate': 0.02}\n",
            "0.8844000101089478 (0.07016009843672655) with: {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 1, 'learn_rate': 0.2}\n",
            "0.9015999913215638 (0.014182388035399672) with: {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 5, 'learn_rate': 0.001}\n",
            "0.89170001745224 (0.024796364236631042) with: {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 5, 'learn_rate': 0.02}\n",
            "0.9009999990463257 (0.06279172504205559) with: {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 5, 'learn_rate': 0.2}\n",
            "0.8981000185012817 (0.021310561953051796) with: {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.001}\n",
            "0.8881999969482421 (0.0275074591723033) with: {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.02}\n",
            "0.9029000043869019 (0.03784625833277596) with: {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.2}\n",
            "0.895200002193451 (0.0184786300706321) with: {'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 1, 'learn_rate': 0.001}\n",
            "0.8965999960899353 (0.013650628306715061) with: {'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 1, 'learn_rate': 0.02}\n",
            "0.7360000014305115 (0.3726600350555198) with: {'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 1, 'learn_rate': 0.2}\n",
            "0.8975000023841858 (0.019836840145926713) with: {'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 5, 'learn_rate': 0.001}\n",
            "0.8794000148773193 (0.02412550715096674) with: {'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 5, 'learn_rate': 0.02}\n",
            "0.691699993610382 (0.35070095209526025) with: {'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 5, 'learn_rate': 0.2}\n",
            "0.8950999975204468 (0.019350456937675495) with: {'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'learn_rate': 0.001}\n",
            "0.888100004196167 (0.045449309385781594) with: {'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'learn_rate': 0.02}\n",
            "0.2924999952316284 (0.38694314002238384) with: {'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'learn_rate': 0.2}\n",
            "0.8953999996185302 (0.017590910133484728) with: {'batch_size': 10, 'dropout_rate': 0.4, 'epochs': 1, 'learn_rate': 0.001}\n",
            "0.7269000053405762 (0.3634662871655874) with: {'batch_size': 10, 'dropout_rate': 0.4, 'epochs': 1, 'learn_rate': 0.02}\n",
            "0.22410000562667848 (0.2770978968899454) with: {'batch_size': 10, 'dropout_rate': 0.4, 'epochs': 1, 'learn_rate': 0.2}\n",
            "0.9040000081062317 (0.020498780558534945) with: {'batch_size': 10, 'dropout_rate': 0.4, 'epochs': 5, 'learn_rate': 0.001}\n",
            "0.8854000091552734 (0.03995421624404414) with: {'batch_size': 10, 'dropout_rate': 0.4, 'epochs': 5, 'learn_rate': 0.02}\n",
            "0.1 (0.20000000000000004) with: {'batch_size': 10, 'dropout_rate': 0.4, 'epochs': 5, 'learn_rate': 0.2}\n",
            "0.8968000054359436 (0.013343919165667404) with: {'batch_size': 10, 'dropout_rate': 0.4, 'epochs': 10, 'learn_rate': 0.001}\n",
            "0.8999000072479248 (0.02487247180762372) with: {'batch_size': 10, 'dropout_rate': 0.4, 'epochs': 10, 'learn_rate': 0.02}\n",
            "0.3 (0.39999999999999997) with: {'batch_size': 10, 'dropout_rate': 0.4, 'epochs': 10, 'learn_rate': 0.2}\n",
            "0.9006999969482422 (0.017325122702912928) with: {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 1, 'learn_rate': 0.001}\n",
            "0.893500006198883 (0.013820289383227944) with: {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 1, 'learn_rate': 0.02}\n",
            "0.7103999972343444 (0.3564799285070436) with: {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 1, 'learn_rate': 0.2}\n",
            "0.8995000004768372 (0.010977246333107852) with: {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 5, 'learn_rate': 0.001}\n",
            "0.9075000047683716 (0.019529470160612218) with: {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 5, 'learn_rate': 0.02}\n",
            "0.8858999967575073 (0.047289952781689334) with: {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 5, 'learn_rate': 0.2}\n",
            "0.8983000159263611 (0.015564711823071453) with: {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.001}\n",
            "0.8883000016212463 (0.020836509861851604) with: {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.02}\n",
            "0.8720999956130981 (0.06640737253158745) with: {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.2}\n",
            "0.8887999892234802 (0.027441928930816862) with: {'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 1, 'learn_rate': 0.001}\n",
            "0.8925000071525574 (0.02334096600785649) with: {'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 1, 'learn_rate': 0.02}\n",
            "0.7996999859809876 (0.10378034714367902) with: {'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 1, 'learn_rate': 0.2}\n",
            "0.9085000038146973 (0.01402497437282965) with: {'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 5, 'learn_rate': 0.001}\n",
            "0.898800003528595 (0.033140001027494606) with: {'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 5, 'learn_rate': 0.02}\n",
            "0.5481000065803527 (0.44817691222120354) with: {'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 5, 'learn_rate': 0.2}\n",
            "0.9069000005722045 (0.02066979121703216) with: {'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'learn_rate': 0.001}\n",
            "0.9003999829292297 (0.02066495129722015) with: {'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'learn_rate': 0.02}\n",
            "0.6671000123023987 (0.33473309334866835) with: {'batch_size': 20, 'dropout_rate': 0.2, 'epochs': 10, 'learn_rate': 0.2}\n",
            "0.9014000058174133 (0.02343373017290039) with: {'batch_size': 20, 'dropout_rate': 0.4, 'epochs': 1, 'learn_rate': 0.001}\n",
            "0.8867000102996826 (0.03265057023501609) with: {'batch_size': 20, 'dropout_rate': 0.4, 'epochs': 1, 'learn_rate': 0.02}\n",
            "0.6225000023841858 (0.19827228717215548) with: {'batch_size': 20, 'dropout_rate': 0.4, 'epochs': 1, 'learn_rate': 0.2}\n",
            "0.9070000052452087 (0.013224977369240953) with: {'batch_size': 20, 'dropout_rate': 0.4, 'epochs': 5, 'learn_rate': 0.001}\n",
            "0.8714999914169311 (0.026735738075418077) with: {'batch_size': 20, 'dropout_rate': 0.4, 'epochs': 5, 'learn_rate': 0.02}\n",
            "0.4996999979019165 (0.32037753252961126) with: {'batch_size': 20, 'dropout_rate': 0.4, 'epochs': 5, 'learn_rate': 0.2}\n",
            "0.9012999892234802 (0.017127747715956754) with: {'batch_size': 20, 'dropout_rate': 0.4, 'epochs': 10, 'learn_rate': 0.001}\n",
            "0.8964000105857849 (0.023603815619300195) with: {'batch_size': 20, 'dropout_rate': 0.4, 'epochs': 10, 'learn_rate': 0.02}\n",
            "0.5448000013828278 (0.3776660719650109) with: {'batch_size': 20, 'dropout_rate': 0.4, 'epochs': 10, 'learn_rate': 0.2}\n",
            "0.832700002193451 (0.0726323762292162) with: {'batch_size': 30, 'dropout_rate': 0.0, 'epochs': 1, 'learn_rate': 0.001}\n",
            "0.9073000073432922 (0.015644796594173116) with: {'batch_size': 30, 'dropout_rate': 0.0, 'epochs': 1, 'learn_rate': 0.02}\n",
            "0.9087000012397766 (0.024436863148780012) with: {'batch_size': 30, 'dropout_rate': 0.0, 'epochs': 1, 'learn_rate': 0.2}\n",
            "0.896399998664856 (0.01706283058601603) with: {'batch_size': 30, 'dropout_rate': 0.0, 'epochs': 5, 'learn_rate': 0.001}\n",
            "0.9101999998092651 (0.01838369257425197) with: {'batch_size': 30, 'dropout_rate': 0.0, 'epochs': 5, 'learn_rate': 0.02}\n",
            "0.8711000084877014 (0.05014319688077738) with: {'batch_size': 30, 'dropout_rate': 0.0, 'epochs': 5, 'learn_rate': 0.2}\n",
            "0.8980999946594238 (0.013868671079039325) with: {'batch_size': 30, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.001}\n",
            "0.9103000044822693 (0.016782719633804302) with: {'batch_size': 30, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.02}\n",
            "0.9043000102043152 (0.04802665676017676) with: {'batch_size': 30, 'dropout_rate': 0.0, 'epochs': 10, 'learn_rate': 0.2}\n",
            "0.8888999938964843 (0.046466553348017456) with: {'batch_size': 30, 'dropout_rate': 0.2, 'epochs': 1, 'learn_rate': 0.001}\n",
            "0.8803000211715698 (0.028919893979278424) with: {'batch_size': 30, 'dropout_rate': 0.2, 'epochs': 1, 'learn_rate': 0.02}\n",
            "0.8901999950408935 (0.05644784381100518) with: {'batch_size': 30, 'dropout_rate': 0.2, 'epochs': 1, 'learn_rate': 0.2}\n",
            "0.9002999901771546 (0.01323103111709835) with: {'batch_size': 30, 'dropout_rate': 0.2, 'epochs': 5, 'learn_rate': 0.001}\n",
            "0.893500006198883 (0.02587856887863091) with: {'batch_size': 30, 'dropout_rate': 0.2, 'epochs': 5, 'learn_rate': 0.02}\n",
            "0.9192000031471252 (0.009341305683631377) with: {'batch_size': 30, 'dropout_rate': 0.2, 'epochs': 5, 'learn_rate': 0.2}\n",
            "0.8980999946594238 (0.012187711311283227) with: {'batch_size': 30, 'dropout_rate': 0.2, 'epochs': 10, 'learn_rate': 0.001}\n",
            "0.9059999942779541 (0.01731761702787007) with: {'batch_size': 30, 'dropout_rate': 0.2, 'epochs': 10, 'learn_rate': 0.02}\n",
            "0.8369000077247619 (0.10577588109583037) with: {'batch_size': 30, 'dropout_rate': 0.2, 'epochs': 10, 'learn_rate': 0.2}\n",
            "0.8768999934196472 (0.027596018497457672) with: {'batch_size': 30, 'dropout_rate': 0.4, 'epochs': 1, 'learn_rate': 0.001}\n",
            "0.9019000053405761 (0.012571385214819628) with: {'batch_size': 30, 'dropout_rate': 0.4, 'epochs': 1, 'learn_rate': 0.02}\n",
            "0.7879999876022339 (0.18511671854179165) with: {'batch_size': 30, 'dropout_rate': 0.4, 'epochs': 1, 'learn_rate': 0.2}\n",
            "0.9001999974250794 (0.01986857309710635) with: {'batch_size': 30, 'dropout_rate': 0.4, 'epochs': 5, 'learn_rate': 0.001}\n",
            "0.9159000039100647 (0.025178172503519457) with: {'batch_size': 30, 'dropout_rate': 0.4, 'epochs': 5, 'learn_rate': 0.02}\n",
            "0.669599997997284 (0.3777858367767191) with: {'batch_size': 30, 'dropout_rate': 0.4, 'epochs': 5, 'learn_rate': 0.2}\n",
            "0.8963000059127808 (0.015667154060591593) with: {'batch_size': 30, 'dropout_rate': 0.4, 'epochs': 10, 'learn_rate': 0.001}\n",
            "0.8907999992370605 (0.027746355816525195) with: {'batch_size': 30, 'dropout_rate': 0.4, 'epochs': 10, 'learn_rate': 0.02}\n",
            "0.4144000053405762 (0.37048393191845347) with: {'batch_size': 30, 'dropout_rate': 0.4, 'epochs': 10, 'learn_rate': 0.2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7JDz4Zj6iTU"
      },
      "source": [
        "#Ejercicio 3 - Spotify Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d00qrkPlbjin"
      },
      "source": [
        "import pandas as pd\n",
        "#leemos el dataset\n",
        "attributes_spotify = pd.read_csv(\"https://raw.githubusercontent.com/emmanueliarussi/DataScienceCapstone/master/3_MidtermProjects/ProjectBOM/data/attributes_spotify.csv\")\n",
        "\n",
        "#attributes_spotify.head(-20)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvuh3c2lfhB7"
      },
      "source": [
        "##Par√°metros\n",
        "####Los par√°metros m√°s importantes de la canci√≥n para m√≠ son :\n",
        "#####Danceability : de acuerdo al estilo de m√∫sica de la persona, puede gustarle una canci√≥n de acuerdo si este par√°metro es alto (ej reggaeton) o bajo (ej m√∫sica cl√°sica)\n",
        "#####Energy : permite disasociar canciones canciones, d√≥nde el espectro m√°s grande (quiz√°s) queda en el medio. Dado que, un valor bajo se corresponde con m√∫sica cl√°sica, y un valor alto se corresponde con death metal\n",
        "#####Liveness : todo buen amante del rock prefiere pistas en vivo a pistas estudio, m√°s a√∫n si suenan igual en ambos √°mbitos\n",
        "#####Loudness : medio d√≠ficil de justificar, pero no solemos preferir canciones que se escuchan bajo\n",
        "\n",
        "####Par√°metros que considero NO tan importantes, y que por eso eliminar√© del dataset\n",
        "#####Duration : la duraci√≥n de la canci√≥n es indistinta, si una canci√≥n por si sola es demasiado larga, uno la salta y listo, y por otro lado, se pueden likear tanto canciones como remix (o enganchados, etc), cuya longitud es extendida.\n",
        "#####Valence : considero que es ambivalente si la canci√≥n es triste o alegre, dado que por lo general, poner de un tipo u otro depende m√°s del estado de √°nimo de la persona que de si te gusta o no. \n",
        "#####Key & Mode : no le encuentro importancia significativa al tono de la canci√≥n\n",
        "#####Tempo & time_signature : al igual que Key & Mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "XJu-ujz2bmuO",
        "outputId": "6b3cebe2-38fd-42b4-d832-1f25856917c7"
      },
      "source": [
        "\n",
        "attributes_spotify.describe()\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>key</th>\n",
              "      <th>liveness</th>\n",
              "      <th>loudness</th>\n",
              "      <th>mode</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>valence</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2017.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>2.017000e+03</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1008.000000</td>\n",
              "      <td>0.187590</td>\n",
              "      <td>0.618422</td>\n",
              "      <td>2.463062e+05</td>\n",
              "      <td>0.681577</td>\n",
              "      <td>0.133286</td>\n",
              "      <td>5.342588</td>\n",
              "      <td>0.190844</td>\n",
              "      <td>-7.085624</td>\n",
              "      <td>0.612295</td>\n",
              "      <td>0.092664</td>\n",
              "      <td>121.603272</td>\n",
              "      <td>3.968270</td>\n",
              "      <td>0.496815</td>\n",
              "      <td>0.505702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>582.402066</td>\n",
              "      <td>0.259989</td>\n",
              "      <td>0.161029</td>\n",
              "      <td>8.198181e+04</td>\n",
              "      <td>0.210273</td>\n",
              "      <td>0.273162</td>\n",
              "      <td>3.648240</td>\n",
              "      <td>0.155453</td>\n",
              "      <td>3.761684</td>\n",
              "      <td>0.487347</td>\n",
              "      <td>0.089931</td>\n",
              "      <td>26.685604</td>\n",
              "      <td>0.255853</td>\n",
              "      <td>0.247195</td>\n",
              "      <td>0.500091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.122000</td>\n",
              "      <td>1.604200e+04</td>\n",
              "      <td>0.014800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018800</td>\n",
              "      <td>-33.097000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023100</td>\n",
              "      <td>47.859000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.034800</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>504.000000</td>\n",
              "      <td>0.009630</td>\n",
              "      <td>0.514000</td>\n",
              "      <td>2.000150e+05</td>\n",
              "      <td>0.563000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.092300</td>\n",
              "      <td>-8.394000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037500</td>\n",
              "      <td>100.189000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.295000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1008.000000</td>\n",
              "      <td>0.063300</td>\n",
              "      <td>0.631000</td>\n",
              "      <td>2.292610e+05</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.127000</td>\n",
              "      <td>-6.248000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.054900</td>\n",
              "      <td>121.427000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.492000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1512.000000</td>\n",
              "      <td>0.265000</td>\n",
              "      <td>0.738000</td>\n",
              "      <td>2.703330e+05</td>\n",
              "      <td>0.846000</td>\n",
              "      <td>0.054000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.247000</td>\n",
              "      <td>-4.746000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.108000</td>\n",
              "      <td>137.849000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.691000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>0.995000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>1.004627e+06</td>\n",
              "      <td>0.998000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>0.969000</td>\n",
              "      <td>-0.307000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.816000</td>\n",
              "      <td>219.331000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.992000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0  acousticness  ...      valence       target\n",
              "count  2017.000000   2017.000000  ...  2017.000000  2017.000000\n",
              "mean   1008.000000      0.187590  ...     0.496815     0.505702\n",
              "std     582.402066      0.259989  ...     0.247195     0.500091\n",
              "min       0.000000      0.000003  ...     0.034800     0.000000\n",
              "25%     504.000000      0.009630  ...     0.295000     0.000000\n",
              "50%    1008.000000      0.063300  ...     0.492000     1.000000\n",
              "75%    1512.000000      0.265000  ...     0.691000     1.000000\n",
              "max    2016.000000      0.995000  ...     0.992000     1.000000\n",
              "\n",
              "[8 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "-LXCuNYmewEL",
        "outputId": "477834ac-64fd-467f-8bee-bbc643fe0fcb"
      },
      "source": [
        "col_names = [\"acousticness\", \"danceability\", \"energy\", \"instrumentalness\", \"liveness\", \"loudness\", \"speechiness\", \"target\"]\n",
        "attributes_spotify_filtered = attributes_spotify[col_names]\n",
        "attributes_spotify_filtered.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>liveness</th>\n",
              "      <th>loudness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0102</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.434</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>0.1650</td>\n",
              "      <td>-8.795</td>\n",
              "      <td>0.4310</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.1990</td>\n",
              "      <td>0.743</td>\n",
              "      <td>0.359</td>\n",
              "      <td>0.006110</td>\n",
              "      <td>0.1370</td>\n",
              "      <td>-10.401</td>\n",
              "      <td>0.0794</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0344</td>\n",
              "      <td>0.838</td>\n",
              "      <td>0.412</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>-7.148</td>\n",
              "      <td>0.2890</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.6040</td>\n",
              "      <td>0.494</td>\n",
              "      <td>0.338</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.0922</td>\n",
              "      <td>-15.236</td>\n",
              "      <td>0.0261</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.1800</td>\n",
              "      <td>0.678</td>\n",
              "      <td>0.561</td>\n",
              "      <td>0.512000</td>\n",
              "      <td>0.4390</td>\n",
              "      <td>-11.648</td>\n",
              "      <td>0.0694</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   acousticness  danceability  energy  ...  loudness  speechiness  target\n",
              "0        0.0102         0.833   0.434  ...    -8.795       0.4310       1\n",
              "1        0.1990         0.743   0.359  ...   -10.401       0.0794       1\n",
              "2        0.0344         0.838   0.412  ...    -7.148       0.2890       1\n",
              "3        0.6040         0.494   0.338  ...   -15.236       0.0261       1\n",
              "4        0.1800         0.678   0.561  ...   -11.648       0.0694       1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDut64cdzCw7"
      },
      "source": [
        "Liked_df = attributes_spotify[\"target\"]\n",
        "attributes_spotify_filtered = attributes_spotify_filtered[[\"acousticness\", \"danceability\", \"energy\", \"instrumentalness\", \"liveness\", \"loudness\", \"speechiness\"]]\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV5IiEgWzx9t"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(attributes_spotify_filtered, Liked_df, test_size=0.40)\n",
        "#Divido a una razon de 60-40 para entrenar y testear"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9GCOCAmz396"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJQTt31w0FOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3de390b7-1803-45f7-e66b-4d29adac2e65"
      },
      "source": [
        "#Dado que es un dataset de 2000+ canciones voy a poner n_neighbors en 10. Luego de plotear el error, recalculo para 8 (error minimo)\n",
        "classifier = KNeighborsClassifier(n_neighbors=8)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=8, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stdC-EiM6-vY"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "#realizo la predicci√≥n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx-E_Viz7Dq-",
        "outputId": "2b15d5f4-c414-46c3-b366-b91b35855b63"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[333  87]\n",
            " [141 246]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.79      0.74       420\n",
            "           1       0.74      0.64      0.68       387\n",
            "\n",
            "    accuracy                           0.72       807\n",
            "   macro avg       0.72      0.71      0.71       807\n",
            "weighted avg       0.72      0.72      0.72       807\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "shviXsQQ7HP_",
        "outputId": "486d7008-dfca-44ff-bc38-a26f400fc3c9"
      },
      "source": [
        "from sklearn import metrics \n",
        "disp = metrics.plot_confusion_matrix(classifier, X_test, y_test, cmap='inferno')\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[333  87]\n",
            " [141 246]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPdVFvRK7LMp"
      },
      "source": [
        "error = []\n",
        "\n",
        "# Calculating error for K values between 1 and 40\n",
        "for i in range(1, 40):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_i = knn.predict(X_test)\n",
        "    error.append(np.mean(pred_i != y_test))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "ZOsJmpLO7VeF",
        "outputId": "bfd79b2a-1ffc-438e-8e75-d987fbfabddd"
      },
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',\n",
        "         markerfacecolor='blue', markersize=10)\n",
        "plt.title('Error Rate K Value')\n",
        "plt.xlabel('K Value')\n",
        "plt.ylabel('Mean Error')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Mean Error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EcJ6NiP8QQz",
        "outputId": "caecc9ee-044b-4a4c-c4ac-f119bc6f06c9"
      },
      "source": [
        "#Ahora voy a recalcular todo, sin sacar variables y ver si hay cambios significativos \n",
        "col_names = [\"acousticness\", \"danceability\", \"duration_ms\", \"energy\", \"instrumentalness\", \"key\", \"liveness\", \"loudness\", \"mode\", \"speechiness\", \"tempo\", \"time_signature\", \"valence\",\"target\" ]\n",
        "attributes_spotify_filtered = attributes_spotify[col_names]\n",
        "attributes_spotify_filtered.head()\n",
        "col_names = [\"acousticness\", \"danceability\", \"duration_ms\", \"energy\", \"instrumentalness\", \"key\", \"liveness\", \"loudness\", \"mode\", \"speechiness\", \"tempo\", \"time_signature\", \"valence\"]\n",
        "Liked_df = attributes_spotify[\"target\"]\n",
        "attributes_spotify_filtered = attributes_spotify_filtered[col_names]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(attributes_spotify_filtered, Liked_df, test_size=0.40)\n",
        "#Divido a una razon de 60-40 para entrenar y testear\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#Tomo n=8 (mejor resultado para el try anterior). Rehago el try con n=9 (segundo mejor resultado de este try)\n",
        "classifier = KNeighborsClassifier(n_neighbors=9)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "#realizo la predicci√≥n\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[309  88]\n",
            " [164 246]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.78      0.71       397\n",
            "           1       0.74      0.60      0.66       410\n",
            "\n",
            "    accuracy                           0.69       807\n",
            "   macro avg       0.69      0.69      0.69       807\n",
            "weighted avg       0.70      0.69      0.69       807\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "EkDUQhaB9ulT",
        "outputId": "c5cfa363-5f49-4b41-ab9a-97711836a5fd"
      },
      "source": [
        "from sklearn import metrics \n",
        "disp = metrics.plot_confusion_matrix(classifier, X_test, y_test, cmap='inferno')\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[309  88]\n",
            " [164 246]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBGejiVe9xCg"
      },
      "source": [
        "error = []\n",
        "\n",
        "# Calculating error for K values between 1 and 50\n",
        "for i in range(1, 50):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_i = knn.predict(X_test)\n",
        "    error.append(np.mean(pred_i != y_test))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "zaU5ptkM9zEV",
        "outputId": "bdea33ff-eeb8-43f7-bfbd-8a7f06bafd11"
      },
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, 50), error, color='red', linestyle='dashed', marker='o',\n",
        "         markerfacecolor='blue', markersize=10)\n",
        "plt.title('Error Rate K Value')\n",
        "plt.xlabel('K Value')\n",
        "plt.ylabel('Mean Error')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Mean Error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCK1ghS4EhKn"
      },
      "source": [
        "#Conclusiones\n",
        "###Para el primer dataset se ha obtenido predicciones satisfactorias con un error de 0.30\n",
        "###En el segundo caso, fue posible disminuir √©ste error hasta 0.27\n",
        "###Sin embargo, para el segundo dataset se computan todas las columnas de datos (13). Si tenemos √©sto en cuenta, al escalar en cantidad de datos se torna mucho m√°s costoso el algoritmo para no obtener una diferencia significativa en la predicci√≥n.\n",
        "###Con el 54% de los datos totales (7 columnas de 13 -> primer dataset) se obtuvo pr√°cticamente la misma efectividad de predicci√≥n que usando los datos totales. \n"
      ]
    }
  ]
}